<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; The What-How Divide – The Human Element</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch04.html" rel="next">
<link href="./Ch02.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-626149efe8f5d16e1d391ba177679bf0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="_resources/css/normalize.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch03.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">The Human Element</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.docx">
              <i class="bi bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The False Binary: Why AI Won’t Replace Human Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch03.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beyond Computation: The Philosophy of Human Intelligence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Human Edge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Finding the Sweet Spot</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Implementation Challenge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Human Element in Creative Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Following the Money</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Building the Future: A Human-Centric Vision for AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">About the Authors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-traditional-how-advantage" id="toc-the-traditional-how-advantage" class="nav-link active" data-scroll-target="#the-traditional-how-advantage"><span class="header-section-number">3.1</span> The Traditional “How” Advantage</a></li>
  <li><a href="#ais-disruption-of-how" id="toc-ais-disruption-of-how" class="nav-link" data-scroll-target="#ais-disruption-of-how"><span class="header-section-number">3.2</span> AI’s Disruption of “How”</a></li>
  <li><a href="#the-rise-of-what-skills" id="toc-the-rise-of-what-skills" class="nav-link" data-scroll-target="#the-rise-of-what-skills"><span class="header-section-number">3.3</span> The Rise of “What” Skills</a></li>
  <li><a href="#real-world-examples" id="toc-real-world-examples" class="nav-link" data-scroll-target="#real-world-examples"><span class="header-section-number">3.4</span> Real-World Examples</a>
  <ul class="collapse">
  <li><a href="#book-writing-when-bulldozers-move-words" id="toc-book-writing-when-bulldozers-move-words" class="nav-link" data-scroll-target="#book-writing-when-bulldozers-move-words"><span class="header-section-number">3.4.1</span> Book-Writing: When Bulldozers Move Words</a></li>
  </ul></li>
  <li><a href="#more-examples" id="toc-more-examples" class="nav-link" data-scroll-target="#more-examples"><span class="header-section-number">3.5</span> More examples</a>
  <ul class="collapse">
  <li><a href="#software-development-beyond-code-generation" id="toc-software-development-beyond-code-generation" class="nav-link" data-scroll-target="#software-development-beyond-code-generation"><span class="header-section-number">3.5.1</span> Software Development: Beyond Code Generation</a></li>
  <li><a href="#investment-analysis-beyond-the-numbers" id="toc-investment-analysis-beyond-the-numbers" class="nav-link" data-scroll-target="#investment-analysis-beyond-the-numbers"><span class="header-section-number">3.5.2</span> Investment Analysis: Beyond the Numbers</a></li>
  <li><a href="#ai-and-healthcare-beyond-pattern-recognition" id="toc-ai-and-healthcare-beyond-pattern-recognition" class="nav-link" data-scroll-target="#ai-and-healthcare-beyond-pattern-recognition"><span class="header-section-number">3.5.3</span> AI and Healthcare: Beyond Pattern Recognition</a></li>
  </ul></li>
  <li><a href="#investment-implications" id="toc-investment-implications" class="nav-link" data-scroll-target="#investment-implications"><span class="header-section-number">3.6</span> Investment Implications</a></li>
  <li><a href="#the-future-of-work" id="toc-the-future-of-work" class="nav-link" data-scroll-target="#the-future-of-work"><span class="header-section-number">3.7</span> The Future of Work</a></li>
  <li><a href="#preparing-for-the-transition" id="toc-preparing-for-the-transition" class="nav-link" data-scroll-target="#preparing-for-the-transition"><span class="header-section-number">3.8</span> Preparing for the Transition</a>
  <ul class="collapse">
  <li><a href="#the-human-element-remains-central" id="toc-the-human-element-remains-central" class="nav-link" data-scroll-target="#the-human-element-remains-central"><span class="header-section-number">3.8.1</span> The Human Element Remains Central</a></li>
  </ul></li>
  <li><a href="#looking-ahead" id="toc-looking-ahead" class="nav-link" data-scroll-target="#looking-ahead"><span class="header-section-number">3.9</span> Looking Ahead</a></li>
  <li><a href="#beyond-the-false-binary" id="toc-beyond-the-false-binary" class="nav-link" data-scroll-target="#beyond-the-false-binary"><span class="header-section-number">3.10</span> Beyond the False Binary</a></li>
  <li><a href="#the-nature-of-the-divide" id="toc-the-nature-of-the-divide" class="nav-link" data-scroll-target="#the-nature-of-the-divide"><span class="header-section-number">3.11</span> The Nature of the Divide</a></li>
  <li><a href="#philosophical-dimensions-of-the-divide" id="toc-philosophical-dimensions-of-the-divide" class="nav-link" data-scroll-target="#philosophical-dimensions-of-the-divide"><span class="header-section-number">3.12</span> Philosophical Dimensions of the Divide</a></li>
  <li><a href="#case-studies-the-divide-in-practice" id="toc-case-studies-the-divide-in-practice" class="nav-link" data-scroll-target="#case-studies-the-divide-in-practice"><span class="header-section-number">3.13</span> Case Studies: The Divide in Practice</a>
  <ul class="collapse">
  <li><a href="#software-development" id="toc-software-development" class="nav-link" data-scroll-target="#software-development"><span class="header-section-number">3.13.1</span> Software Development</a></li>
  <li><a href="#content-creation" id="toc-content-creation" class="nav-link" data-scroll-target="#content-creation"><span class="header-section-number">3.13.2</span> Content Creation</a></li>
  <li><a href="#healthcare" id="toc-healthcare" class="nav-link" data-scroll-target="#healthcare"><span class="header-section-number">3.13.3</span> Healthcare</a></li>
  </ul></li>
  <li><a href="#the-competitive-dynamics-of-the-divide" id="toc-the-competitive-dynamics-of-the-divide" class="nav-link" data-scroll-target="#the-competitive-dynamics-of-the-divide"><span class="header-section-number">3.14</span> The Competitive Dynamics of the Divide</a></li>
  <li><a href="#organizational-implications" id="toc-organizational-implications" class="nav-link" data-scroll-target="#organizational-implications"><span class="header-section-number">3.15</span> Organizational Implications</a></li>
  <li><a href="#investment-implications-1" id="toc-investment-implications-1" class="nav-link" data-scroll-target="#investment-implications-1"><span class="header-section-number">3.16</span> Investment Implications</a></li>
  <li><a href="#the-evolution-of-knowledge-work" id="toc-the-evolution-of-knowledge-work" class="nav-link" data-scroll-target="#the-evolution-of-knowledge-work"><span class="header-section-number">3.17</span> The Evolution of Knowledge Work</a></li>
  <li><a href="#integration-with-enhancement-thesis" id="toc-integration-with-enhancement-thesis" class="nav-link" data-scroll-target="#integration-with-enhancement-thesis"><span class="header-section-number">3.18</span> Integration with Enhancement Thesis</a></li>
  <li><a href="#conclusion-navigating-the-transformation" id="toc-conclusion-navigating-the-transformation" class="nav-link" data-scroll-target="#conclusion-navigating-the-transformation"><span class="header-section-number">3.19</span> Conclusion: Navigating the Transformation</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></h1>
<p class="subtitle lead">AI’s Real Impact on Knowledge Work</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Until recently, career success in knowledge work depended heavily on mastering “how” skills - knowing how to build a compelling PowerPoint, how to structure a financial model, or how to write efficient code. But as AI systems become more capable at these technical tasks, the competitive advantage is shifting dramatically toward people who know “what” needs to be done - those who can identify the right problems to solve and strategies to pursue.</p>
<p>This fundamental shift from “how” to “what” has profound implications for businesses, careers, and investment opportunities. Let’s explore why this transformation is happening and what it means for different stakeholders.</p>
<section id="the-traditional-how-advantage" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="the-traditional-how-advantage"><span class="header-section-number">3.1</span> The Traditional “How” Advantage</h2>
<p>Traditionally, organizations needed large teams of specialists who knew “how” to perform various technical tasks: - Financial analysts who knew how to build complex Excel models - Software engineers who knew how to write code in specific languages - Designers who knew how to use tools like Photoshop - Writers who knew how to craft clear technical documentation - Translators who knew how to convert text between languages</p>
<p>These specialists developed their skills through years of practice and training. Their expertise created both job security and earning power - companies were willing to pay premium salaries for people who could execute complex technical tasks effectively.</p>
</section>
<section id="ais-disruption-of-how" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="ais-disruption-of-how"><span class="header-section-number">3.2</span> AI’s Disruption of “How”</h2>
<p>Large language models and other AI tools are rapidly getting better at many of these “how” tasks: - ChatGPT can write basic code in multiple languages - Midjourney can generate sophisticated images - Translation tools are approaching human-level quality - AI assistants can create presentations and documentation</p>
<p>This capability is expanding quickly. Tasks that seemed immune to automation just a few years ago are now being handled competently by AI systems. And unlike human specialists who may take years to master new skills, AI systems can be rapidly retrained or fine-tuned for new capabilities.</p>
</section>
<section id="the-rise-of-what-skills" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="the-rise-of-what-skills"><span class="header-section-number">3.3</span> The Rise of “What” Skills</h2>
<p>As AI handles more of the “how,” competitive advantage shifts to people who excel at determining “what” needs to be done: - What problems are worth solving? - What features should a product include? - What markets should a company enter? - What strategies will create sustainable advantages? - What metrics matter most for success?</p>
<p>These “what” decisions require capabilities that current AI systems fundamentally lack:</p>
<p><strong>Pattern Recognition Across Domains</strong> Humans can notice subtle patterns and draw insights across seemingly unrelated fields. A business leader might see parallels between consumer behavior in fashion and trends in enterprise software, leading to novel strategic insights. Current AI systems, despite their broad training, struggle to make these creative connections in meaningful ways.</p>
<p><strong>Judgment Under Uncertainty</strong> Many crucial business decisions involve incomplete information and conflicting priorities. Experienced leaders develop judgment about which risks are worth taking and which tradeoffs make sense. This type of judgment emerges from years of seeing both successes and failures firsthand - something AI systems cannot truly replicate.</p>
<p><strong>Understanding Human Context</strong> Success in business ultimately depends on understanding human needs, motivations, and behaviors. While AI can process vast amounts of data about human behavior, it lacks the innate understanding that comes from being human and experiencing the full range of human emotions and social dynamics.</p>
</section>
<section id="real-world-examples" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="real-world-examples"><span class="header-section-number">3.4</span> Real-World Examples</h2>
<p>Let’s look at some specific examples of how this “what vs.&nbsp;how” divide plays out:</p>
<section id="book-writing-when-bulldozers-move-words" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="book-writing-when-bulldozers-move-words"><span class="header-section-number">3.4.1</span> Book-Writing: When Bulldozers Move Words</h3>
<p>What’s the value of traditional books when ChatGPT can generate coherent answers to any question?</p>
<p>The analogy of construction work helps illustrate the relationship between AI and human authorship. Like bulldozers that efficiently move earth, AI can rapidly generate vast quantities of coherent text. But just as construction requires both heavy machinery and skilled artisans, meaningful books need both AI’s raw productive power and human refinement.</p>
<p>Consider the process of learning chess. ChatGPT can explain rules, play practice games, and offer personalized instruction. Future versions might even customize the learning path based on individual aptitude and interests. However, a well-crafted book offers something different: a carefully structured approach that helps readers decide their level of engagement. The finite, constrained nature of a book provides focus that chatbots, with their endless potential for digression, cannot easily match.</p>
<p>The key to understanding AI’s role in authorship lies in recognizing the distinct phases of book creation.</p>
<ol type="1">
<li><p>The initial phase - deciding subject matter and scope, aka the “what” phase — remains fundamentally human. While AI can help brainstorm ideas or identify underexplored topics, the essential creative spark and purpose must come from human intention. This reflects a broader truth about AI: it excels at processing existing patterns but struggles to generate truly novel directions.</p></li>
<li><p>The next phase — outlining the subject into smaller, related topics that make a coherent whole — demonstrates the potential for human-AI collaboration. AI can quickly generate comprehensive topic structures, but human expertise is crucial for identifying gaps, inconsistencies, or areas requiring special emphasis. This interplay between AI’s broad pattern recognition and human domain knowledge creates stronger frameworks than either could achieve alone.</p></li>
<li><p>The writing phase is where AI’s “bulldozer” capabilities shine. Instead of laboriously crafting individual sentences, authors can use AI to generate substantial blocks of coherent text. This dramatically accelerates the initial draft process. However, like rough-graded earth, this AI-generated text requires careful refinement to achieve its final form.</p></li>
<li><p>The refinement phase is where human judgment becomes paramount. Authors must shape the AI-generated content to maintain consistent voice, ensure logical flow, and preserve the book’s core purpose. This requires understanding nuances of audience expectations and subject matter that current AI systems cannot fully grasp.</p></li>
</ol>
<p>This iterative process of generation and refinement continues until the project achieves its goals - another judgment that requires human evaluation. The result is neither purely AI-generated nor traditionally human-authored, but rather a new form of hybrid creativity that leverages the strengths of both.</p>
<p>The role of books may evolve, but their fundamental purpose - to present structured, focused exploration of subjects - will always be valuable. The challenge for authors is not to compete with AI’s raw generative capabilities, but to use them effectively while maintaining the human elements that give books their lasting value.</p>
<p>This suggests a future where successful authors are those who master the art of AI collaboration rather than resist it. Just as modern architects must understand both traditional design principles and computer-aided tools, tomorrow’s authors will need to balance classic writing skills with AI capabilities.</p>
<p>The key question is no longer whether AI will replace human authors, but how it will transform the authorship process. The answer lies in recognizing that while AI can move mountains of words, humans must still decide which mountains to move and how to shape the resulting landscape.</p>
<p>This transformation parallels broader changes in knowledge work. As AI handles more routine cognitive tasks, human value increasingly derives from higher-order skills like judgment, creativity, and strategic thinking. The future of authorship, like many professional fields, will belong to those who can effectively combine human insight with AI capabilities.</p>
<p>The rise of AI authors doesn’t diminish the value of books but rather changes how they’re created. The essential human elements - purpose, judgment, refinement - remain crucial, even as AI dramatically expands our capability to generate and process information. The result may be not just better books, but new forms of knowledge sharing that we’re only beginning to imagine.</p>
</section>
</section>
<section id="more-examples" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="more-examples"><span class="header-section-number">3.5</span> More examples</h2>
<section id="software-development-beyond-code-generation" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="software-development-beyond-code-generation"><span class="header-section-number">3.5.1</span> Software Development: Beyond Code Generation</h3>
<p>The construction industry provides useful analogies for understanding AI’s impact on software development. Just as modern construction sites use both automated machinery and skilled human workers, software development is evolving into a hybrid process where AI handles routine coding tasks while humans focus on architecture and design decisions.</p>
<p>Consider a typical software project. Traditional development required writing every line of code manually, like building a house brick by brick. Now, AI coding assistants like GitHub Copilot or Amazon CodeWhisperer can generate entire functions or modules automatically, similar to how prefabricated components accelerated construction. These AI tools excel at producing standard elements - authentication systems, database queries, API endpoints - just as manufacturing automation excels at producing standardized building materials.</p>
<p>However, like construction projects, software development involves more than assembling standard components. A successful project requires understanding user needs, designing intuitive interfaces, ensuring security, and maintaining long-term reliability. These higher-level decisions remain firmly in human territory.</p>
<p>The architectural parallel is particularly apt. Just as architects must consider aesthetics, functionality, and structural integrity, software architects must balance user experience, system performance, and code maintainability. AI can suggest implementation details, but it cannot determine whether a feature aligns with business goals or how it might affect user behavior.</p>
<p>Technical debt offers another illuminating comparison. In construction, taking shortcuts (like using lower-grade materials) can speed completion but creates future maintenance problems. Similarly, in software development, quick fixes and temporary solutions accumulate as technical debt. While AI can identify potential debt and suggest refactoring strategies, humans must weigh the business tradeoffs of addressing it now versus later.</p>
<p>Integration challenges further highlight AI’s limitations. Modern software systems are complex ecosystems of interacting components, like cities with interconnected infrastructure systems. AI excels at optimizing individual components but struggles to understand system-wide implications. Humans must orchestrate these interactions, ensuring different parts work together coherently while maintaining system reliability and performance.</p>
<p>Security considerations demonstrate another crucial human role. Like building security systems, software security requires anticipating potential threats and implementing appropriate protections. AI can identify common vulnerabilities and suggest fixes, but it cannot understand the broader security context or evaluate risk tradeoffs. These decisions require human judgment informed by business context and threat assessment.</p>
<p>The testing and quality assurance phase reveals both AI’s strengths and limitations. AI tools can automatically generate test cases and identify potential bugs, similar to automated building inspections. However, human testers are still essential for evaluating user experience, identifying edge cases, and ensuring the software meets business requirements. AI can verify that code works as written, but humans must verify it works as intended.</p>
<p>Looking ahead, successful software development will likely become increasingly collaborative between humans and AI. Development teams will need to master new workflows that leverage AI’s capabilities while maintaining human oversight of critical decisions. This might involve using AI for initial code generation and routine maintenance while focusing human effort on architecture, security, and user experience.</p>
<p>This evolution parallels broader trends in professional work. Just as power tools didn’t eliminate the need for skilled carpenters but changed how they work, AI won’t eliminate software developers but will transform their role. The most valuable developers will be those who can effectively direct AI tools while maintaining high-level system understanding.</p>
<p>The implications for software education and training are significant. Future developers will need less emphasis on memorizing syntax and more focus on system design, architecture, and AI collaboration skills. This mirrors how modern architectural education focuses less on manual drafting and more on design principles and computer-aided tools.</p>
<p>However, the fundamental role of human creativity and judgment remains unchanged. Just as beautiful buildings require human vision despite advanced construction technology, great software requires human insight despite sophisticated AI tools. The key is understanding AI as an enabler of human creativity rather than its replacement.</p>
<p>This suggests that software development is entering a new phase where success depends on effectively combining AI capabilities with human insight. The future belongs not to those who can code fastest, but to those who can best envision how technology can serve human needs while using AI to implement that vision efficiently and reliably.</p>
<p>In this new paradigm, the measure of a developer shifts from lines of code written to the effectiveness of their human-AI collaboration in creating valuable software solutions. The construction industry’s evolution from manual labor to machine-assisted craftsmanship provides a roadmap for this transformation.</p>
</section>
<section id="investment-analysis-beyond-the-numbers" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="investment-analysis-beyond-the-numbers"><span class="header-section-number">3.5.2</span> Investment Analysis: Beyond the Numbers</h3>
<p>Just as modern factories use automation for routine manufacturing while relying on human expertise for product design and quality control, investment analysis is evolving into a hybrid process where AI handles data processing while humans focus on strategic insights and judgment calls.</p>
<p>Consider a typical investment analysis project. Traditionally, analysts spent countless hours gathering financial data, creating comparison spreadsheets, and writing preliminary reports. Now, AI can instantly process quarterly reports, generate peer comparisons, and draft initial analyses. This is similar to how automated assembly lines handle routine manufacturing tasks, freeing human workers to focus on complex problems requiring judgment and creativity.</p>
<p>However, like manufacturing, successful investing involves more than processing standard inputs. While AI excels at identifying patterns in financial statements and market data, it struggles with crucial qualitative factors. Can management be trusted? Is the company’s competitive advantage sustainable? Will current market opportunities persist? These questions require human judgment informed by experience and industry knowledge.</p>
<p>The manufacturing quality control parallel is particularly relevant. Just as experienced inspectors can spot subtle defects that automated systems miss, seasoned investors can identify red flags in management behavior or market dynamics that AI might overlook. A CEO’s body language during earnings calls, the timing of insider stock sales, or subtle shifts in competitive dynamics - these nuanced signals often prove more valuable than quantitative metrics.</p>
<p>Competitive analysis offers another illuminating comparison. In manufacturing, understanding market dynamics requires more than analyzing production statistics - it requires insight into changing consumer preferences, emerging technologies, and competitor strategies. Similarly, while AI can process vast amounts of market data, humans must evaluate whether a company’s competitive position is truly defensible and whether management’s strategy aligns with market realities.</p>
<p>The role of trust highlights another crucial human element. Just as manufacturing partnerships require trust built through personal relationships and demonstrated reliability, investment success often depends on accurately assessing management credibility. AI can flag inconsistencies in financial statements or unusual transaction patterns, but it cannot evaluate character or judge whether explanations for apparent irregularities are credible.</p>
<p>Market opportunity assessment demonstrates similar limitations. Like evaluating new manufacturing technologies, assessing market opportunities requires understanding both technical capabilities and human behavior. AI can analyze historical market data and identify trends, but it cannot predict how human customers, competitors, and regulators will react to new situations. These predictions require human insight into psychology and social dynamics.</p>
<p>Risk assessment reveals both AI’s strengths and limitations. AI systems can quickly identify common risk factors and calculate standard metrics, similar to automated safety systems in manufacturing. However, the most significant risks often come from unexpected directions that don’t appear in historical data. Human judgment remains essential for identifying and evaluating these non-obvious risks.</p>
<p>Looking ahead, successful investment analysis will likely become increasingly collaborative between humans and AI. Analysis teams will need to master new workflows that leverage AI’s data processing capabilities while maintaining human oversight of critical judgments. This might involve using AI for initial screening and routine monitoring while focusing human effort on qualitative assessment and strategic thinking.</p>
<p>This evolution parallels broader trends in professional work. Just as automation didn’t eliminate the need for skilled manufacturing workers but changed their role, AI won’t eliminate investment analysts but will transform how they work. The most valuable analysts will be those who can effectively direct AI tools while maintaining deep industry understanding and judgment capabilities.</p>
<p>The implications for investment education and training are significant. Future analysts will need less emphasis on spreadsheet skills and more focus on business judgment and AI collaboration capabilities. This mirrors how modern manufacturing education focuses less on manual skills and more on process management and technology integration.</p>
<p>However, the fundamental role of human judgment remains unchanged. Just as quality manufacturing requires human oversight despite advanced automation, successful investing requires human insight despite sophisticated AI tools. The key is understanding AI as an enhancer of human judgment rather than its replacement.</p>
<p>This suggests that investment analysis is entering a new phase where success depends on effectively combining AI capabilities with human insight. The future belongs not to those who can process data fastest, but to those who can best understand business fundamentals while using AI to implement that understanding efficiently and reliably.</p>
<p>In this new paradigm, the measure of an analyst shifts from computational speed to the effectiveness of their human-AI collaboration in identifying truly attractive investments. The manufacturing industry’s evolution from manual production to technology-enhanced craftsmanship provides a roadmap for this transformation.</p>
</section>
<section id="ai-and-healthcare-beyond-pattern-recognition" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="ai-and-healthcare-beyond-pattern-recognition"><span class="header-section-number">3.5.3</span> AI and Healthcare: Beyond Pattern Recognition</h3>
<p>The evolution of AI in healthcare parallels modern manufacturing quality control, where automated systems handle routine inspections while skilled technicians focus on complex problems requiring human judgment. Similarly, healthcare is becoming a hybrid system where AI processes medical data while human doctors focus on patient relationships and complex medical decisions.</p>
<p>Consider a typical diagnostic process. Traditionally, doctors spent considerable time reviewing test results, consulting medical literature, and documenting findings. Now, AI can instantly analyze lab results, medical images, and patient histories to suggest potential diagnoses. This is similar to how automated inspection systems quickly identify defects in manufactured products, allowing human inspectors to focus on more complex quality issues.</p>
<p>However, like quality control, successful healthcare involves more than pattern recognition. While AI excels at identifying anomalies in test results and suggesting standard treatments, it struggles with crucial contextual factors. How will a patient’s living situation affect treatment adherence? Which side effects are acceptable given a patient’s lifestyle? What treatment modifications are needed given other health conditions? These questions require human judgment informed by direct patient interaction and medical experience.</p>
<p>The empathy factor is particularly relevant. Just as effective quality control requires understanding how products will be used in real-world conditions, effective healthcare requires understanding patients’ lives and concerns. AI can process medical histories and suggest treatment protocols, but it cannot truly empathize with patient fears or understand how cultural and personal factors might affect treatment success.</p>
<p>Treatment customization offers another illuminating comparison. In manufacturing, standard quality metrics must often be adjusted for specific use cases. Similarly, while AI can recommend standard treatments based on medical literature, doctors must adapt these recommendations to individual patient circumstances. A treatment protocol that looks optimal on paper might be impractical or inappropriate given a patient’s specific situation.</p>
<p>The trust relationship highlights another crucial human element. Just as manufacturing quality depends on trust between suppliers and customers, healthcare outcomes often depend on patient trust in their medical providers. AI can provide accurate medical information, but it cannot build the personal trust that encourages treatment compliance and honest symptom reporting.</p>
<p>Emergency response demonstrates both AI’s strengths and limitations. AI systems can quickly process vital signs and suggest immediate interventions, similar to automated safety systems in manufacturing. However, emergency medicine often requires split-second decisions based on incomplete information and complex tradeoffs. Human judgment remains essential for these high-stakes decisions where standard protocols may not apply.</p>
<p>Looking ahead, successful healthcare will likely become increasingly collaborative between humans and AI. Medical teams will need to master new workflows that leverage AI’s analytical capabilities while maintaining human oversight of critical decisions. This might involve using AI for initial screening and routine monitoring while focusing human effort on patient interaction and complex case management.</p>
<p>This evolution parallels broader trends in professional work. Just as automation didn’t eliminate the need for skilled quality control technicians but changed their role, AI won’t eliminate doctors but will transform how they work. The most valuable healthcare providers will be those who can effectively direct AI tools while maintaining strong patient relationships and clinical judgment.</p>
<p>The implications for medical education and training are significant. Future doctors will need less emphasis on memorizing medical facts and more focus on patient communication and AI collaboration skills. This mirrors how modern quality control training focuses less on inspection procedures and more on system management and problem-solving.</p>
<p>However, the fundamental role of human judgment remains unchanged. Just as quality control requires human oversight despite advanced inspection technology, healthcare requires human insight despite sophisticated AI tools. The key is understanding AI as an enhancer of medical judgment rather than its replacement.</p>
<p>This suggests that healthcare is entering a new phase where success depends on effectively combining AI capabilities with human insight. The future belongs not to those who can recall the most medical facts, but to those who can best understand patient needs while using AI to implement that understanding efficiently and safely.</p>
<p>In this new paradigm, the measure of a healthcare provider shifts from diagnostic speed to the effectiveness of their human-AI collaboration in achieving optimal patient outcomes. The quality control industry’s evolution from manual inspection to technology-enhanced oversight provides a roadmap for this transformation.</p>
<p>The challenge ahead is not whether to adopt AI in healthcare, but how to integrate it while preserving the human elements that make medicine effective. Success will require understanding both AI’s capabilities and its limitations, while never losing sight of healthcare’s fundamental mission: helping human patients achieve better health outcomes through personalized, compassionate care.</p>
</section>
</section>
<section id="investment-implications" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="investment-implications"><span class="header-section-number">3.6</span> Investment Implications</h2>
<p>This shift has important implications for investors:</p>
<p><strong>Winners</strong>: - Companies that help humans make better “what” decisions - Tools that augment human judgment rather than replace it - Platforms that combine AI capabilities with human insight - Businesses with strong human judgment at their core</p>
<p><strong>Losers</strong>: - Pure automation plays that don’t preserve human judgment - Companies selling commoditized “how” skills - Businesses that can’t articulate their human advantage</p>
</section>
<section id="the-future-of-work" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="the-future-of-work"><span class="header-section-number">3.7</span> The Future of Work</h2>
<p>This transition suggests several changes in how organizations will operate:</p>
<p><strong>New Organizational Structures</strong></p>
<ul>
<li>Flatter hierarchies as AI handles routine coordination</li>
<li>Smaller, more senior teams focused on “what” decisions</li>
<li>Greater emphasis on judgment and strategic thinking</li>
</ul>
<p><strong>Changed Skill Requirements</strong></p>
<ul>
<li>Less focus on technical tool proficiency</li>
<li>More emphasis on strategic thinking and judgment</li>
<li>Greater value placed on cross-domain knowledge</li>
</ul>
<p><strong>Modified Training Approaches</strong></p>
<ul>
<li>Reduced time spent teaching technical “how” skills</li>
<li>Increased focus on judgment development</li>
<li>More emphasis on understanding human factors</li>
</ul>
</section>
<section id="preparing-for-the-transition" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="preparing-for-the-transition"><span class="header-section-number">3.8</span> Preparing for the Transition</h2>
<p>For individuals and organizations looking to succeed in this new environment, several approaches make sense:</p>
<p><strong>For Individuals</strong>:</p>
<ul>
<li>Focus on developing judgment through varied experiences</li>
<li>Build broad knowledge across multiple domains</li>
<li>Practice making and learning from strategic decisions</li>
<li>Get comfortable with ambiguity and uncertainty</li>
</ul>
<p><strong>For Organizations</strong>:</p>
<ul>
<li>Invest in tools that augment human judgment</li>
<li>Develop processes that capture and share strategic insights</li>
<li>Create cultures that value and develop good judgment</li>
<li>Build teams with diverse perspectives and experiences</li>
</ul>
<section id="the-human-element-remains-central" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="the-human-element-remains-central"><span class="header-section-number">3.8.1</span> The Human Element Remains Central</h3>
<p>It’s crucial to remember that this shift doesn’t diminish the importance of human contribution - it actually elevates it. As AI handles more routine tasks, human judgment, creativity, and wisdom become more valuable, not less.</p>
<p>Consider the example of chess: Despite AI systems being able to beat any human player, human chess hasn’t disappeared. Instead, it’s evolved. The most interesting matches now involve human-AI collaboration, where success depends on humans knowing what positions to play for and when to trust or override AI suggestions.</p>
<p>This pattern will likely repeat across many fields - the key to success will be understanding what humans do best and creating systems that augment these capabilities rather than try to replace them.</p>
</section>
</section>
<section id="looking-ahead" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="looking-ahead"><span class="header-section-number">3.9</span> Looking Ahead</h2>
<p>The transition from “how” to “what” won’t happen overnight, but it’s already underway. Organizations and individuals that recognize and adapt to this shift will have significant advantages. Those that continue to focus primarily on “how” skills risk finding their capabilities increasingly commoditized by AI.</p>
<p>This shift also suggests we need to rethink education and training. Rather than focusing primarily on teaching technical skills that AI might soon handle, we should emphasize developing judgment, creativity, and strategic thinking - the fundamentally human capabilities that will become increasingly valuable.</p>
<p>The future belongs not to those who can execute tasks most efficiently, but to those who can best decide what tasks are worth doing in the first place.</p>
<p>In the early days of the personal computer revolution, spreadsheet software transformed financial analysis. Critics warned that tools like VisiCalc and Lotus 1-2-3 would eliminate financial analysts by automating their calculations. Instead, these tools dramatically increased productivity while shifting analysts’ focus from mathematical computation to business insight. Today’s artificial intelligence is driving a similar transformation, but at a far greater scale and across virtually every knowledge-based profession.</p>
<div id="fig-what-how-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-what-how-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="_resources/images/Ch03-images/what-how-matrix.svg" alt="What-How Matrix" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-what-how-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1
</figcaption>
</figure>
</div>
</section>
<section id="beyond-the-false-binary" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="beyond-the-false-binary"><span class="header-section-number">3.10</span> Beyond the False Binary</h2>
<p>The current discourse on AI’s impact falls into a tiresome and inaccurate binary: either AI will replace human workers entirely, or its effects will be marginal. Both narratives miss the fundamental transformation underway. What we’re witnessing is not wholesale replacement but a profound shift in the nature of human contribution—a redistribution of value across the knowledge work spectrum that redefines which human capabilities command a premium.</p>
<p>This transformation becomes apparent when we distinguish between two fundamental aspects of any intellectual task: determining <em>what</em> needs to be done versus executing <em>how</em> to do it. This distinction, while seemingly straightforward, carries profound implications for the future of work, business strategy, and investment that extend far beyond the simplistic replacement narrative dominating public discourse.</p>
<p>The what-how framework offers remarkable clarity amid the confusing narratives surrounding AI. It helps explain why certain cognitive tasks are rapidly becoming commoditized while others remain stubbornly resistant to automation. More importantly, it provides a roadmap for individuals, organizations, and policymakers navigating a landscape where artificial intelligence increasingly pervades knowledge work.</p>
</section>
<section id="the-nature-of-the-divide" class="level2" data-number="3.11">
<h2 data-number="3.11" class="anchored" data-anchor-id="the-nature-of-the-divide"><span class="header-section-number">3.11</span> The Nature of the Divide</h2>
<p>Until the arrival of generative AI, individuals gained professional advantages through superior “how” skills—they excelled at crafting compelling presentations, building complex spreadsheets, writing efficient code, or translating between languages. These implementation abilities represented valuable skills that could be developed and applied on behalf of those who determined <em>what</em> needed to be done.</p>
<p>In traditional organizational hierarchies, executives and managers typically decide <em>what</em> initiatives to pursue, while specialized knowledge workers determine <em>how</em> to execute them. This division has historically functioned efficiently because <em>how</em> expertise—whether in financial modeling, software development, or content creation—required significant investment in learning specialized tools and methodologies.</p>
<p>The emergence of sophisticated AI systems fundamentally alters this equation. Large language models demonstrate remarkable proficiency in implementation tasks, often exceeding human capabilities in narrow domains. They can generate code, compose business communications, create visual assets, and perform complex analyses with minimal human guidance. These systems excel precisely in the domain of <em>how</em>—the execution of well-defined tasks within established parameters.</p>
<p>What these systems cannot do—and what remains uniquely human—is determine <em>what</em> is worth doing in the first place. They cannot independently identify which problems merit attention, which strategies align with organizational values, or which approaches will resonate with stakeholders. They lack the contextual understanding, ethical framework, and strategic vision required to make these determinations.</p>
<p>Consider the financial analyst whose value traditionally derived from technical modeling skills. As AI systems increasingly automate complex financial calculations, the analyst’s competitive advantage shifts toward identifying which factors merit analysis, which comparisons yield strategic insights, and how findings translate into investment decisions. The technical implementation—the <em>how</em>—becomes commoditized, while judgment about <em>what</em> to analyze becomes the primary value driver.</p>
<p>This pattern repeats across knowledge work domains. In marketing, AI can generate endless variations of campaign materials, but cannot determine which messaging will align with brand values and audience expectations. In software development, AI can produce functional code based on specifications but cannot identify which features will deliver genuine user value. In healthcare, AI can analyze diagnostic images with remarkable accuracy but cannot integrate these findings with the full context of patient well-being.</p>
</section>
<section id="philosophical-dimensions-of-the-divide" class="level2" data-number="3.12">
<h2 data-number="3.12" class="anchored" data-anchor-id="philosophical-dimensions-of-the-divide"><span class="header-section-number">3.12</span> Philosophical Dimensions of the Divide</h2>
<p>The what-how divide resonates with deeper philosophical questions about the nature of intelligence and agency. Martin Heidegger, whose work we explore more fully in Chapter 4, offers particularly relevant insights through his concept of “comportments”—the way humans face and engage with the world around them.</p>
<p>When we are deeply engaged in an activity—skillfully driving a car, playing an instrument, or writing code—we are not consciously thinking about the mechanics of these actions. Our focus extends beyond the immediate task to its purpose and meaning within our broader existence. The ultimate comportment, Heidegger suggests, is our orientation toward being itself, which encompasses our understanding of past, present, and future.</p>
<p>Artificial intelligence systems, even sophisticated ones like GPT-4 or Claude, lack these comportments. They process information without any inherent purpose or temporal orientation. They can mimic human-like outputs but have no concept of why these outputs matter or how they fit into broader human concerns. This philosophical distinction manifests practically in AI’s inability to determine <em>what</em> is worth doing independent of human direction.</p>
<p>The what-how divide thus represents more than a practical delineation of tasks; it reflects a fundamental distinction between human and artificial intelligence. While AI excels at executing well-defined processes—the <em>how</em>—it cannot engage with the existential questions of purpose and meaning that inform human decisions about <em>what</em> deserves attention.</p>
<p>This philosophical perspective helps explain why LLMs struggle with certain seemingly simple tasks, as we demonstrated in prior chapters. Tasks that require constant re-evaluation and adjustment based on evolving goals—like writing a sentence that accurately describes its own length or completing a Sudoku puzzle—reveal the fundamental limitations of systems that cannot backtrack or reconsider their approach once they’ve begun generating outputs.</p>
</section>
<section id="case-studies-the-divide-in-practice" class="level2" data-number="3.13">
<h2 data-number="3.13" class="anchored" data-anchor-id="case-studies-the-divide-in-practice"><span class="header-section-number">3.13</span> Case Studies: The Divide in Practice</h2>
<p>To illustrate the what-how divide, let’s examine several domains where this transformation is particularly evident:</p>
<section id="software-development" class="level3" data-number="3.13.1">
<h3 data-number="3.13.1" class="anchored" data-anchor-id="software-development"><span class="header-section-number">3.13.1</span> Software Development</h3>
<p>Traditional programming expertise focused heavily on implementation details—mastering specific languages, frameworks, and architectural patterns. While these technical skills remain valuable, AI code generation tools increasingly automate routine implementation tasks. The premium shifts toward determining which features will deliver value, how systems should interact with users, and what architectural decisions will support long-term business objectives.</p>
<p>Senior developers report that junior programmers who once spent years mastering syntax and debugging techniques now leverage AI assistants to handle these aspects, allowing them to focus earlier in their careers on higher-level system design and user experience considerations—traditionally the domain of more experienced developers.</p>
<p>This shift alters the career progression trajectory for software engineers. Technical implementation skills remain necessary but insufficient; they must be paired with strategic judgment about what deserves implementation in the first place. Engineers who maintain purely technical focus without developing this broader perspective may find their competitive position eroding as AI systems increasingly automate routine coding tasks.</p>
</section>
<section id="content-creation" class="level3" data-number="3.13.2">
<h3 data-number="3.13.2" class="anchored" data-anchor-id="content-creation"><span class="header-section-number">3.13.2</span> Content Creation</h3>
<p>In media and marketing, AI systems now generate remarkably coherent and stylistically appropriate content at scale. The limiting factor is no longer production capacity but strategic direction—determining which messages will resonate with target audiences, which topics deserve attention, and how content aligns with broader brand narratives.</p>
<p>Marketing executives evaluating AI writing assistants frequently report that while these tools can “automatically compose email replies,” users typically spend as much time editing these drafts as they would creating responses from scratch. The real value emerges when humans with deep customer knowledge direct these tools toward specific strategic objectives.</p>
<p>This transformation extends beyond business communication to creative fields. As we explored with the AI-generated completion of Beethoven’s unfinished tenth symphony, technical proficiency alone cannot replicate the ineffable quality that distinguishes truly meaningful creative work. As music critic Jan Swafford observed, “We humans need to see the human doing it.” The value derives not just from the output itself but from knowing it represents authentic human struggle, insight, and purpose.</p>
</section>
<section id="healthcare" class="level3" data-number="3.13.3">
<h3 data-number="3.13.3" class="anchored" data-anchor-id="healthcare"><span class="header-section-number">3.13.3</span> Healthcare</h3>
<p>Medical diagnostic systems increasingly match or exceed human performance in analyzing medical images, identifying patterns in patient data, and suggesting potential diagnoses. Yet these systems cannot determine which factors are most relevant for a particular patient, how to weigh complex trade-offs between treatment options, or how to communicate findings in ways that respect patient values and preferences.</p>
<p>A physician whose only skill is knowing <em>how</em> to diagnose a patient’s condition is becoming less necessary. The crucial human contribution shifts toward determining <em>what</em> aspects of patient wellbeing deserve priority, which treatment approaches align with patient values, and how to integrate medical insights with broader quality-of-life considerations.</p>
<p>This shift carries significant implications for medical education and practice. Technical diagnostic skills remain essential but must increasingly be paired with heightened capabilities for integrative judgment, ethical reasoning, and communication. The most effective healthcare practitioners of the future will leverage AI for routine analytical tasks while focusing their human expertise on the complex judgments that machines cannot make.</p>
</section>
</section>
<section id="the-competitive-dynamics-of-the-divide" class="level2" data-number="3.14">
<h2 data-number="3.14" class="anchored" data-anchor-id="the-competitive-dynamics-of-the-divide"><span class="header-section-number">3.14</span> The Competitive Dynamics of the Divide</h2>
<p>The what-how framework carries significant implications for competitive strategy across industries. As implementation capabilities become increasingly commoditized through AI, sustainable competitive advantage shifts toward superior judgment about what deserves implementation in the first place.</p>
<p>This dynamic particularly challenges organizations that have traditionally derived their advantage primarily from superior execution. When AI systems can implement strategies with comparable efficiency across competitors, the primary differentiator becomes the quality of strategic judgment guiding that implementation. Organizations must evolve their capabilities accordingly, developing institutional capacity for the complex judgments that remain resistant to automation.</p>
<p>We see this pattern emerging in investment management, where quantitative analysis tools have become increasingly sophisticated and widely available. The differentiator for successful investment firms shifts toward superior judgment about which factors merit analysis, which market signals deserve attention, and how various considerations should be weighted in decision-making.</p>
<p>Similarly, in management consulting, the technical aspects of data analysis and presentation—traditionally key components of the service offering—are increasingly automated. The value proposition shifts toward helping clients determine which problems deserve attention, which approaches align with organizational values, and how various factors should be prioritized.</p>
<p>For technology companies specifically, the what-how framework offers valuable guidance for product development. The most successful AI implementations enhance rather than replace human judgment, allowing people to focus on the high-value <em>what</em> decisions where they maintain a durable advantage. Products that merely automate implementation without facilitating better strategic decisions will struggle to deliver sustainable value.</p>
</section>
<section id="organizational-implications" class="level2" data-number="3.15">
<h2 data-number="3.15" class="anchored" data-anchor-id="organizational-implications"><span class="header-section-number">3.15</span> Organizational Implications</h2>
<p>This fundamental shift carries significant implications for how organizations approach talent development, operational structure, and competitive strategy. Companies that recognize and adapt to the what-how divide will establish sustainable advantages in an AI-enhanced economy.</p>
<p>First, talent development programs must evolve beyond technical training focused on implementation skills. While baseline technical literacy remains essential, organizations should invest more heavily in developing employees’ abilities to frame problems effectively, synthesize insights across domains, and make nuanced judgments that integrate technical, business, and ethical considerations.</p>
<p>The most valuable professional development initiatives will foster precisely those capabilities that remain distinctly human—contextual understanding, strategic synthesis, and ethical judgment. This represents a significant departure from traditional approaches that emphasize mastery of specific tools and methodologies.</p>
<p>Second, workflow design should consciously separate strategic decisions from implementation details, creating clear interfaces between human judgment and AI execution. This approach maintains appropriate human oversight while leveraging AI’s capabilities for rapid, consistent implementation.</p>
<p>Effective workflow design requires careful consideration of where human judgment adds the most value. Rather than automating entire processes end-to-end, organizations should identify the critical decision points where human judgment remains essential and design workflows that explicitly incorporate this judgment while automating surrounding implementation steps.</p>
<p>Third, organizational structures should evolve to emphasize roles that combine domain expertise with AI literacy. The traditional separation between business strategists and technical implementers becomes less valuable as AI systems increasingly bridge this gap. New hybrid roles will emerge that focus on translating business objectives into effective AI implementation approaches.</p>
<p>This structural evolution may require reconsidering traditional career paths and reporting relationships. Organizations that maintain rigid distinctions between technical and strategic roles may struggle to develop the integrated capabilities needed for effective human-AI collaboration.</p>
</section>
<section id="investment-implications-1" class="level2" data-number="3.16">
<h2 data-number="3.16" class="anchored" data-anchor-id="investment-implications-1"><span class="header-section-number">3.16</span> Investment Implications</h2>
<p>For investors, the what-how framework offers valuable guidance for evaluating AI-related opportunities. Companies positioned to win in this environment include those that:</p>
<ol type="1">
<li>Develop tools that enhance human strategic thinking rather than merely automating implementation tasks</li>
<li>Create platforms that facilitate seamless collaboration between human judgment and AI execution</li>
<li>Build solutions that maintain appropriate human oversight while leveraging AI capabilities</li>
<li>Design business models that recognize and reward uniquely human contributions</li>
</ol>
<p>By contrast, companies that focus exclusively on automation without considering the continued importance of human judgment will likely struggle to deliver sustainable value. The most successful AI implementations will be those that augment rather than replace human capabilities, allowing people to focus on the high-value <em>what</em> decisions where they maintain a durable advantage.</p>
<p>This perspective offers a useful corrective to the common investor tendency to overvalue pure automation plays. The history of technology adoption suggests that approaches that enhance rather than replace human capabilities typically deliver more sustainable value over time.</p>
</section>
<section id="the-evolution-of-knowledge-work" class="level2" data-number="3.17">
<h2 data-number="3.17" class="anchored" data-anchor-id="the-evolution-of-knowledge-work"><span class="header-section-number">3.17</span> The Evolution of Knowledge Work</h2>
<p>As AI capabilities continue to evolve, we can anticipate further shifts in the relative value of different forms of human contribution. Implementation skills—the <em>how</em>—will continue to be commoditized, while strategic judgment—the <em>what</em>—will command an increasing premium. This doesn’t mean implementation expertise becomes irrelevant, but rather that it must be paired with higher-level strategic capabilities to remain valuable.</p>
<p>For individual knowledge workers, this suggests a clear direction for professional development. Rather than focusing exclusively on technical mastery within narrow domains, sustainable career advancement will require developing broader strategic capabilities: understanding stakeholder needs, synthesizing insights across disciplines, and making nuanced judgments that integrate technical, business, and ethical considerations.</p>
<p>For educational institutions, the what-how divide suggests the need for fundamental curriculum redesign. Traditional education systems heavily emphasize <em>how</em> skills—teaching specific methodologies, tools, and techniques. Future-oriented education should place greater emphasis on developing students’ abilities to frame problems effectively, think across disciplinary boundaries, and make contextual judgments that cannot be easily automated.</p>
<p>For policymakers, this framework offers a more nuanced understanding of AI’s impact on employment and economic opportunity. Rather than focusing exclusively on potential job displacement, policy approaches should consider how to facilitate the transition toward work that emphasizes uniquely human strategic capabilities while ensuring that the benefits of AI-driven productivity gains are broadly shared.</p>
</section>
<section id="integration-with-enhancement-thesis" class="level2" data-number="3.18">
<h2 data-number="3.18" class="anchored" data-anchor-id="integration-with-enhancement-thesis"><span class="header-section-number">3.18</span> Integration with Enhancement Thesis</h2>
<p>The what-how framework aligns perfectly with our core thesis that AI will enhance rather than replace human capabilities across industries. By automating routine implementation tasks, AI frees human cognitive capacity for higher-level strategic thinking—the domain where human judgment maintains a durable advantage. This represents not replacement but enhancement of human potential.</p>
<p>This perspective also explains why purely automated approaches often disappoint. When AI systems operate without appropriate human direction and oversight, they may execute flawlessly within their parameters while completely missing the broader context that gives their outputs meaning and value. The most successful implementations maintain humans “in the loop” precisely because human judgment about <em>what</em> matters cannot be delegated to automated systems.</p>
<p>Consider full self-driving technology, which we’ll explore more fully in later chapters. Companies like Tesla have collected unprecedented amounts of driving data and developed increasingly sophisticated systems for navigating complex environments. Yet as robotics pioneer Rodney Brooks has observed, these systems still struggle with the contextual judgment that experienced human drivers exercise effortlessly.</p>
<p>A human driver approaching a neighborhood with cars parked tightly on both sides naturally slows down, recognizing the increased risk of children darting into the street. This judgment doesn’t derive from explicit rules but from a holistic understanding of context that integrates multiple factors—some explicit, others tacit. Autonomous systems may eventually replicate this behavior through sophisticated pattern recognition, but they cannot independently determine which factors deserve attention without human direction.</p>
</section>
<section id="conclusion-navigating-the-transformation" class="level2" data-number="3.19">
<h2 data-number="3.19" class="anchored" data-anchor-id="conclusion-navigating-the-transformation"><span class="header-section-number">3.19</span> Conclusion: Navigating the Transformation</h2>
<p>The what-how divide provides a powerful framework for understanding AI’s true impact on knowledge work and business strategy. Rather than wholesale replacement, we’re witnessing a fundamental shift in the nature of human contribution—from executing well-defined tasks to making strategic judgments about what deserves attention and how different considerations should be weighed.</p>
<p>This transformation presents both challenges and opportunities. Organizations and individuals that continue to focus exclusively on implementation skills will find their competitive position eroding as AI systems increasingly automate these functions. Those who develop the strategic judgment to determine <em>what</em> is worth doing—and the ability to direct AI systems effectively toward these ends—will thrive in an AI-enhanced economy.</p>
<p>The what-how framework aligns with our broader thesis that successful AI implementation requires keeping humans “in the loop.” Not because of temporary technical limitations that will eventually be overcome, but because of fundamental differences between human and artificial intelligence. The most valuable human contributions have always involved more than technical execution—they reflect purpose, meaning, and judgment that remain uniquely human even as AI capabilities advance.</p>
<p>In the next chapter, we’ll explore these philosophical dimensions more deeply, examining why understanding the nature of human intelligence is crucial for designing effective human-AI collaborations. By recognizing both the capabilities and limitations of artificial intelligence, we can develop approaches that truly enhance human potential rather than attempting to replace it.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abdin_phi-3_2024" class="csl-entry" role="listitem">
Abdin, Marah, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, et al. 2024. <span>“Phi-3 <span>Technical</span> <span>Report</span>: <span>A</span> <span>Highly</span> <span>Capable</span> <span>Language</span> <span>Model</span> <span>Locally</span> on <span>Your</span> <span>Phone</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.14219">http://arxiv.org/abs/2404.14219</a>.
</div>
<div id="ref-ai_yi_2024" class="csl-entry" role="listitem">
AI, 01, Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, et al. 2024. <span>“Yi: <span>Open</span> <span>Foundation</span> <span>Models</span> by 01.<span>AI</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.04652">http://arxiv.org/abs/2403.04652</a>.
</div>
<div id="ref-alamdari_protein_2023" class="csl-entry" role="listitem">
Alamdari, Sarah, Nitya Thakkar, Rianne Van Den Berg, Alex Xijie Lu, Nicolo Fusi, Ava Pardis Amini, and Kevin K Yang. 2023. <span>“Protein Generation with Evolutionary Diffusion: Sequence Is All You Need.”</span> Preprint. Bioengineering. <a href="https://doi.org/10.1101/2023.09.11.556673">https://doi.org/10.1101/2023.09.11.556673</a>.
</div>
<div id="ref-bender_dangers_2021" class="csl-entry" role="listitem">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>“On the <span>Dangers</span> of <span>Stochastic</span> <span>Parrots</span>: <span>Can</span> <span>Language</span> <span>Models</span> <span>Be</span> <span>Too</span> <span>Big</span>? 🦜.”</span> In <em>Proceedings of the 2021 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 610–23. Virtual Event Canada: ACM. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-berglund_reversal_2023" class="csl-entry" role="listitem">
Berglund, Lukas, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023. <span>“The <span>Reversal</span> <span>Curse</span>: <span>LLMs</span> Trained on "<span>A</span> Is <span>B</span>" Fail to Learn "<span>B</span> Is <span>A</span>".”</span> arXiv. <a href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a>.
</div>
<div id="ref-bsharat_principled_2023" class="csl-entry" role="listitem">
Bsharat, Sondos Mahmoud, Aidar Myrzakhan, and Zhiqiang Shen. 2023. <span>“Principled <span>Instructions</span> <span>Are</span> <span>All</span> <span>You</span> <span>Need</span> for <span>Questioning</span> <span>LLaMA</span>-1/2, <span>GPT</span>-3.5/4.”</span> arXiv. <a href="http://arxiv.org/abs/2312.16171">http://arxiv.org/abs/2312.16171</a>.
</div>
<div id="ref-burtch_consequences_2024" class="csl-entry" role="listitem">
Burtch, Gordon, Dokyun Lee, and Zhichen Chen. 2024. <span>“The Consequences of Generative <span>AI</span> for Online Knowledge Communities.”</span> <em>Scientific Reports</em> 14 (1): 10413. <a href="https://doi.org/10.1038/s41598-024-61221-0">https://doi.org/10.1038/s41598-024-61221-0</a>.
</div>
<div id="ref-butlin_consciousness_2023" class="csl-entry" role="listitem">
Butlin, Patrick, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, et al. 2023. <span>“Consciousness in <span>Artificial</span> <span>Intelligence</span>: <span>Insights</span> from the <span>Science</span> of <span>Consciousness</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2308.08708">https://doi.org/10.48550/ARXIV.2308.08708</a>.
</div>
<div id="ref-carlini_stealing_2024" class="csl-entry" role="listitem">
Carlini, Nicholas, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, et al. 2024. <span>“Stealing <span>Part</span> of a <span>Production</span> <span>Language</span> <span>Model</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.06634">http://arxiv.org/abs/2403.06634</a>.
</div>
<div id="ref-chang_speak_2023" class="csl-entry" role="listitem">
Chang, Kent K., Mackenzie Cramer, Sandeep Soni, and David Bamman. 2023a. <span>“Speak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.00118">https://doi.org/10.48550/ARXIV.2305.00118</a>.
</div>
<div id="ref-chang_speak_2023-1" class="csl-entry" role="listitem">
———. 2023b. <span>“Speak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.”</span> arXiv. <a href="http://arxiv.org/abs/2305.00118">http://arxiv.org/abs/2305.00118</a>.
</div>
<div id="ref-de__fauw_clinically_2018" class="csl-entry" role="listitem">
De Fauw, Jeffrey, Joseph R. Ledsam, Bernardino Romera-Paredes, Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham, et al. 2018. <span>“Clinically Applicable Deep Learning for Diagnosis and Referral in Retinal Disease.”</span> <em>Nature Medicine</em> 24 (9): 1342–50. <a href="https://doi.org/10.1038/s41591-018-0107-6">https://doi.org/10.1038/s41591-018-0107-6</a>.
</div>
<div id="ref-di_palma_evaluating_2023" class="csl-entry" role="listitem">
Di Palma, Dario, Giovanni Maria Biancofiore, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia, and Eugenio Di Sciascio. 2023. <span>“Evaluating <span>ChatGPT</span> as a <span>Recommender</span> <span>System</span>: <span>A</span> <span>Rigorous</span> <span>Approach</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.03613">http://arxiv.org/abs/2309.03613</a>.
</div>
<div id="ref-dodge_documenting_2021" class="csl-entry" role="listitem">
Dodge, Jesse, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. <span>“Documenting <span>Large</span> <span>Webtext</span> <span>Corpora</span>: <span>A</span> <span>Case</span> <span>Study</span> on the <span>Colossal</span> <span>Clean</span> <span>Crawled</span> <span>Corpus</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2104.08758">https://doi.org/10.48550/ARXIV.2104.08758</a>.
</div>
<div id="ref-dreyfus_why_2007" class="csl-entry" role="listitem">
Dreyfus, Hubert L. 2007. <span>“Why <span>Heideggerian</span> <span>AI</span> <span>Failed</span> and <span>How</span> <span>Fixing</span> It <span>Would</span> <span>Require</span> <span>Making</span> It <span>More</span> <span>Heideggerian</span>.”</span> <em>Philosophical Psychology</em> 20 (2): 247–68. <a href="https://doi.org/10.1080/09515080701239510">https://doi.org/10.1080/09515080701239510</a>.
</div>
<div id="ref-epoch_ai_data_2024" class="csl-entry" role="listitem">
Epoch AI. 2024. <span>“Data on <span>Large</span> <span>Language</span> <span>AI</span> <span>Models</span>.”</span> <a href="https://epochai.org/data/large-scale-ai-models">https://epochai.org/data/large-scale-ai-models</a>.
</div>
<div id="ref-erdil_explosive_2024" class="csl-entry" role="listitem">
Erdil, Ege, and Tamay Besiroglu. 2024. <span>“Explosive Growth from <span>AI</span> Automation: <span>A</span> Review of the Arguments.”</span> arXiv. <a href="http://arxiv.org/abs/2309.11690">http://arxiv.org/abs/2309.11690</a>.
</div>
<div id="ref-esteva_guide_2019" class="csl-entry" role="listitem">
Esteva, Andre, Alexandre Robicquet, Bharath Ramsundar, Volodymyr Kuleshov, Mark DePristo, Katherine Chou, Claire Cui, Greg Corrado, Sebastian Thrun, and Jeff Dean. 2019. <span>“A Guide to Deep Learning in Healthcare.”</span> <em>Nature Medicine</em> 25 (1): 24–29. <a href="https://doi.org/10.1038/s41591-018-0316-z">https://doi.org/10.1038/s41591-018-0316-z</a>.
</div>
<div id="ref-feng_pretraining_2023" class="csl-entry" role="listitem">
Feng, Shangbin, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov. 2023. <span>“From <span>Pretraining</span> <span>Data</span> to <span>Language</span> <span>Models</span> to <span>Downstream</span> <span>Tasks</span>: <span>Tracking</span> the <span>Trails</span> of <span>Political</span> <span>Biases</span> <span>Leading</span> to <span>Unfair</span> <span>NLP</span> <span>Models</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.08283">https://doi.org/10.48550/ARXIV.2305.08283</a>.
</div>
<div id="ref-goh_large_2024" class="csl-entry" role="listitem">
Goh, Ethan, Robert Gallo, Jason Hom, Eric Strong, Yingjie Weng, Hannah Kerman, Joséphine A. Cool, et al. 2024. <span>“Large <span>Language</span> <span>Model</span> <span>Influence</span> on <span>Diagnostic</span> <span>Reasoning</span>: <span>A</span> <span>Randomized</span> <span>Clinical</span> <span>Trial</span>.”</span> <em>JAMA Network Open</em> 7 (10): e2440969. <a href="https://doi.org/10.1001/jamanetworkopen.2024.40969">https://doi.org/10.1001/jamanetworkopen.2024.40969</a>.
</div>
<div id="ref-grossmann_ai_2023" class="csl-entry" role="listitem">
Grossmann, Igor, Matthew Feinberg, Dawn C. Parker, Nicholas A. Christakis, Philip E. Tetlock, and William A. Cunningham. 2023. <span>“<span>AI</span> and the Transformation of Social Science Research.”</span> <em>Science</em> 380 (6650): 1108–9. <a href="https://doi.org/10.1126/science.adi1778">https://doi.org/10.1126/science.adi1778</a>.
</div>
<div id="ref-gupta_calm_2023" class="csl-entry" role="listitem">
Gupta, Vipul, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, and Rebecca J. Passonneau. 2023. <span>“<span>CALM</span> : <span>A</span> <span>Multi</span>-Task <span>Benchmark</span> for <span>Comprehensive</span> <span>Assessment</span> of <span>Language</span> <span>Model</span> <span>Bias</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a>.
</div>
<div id="ref-he_foundation_2024" class="csl-entry" role="listitem">
He, Yuting, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, and Hao Chen. 2024. <span>“Foundation <span>Model</span> for <span>Advancing</span> <span>Healthcare</span>: <span>Challenges</span>, <span>Opportunities</span>, and <span>Future</span> <span>Directions</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.03264">http://arxiv.org/abs/2404.03264</a>.
</div>
<div id="ref-hendy_how_2023" class="csl-entry" role="listitem">
Hendy, Amr, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. <span>“How <span>Good</span> <span>Are</span> <span>GPT</span> <span>Models</span> at <span>Machine</span> <span>Translation</span>? <span>A</span> <span>Comprehensive</span> <span>Evaluation</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2302.09210">http://arxiv.org/abs/2302.09210</a>.
</div>
<div id="ref-hicks_chatgpt_2024" class="csl-entry" role="listitem">
Hicks, Michael Townsen, James Humphries, and Joe Slater. 2024. <span>“<span>ChatGPT</span> Is Bullshit.”</span> <em>Ethics and Information Technology</em> 26 (2): 38. <a href="https://doi.org/10.1007/s10676-024-09775-5">https://doi.org/10.1007/s10676-024-09775-5</a>.
</div>
<div id="ref-hoffmann_training_2022" class="csl-entry" role="listitem">
Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <span>“Training <span>Compute</span>-<span>Optimal</span> <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2203.15556">http://arxiv.org/abs/2203.15556</a>.
</div>
<div id="ref-hopkins_artificial_2023" class="csl-entry" role="listitem">
Hopkins, Ashley M, Jessica M Logan, Ganessan Kichenadasse, and Michael J Sorich. 2023. <span>“Artificial Intelligence Chatbots Will Revolutionize How Cancer Patients Access Information: <span>ChatGPT</span> Represents a Paradigm-Shift.”</span> <em>JNCI Cancer Spectrum</em> 7 (2): pkad010. <a href="https://doi.org/10.1093/jncics/pkad010">https://doi.org/10.1093/jncics/pkad010</a>.
</div>
<div id="ref-hristidis_chatgpt_2023" class="csl-entry" role="listitem">
Hristidis, Vagelis, Nicole Ruggiano, Ellen L Brown, Sai Rithesh Reddy Ganta, and Selena Stewart. 2023. <span>“<span>ChatGPT</span> Vs <span>Google</span> for <span>Queries</span> <span>Related</span> to <span>Dementia</span> and <span>Other</span> <span>Cognitive</span> <span>Decline</span>: <span>Comparison</span> of <span>Results</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (July): e48966. <a href="https://doi.org/10.2196/48966">https://doi.org/10.2196/48966</a>.
</div>
<div id="ref-huang_propaganda_2013" class="csl-entry" role="listitem">
Huang, Haifeng, and Zhi Li. 2013. <span>“Propaganda and <span>Signaling</span>.”</span> <em>SSRN Electronic Journal</em>. <a href="https://doi.org/10.2139/ssrn.2325101">https://doi.org/10.2139/ssrn.2325101</a>.
</div>
<div id="ref-huang_crispr-gpt_2024" class="csl-entry" role="listitem">
Huang, Kaixuan, Yuanhao Qu, Henry Cousins, William A. Johnson, Di Yin, Mihir Shah, Denny Zhou, Russ Altman, Mengdi Wang, and Le Cong. 2024. <span>“<span>CRISPR</span>-<span>GPT</span>: <span>An</span> <span>LLM</span> <span>Agent</span> for <span>Automated</span> <span>Design</span> of <span>Gene</span>-<span>Editing</span> <span>Experiments</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.18021">http://arxiv.org/abs/2404.18021</a>.
</div>
<div id="ref-jackson_exposure_2023" class="csl-entry" role="listitem">
Jackson, Joshua Conrad, Kai Chi Yam, Pok Man Tang, Chris G. Sibley, and Adam Waytz. 2023. <span>“Exposure to Automation Explains Religious Declines.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (34): e2304748120. <a href="https://doi.org/10.1073/pnas.2304748120">https://doi.org/10.1073/pnas.2304748120</a>.
</div>
<div id="ref-jin_darkbert_2023" class="csl-entry" role="listitem">
Jin, Youngjin, Eugene Jang, Jian Cui, Jin-Woo Chung, Yongjae Lee, and Seungwon Shin. 2023. <span>“<span>DarkBERT</span>: <span>A</span> <span>Language</span> <span>Model</span> for the <span>Dark</span> <span>Side</span> of the <span>Internet</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.08596">https://doi.org/10.48550/ARXIV.2305.08596</a>.
</div>
<div id="ref-jing_alphafold_2024" class="csl-entry" role="listitem">
Jing, Bowen, Bonnie Berger, and Tommi Jaakkola. 2024. <span>“<span>AlphaFold</span> <span>Meets</span> <span>Flow</span> <span>Matching</span> for <span>Generating</span> <span>Protein</span> <span>Ensembles</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.04845">http://arxiv.org/abs/2402.04845</a>.
</div>
<div id="ref-kaddour_challenges_2023" class="csl-entry" role="listitem">
Kaddour, Jean, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023. <span>“Challenges and <span>Applications</span> of <span>Large</span> <span>Language</span> <span>Models</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2307.10169">https://doi.org/10.48550/ARXIV.2307.10169</a>.
</div>
<div id="ref-kallini_mission_2024" class="csl-entry" role="listitem">
Kallini, Julie, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, and Christopher Potts. 2024. <span>“Mission: <span>Impossible</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.06416">http://arxiv.org/abs/2401.06416</a>.
</div>
<div id="ref-kanjee_accuracy_2023" class="csl-entry" role="listitem">
Kanjee, Zahir, Byron Crowe, and Adam Rodman. 2023. <span>“Accuracy of a <span>Generative</span> <span>Artificial</span> <span>Intelligence</span> <span>Model</span> in a <span>Complex</span> <span>Diagnostic</span> <span>Challenge</span>.”</span> <em>JAMA</em> 330 (1): 78. <a href="https://doi.org/10.1001/jama.2023.8288">https://doi.org/10.1001/jama.2023.8288</a>.
</div>
<div id="ref-kaufman_acoustic_2023" class="csl-entry" role="listitem">
Kaufman, Jaycee M., Anirudh Thommandram, and Yan Fossat. 2023. <span>“Acoustic <span>Analysis</span> and <span>Prediction</span> of <span>Type</span> 2 <span>Diabetes</span> <span>Mellitus</span> <span>Using</span> <span>Smartphone</span>-<span>Recorded</span> <span>Voice</span> <span>Segments</span>.”</span> <em>Mayo Clinic Proceedings: Digital Health</em> 1 (4): 534–44. <a href="https://doi.org/10.1016/j.mcpdig.2023.08.005">https://doi.org/10.1016/j.mcpdig.2023.08.005</a>.
</div>
<div id="ref-killock_ai_2020" class="csl-entry" role="listitem">
Killock, David. 2020. <span>“<span>AI</span> Outperforms Radiologists in Mammographic Screening.”</span> <em>Nature Reviews Clinical Oncology</em> 17 (3): 134–34. <a href="https://doi.org/10.1038/s41571-020-0329-7">https://doi.org/10.1038/s41571-020-0329-7</a>.
</div>
<div id="ref-kim_health-llm_2024" class="csl-entry" role="listitem">
Kim, Yubin, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park. 2024. <span>“Health-<span>LLM</span>: <span>Large</span> <span>Language</span> <span>Models</span> for <span>Health</span> <span>Prediction</span> via <span>Wearable</span> <span>Sensor</span> <span>Data</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.06866">http://arxiv.org/abs/2401.06866</a>.
</div>
<div id="ref-kung_performance_2022" class="csl-entry" role="listitem">
Kung, Tiffany H., Morgan Cheatham, ChatGPT, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, et al. 2022. <span>“Performance of <span>ChatGPT</span> on <span>USMLE</span>: <span>Potential</span> for <span>AI</span>-<span>Assisted</span> <span>Medical</span> <span>Education</span> <span>Using</span> <span>Large</span> <span>Language</span> <span>Models</span>.”</span> Preprint. Medical Education. <a href="https://doi.org/10.1101/2022.12.19.22283643">https://doi.org/10.1101/2022.12.19.22283643</a>.
</div>
<div id="ref-larson_myth_2021" class="csl-entry" role="listitem">
Larson, Erik J. 2021a. <em>The Myth of Artificial Intelligence: Why Computers Can’t Think the Way We Do</em>. Cambridge, Massachusetts London, England: The Belknap Press of Harvard University Press.
</div>
<div id="ref-larson_myth_2021-1" class="csl-entry" role="listitem">
———. 2021b. <em>The Myth of Artificial Intelligence: Why Computers Can’t Think the Way We Do</em>. Cambridge, Massachusetts: The Belknap Press of Harvard University Press.
</div>
<div id="ref-lee_deep_2017" class="csl-entry" role="listitem">
Lee, Cecilia S., Doug M. Baughman, and Aaron Y. Lee. 2017. <span>“Deep <span>Learning</span> <span>Is</span> <span>Effective</span> for <span>Classifying</span> <span>Normal</span> Versus <span>Age</span>-<span>Related</span> <span>Macular</span> <span>Degeneration</span> <span>OCT</span> <span>Images</span>.”</span> <em>Ophthalmology Retina</em> 1 (4): 322–27. <a href="https://doi.org/10.1016/j.oret.2016.12.009">https://doi.org/10.1016/j.oret.2016.12.009</a>.
</div>
<div id="ref-drazen_benefits_2023" class="csl-entry" role="listitem">
Lee, Peter, Sebastien Bubeck, and Joseph Petro. 2023. <span>“Benefits, <span>Limits</span>, and <span>Risks</span> of <span>GPT</span>-4 as an <span>AI</span> <span>Chatbot</span> for <span>Medicine</span>.”</span> Edited by Jeffrey M. Drazen, Isaac S. Kohane, and Tze-Yun Leong. <em>New England Journal of Medicine</em> 388 (13): 1233–39. <a href="https://doi.org/10.1056/NEJMsr2214184">https://doi.org/10.1056/NEJMsr2214184</a>.
</div>
<div id="ref-lee_ai_2023" class="csl-entry" role="listitem">
Lee, Peter, Carey Goldberg, and Isaac Kohane. 2023. <em>The <span>AI</span> Revolution in Medicine: <span>GPT</span>-4 and Beyond</em>. 1st ed. Hoboken: Pearson.
</div>
<div id="ref-leivada_dall-e_2022" class="csl-entry" role="listitem">
Leivada, Evelina, Elliot Murphy, and Gary Marcus. 2022. <span>“<span>DALL</span>-<span>E</span> 2 <span>Fails</span> to <span>Reliably</span> <span>Capture</span> <span>Common</span> <span>Syntactic</span> <span>Processes</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2210.12889">http://arxiv.org/abs/2210.12889</a>.
</div>
<div id="ref-lenat_getting_2023" class="csl-entry" role="listitem">
Lenat, Doug, and Gary Marcus. 2023. <span>“Getting from <span>Generative</span> <span>AI</span> to <span>Trustworthy</span> <span>AI</span>: <span>What</span> <span>LLMs</span> Might Learn from <span>Cyc</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2308.04445">http://arxiv.org/abs/2308.04445</a>.
</div>
<div id="ref-li_transformer-lite_2024" class="csl-entry" role="listitem">
Li, Luchang, Sheng Qian, Jie Lu, Lunxi Yuan, Rui Wang, and Qin Xie. 2024. <span>“Transformer-<span>Lite</span>: <span>High</span>-Efficiency <span>Deployment</span> of <span>Large</span> <span>Language</span> <span>Models</span> on <span>Mobile</span> <span>Phone</span> <span>GPUs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.20041">http://arxiv.org/abs/2403.20041</a>.
</div>
<div id="ref-liu_evaluating_2023" class="csl-entry" role="listitem">
Liu, Nelson F., Tianyi Zhang, and Percy Liang. 2023. <span>“Evaluating <span>Verifiability</span> in <span>Generative</span> <span>Search</span> <span>Engines</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2304.09848">http://arxiv.org/abs/2304.09848</a>.
</div>
<div id="ref-liu_agentbench_2023" class="csl-entry" role="listitem">
Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023. <span>“<span>AgentBench</span>: <span>Evaluating</span> <span>LLMs</span> as <span>Agents</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2308.03688">https://doi.org/10.48550/ARXIV.2308.03688</a>.
</div>
<div id="ref-liu_mobilellm_2024" class="csl-entry" role="listitem">
Liu, Zechun, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor Fedorov, Yunyang Xiong, et al. 2024. <span>“<span>MobileLLM</span>: <span>Optimizing</span> <span>Sub</span>-Billion <span>Parameter</span> <span>Language</span> <span>Models</span> for <span>On</span>-<span>Device</span> <span>Use</span> <span>Cases</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.14905">http://arxiv.org/abs/2402.14905</a>.
</div>
<div id="ref-liu_monolith_2022" class="csl-entry" role="listitem">
Liu, Zhuoran, Leqi Zou, Xuan Zou, Caihua Wang, Biao Zhang, Da Tang, Bolin Zhu, et al. 2022. <span>“Monolith: <span>Real</span> <span>Time</span> <span>Recommendation</span> <span>System</span> <span>With</span> <span>Collisionless</span> <span>Embedding</span> <span>Table</span>.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2209.07663">https://doi.org/10.48550/ARXIV.2209.07663</a>.
</div>
<div id="ref-lu_ai_2024" class="csl-entry" role="listitem">
Lu, Chris, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. 2024. <span>“The <span>AI</span> <span>Scientist</span>: <span>Towards</span> <span>Fully</span> <span>Automated</span> <span>Open</span>-<span>Ended</span> <span>Scientific</span> <span>Discovery</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2408.06292">http://arxiv.org/abs/2408.06292</a>.
</div>
<div id="ref-luo_biogpt_2022" class="csl-entry" role="listitem">
Luo, Renqian, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. <span>“<span>BioGPT</span>: Generative Pre-Trained Transformer for Biomedical Text Generation and Mining.”</span> <em>Briefings in Bioinformatics</em> 23 (6): bbac409. <a href="https://doi.org/10.1093/bib/bbac409">https://doi.org/10.1093/bib/bbac409</a>.
</div>
<div id="ref-lutsker_glucose_2024" class="csl-entry" role="listitem">
Lutsker, Guy, Gal Sapir, Anastasia Godneva, Smadar Shilo, Jerry R. Greenfield, Dorit Samocha-Bonet, Shie Mannor, et al. 2024. <span>“From <span>Glucose</span> <span>Patterns</span> to <span>Health</span> <span>Outcomes</span>: <span>A</span> <span>Generalizable</span> <span>Foundation</span> <span>Model</span> for <span>Continuous</span> <span>Glucose</span> <span>Monitor</span> <span>Data</span> <span>Analysis</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2408.11876">http://arxiv.org/abs/2408.11876</a>.
</div>
<div id="ref-ma_lets_2023" class="csl-entry" role="listitem">
Ma, Xiao, Swaroop Mishra, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023. <span>“Let’s <span>Do</span> a <span>Thought</span> <span>Experiment</span>: <span>Using</span> <span>Counterfactuals</span> to <span>Improve</span> <span>Moral</span> <span>Reasoning</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2306.14308">https://doi.org/10.48550/ARXIV.2306.14308</a>.
</div>
<div id="ref-mahowald_dissociating_2023" class="csl-entry" role="listitem">
Mahowald, Kyle, Anna A. Ivanova, Idan A. Blank, Nancy Kanwisher, Joshua B. Tenenbaum, and Evelina Fedorenko. 2023. <span>“Dissociating Language and Thought in Large Language Models: A Cognitive Perspective.”</span> arXiv. <a href="http://arxiv.org/abs/2301.06627">http://arxiv.org/abs/2301.06627</a>.
</div>
<div id="ref-manathunga_aligning_2023" class="csl-entry" role="listitem">
Manathunga, Supun, and Isuru Hettigoda. 2023. <span>“Aligning <span>Large</span> <span>Language</span> <span>Models</span> for <span>Clinical</span> <span>Tasks</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.02884">http://arxiv.org/abs/2309.02884</a>.
</div>
<div id="ref-mcduff_towards_2023" class="csl-entry" role="listitem">
McDuff, Daniel, Mike Schaekermann, Tao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan Singhal, et al. 2023. <span>“Towards <span>Accurate</span> <span>Differential</span> <span>Diagnosis</span> with <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2312.00164">http://arxiv.org/abs/2312.00164</a>.
</div>
<div id="ref-mesko_prompt_2023" class="csl-entry" role="listitem">
Meskó, Bertalan. 2023. <span>“Prompt <span>Engineering</span> as an <span>Important</span> <span>Emerging</span> <span>Skill</span> for <span>Medical</span> <span>Professionals</span>: <span>Tutorial</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (October): e50638. <a href="https://doi.org/10.2196/50638">https://doi.org/10.2196/50638</a>.
</div>
<div id="ref-mesko_imperative_2023" class="csl-entry" role="listitem">
Meskó, Bertalan, and Eric J. Topol. 2023. <span>“The Imperative for Regulatory Oversight of Large Language Models (or Generative <span>AI</span>) in Healthcare.”</span> <em>Npj Digital Medicine</em> 6 (1): 120. <a href="https://doi.org/10.1038/s41746-023-00873-0">https://doi.org/10.1038/s41746-023-00873-0</a>.
</div>
<div id="ref-milliere_philosophical_2024" class="csl-entry" role="listitem">
Millière, Raphaël, and Cameron Buckner. 2024. <span>“A <span>Philosophical</span> <span>Introduction</span> to <span>Language</span> <span>Models</span> – <span>Part</span> <span>I</span>: <span>Continuity</span> <span>With</span> <span>Classic</span> <span>Debates</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.03910">http://arxiv.org/abs/2401.03910</a>.
</div>
<div id="ref-narayanan_ai_2024" class="csl-entry" role="listitem">
Narayanan, Arvind, and Sayash Kapoor. 2024. <em><span>AI</span> Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference</em>. Princeton Oxford: Princeton University Press.
</div>
<div id="ref-nori_capabilities_2023" class="csl-entry" role="listitem">
Nori, Harsha, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. 2023. <span>“Capabilities of <span>GPT</span>-4 on <span>Medical</span> <span>Challenge</span> <span>Problems</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2303.13375">https://doi.org/10.48550/ARXIV.2303.13375</a>.
</div>
<div id="ref-oh_organ_2023" class="csl-entry" role="listitem">
Oh, Hamilton Se-Hwee, Jarod Rutledge, Daniel Nachun, Róbert Pálovics, Olamide Abiose, Patricia Moran-Losada, Divya Channappa, et al. 2023. <span>“Organ Aging Signatures in the Plasma Proteome Track Health and Disease.”</span> <em>Nature</em> 624 (7990): 164–72. <a href="https://doi.org/10.1038/s41586-023-06802-1">https://doi.org/10.1038/s41586-023-06802-1</a>.
</div>
<div id="ref-oren_proving_2023" class="csl-entry" role="listitem">
Oren, Yonatan, Nicole Meister, Niladri Chatterji, Faisal Ladhak, and Tatsunori B. Hashimoto. 2023. <span>“Proving <span>Test</span> <span>Set</span> <span>Contamination</span> in <span>Black</span> <span>Box</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2310.17623">http://arxiv.org/abs/2310.17623</a>.
</div>
<div id="ref-pei_deepfake_2024" class="csl-entry" role="listitem">
Pei, Gan, Jiangning Zhang, Menghan Hu, Guangtao Zhai, Chengjie Wang, Zhenyu Zhang, Jian Yang, Chunhua Shen, and Dacheng Tao. 2024. <span>“Deepfake <span>Generation</span> and <span>Detection</span>: <span>A</span> <span>Benchmark</span> and <span>Survey</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.17881">http://arxiv.org/abs/2403.17881</a>.
</div>
<div id="ref-qian_merge_2023" class="csl-entry" role="listitem">
Qian, Cheng, Xinran Zhao, and Sherry Tongshuang Wu. 2023. <span>“"<span>Merge</span> <span>Conflicts</span>!" <span>Exploring</span> the <span>Impacts</span> of <span>External</span> <span>Distractors</span> to <span>Parametric</span> <span>Knowledge</span> <span>Graphs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.08594">http://arxiv.org/abs/2309.08594</a>.
</div>
<div id="ref-qiu_towards_2024" class="csl-entry" role="listitem">
Qiu, Pengcheng, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, and Weidi Xie. 2024. <span>“Towards <span>Building</span> <span>Multilingual</span> <span>Language</span> <span>Model</span> for <span>Medicine</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.13963">http://arxiv.org/abs/2402.13963</a>.
</div>
<div id="ref-raji_fallacy_2022" class="csl-entry" role="listitem">
Raji, Inioluwa Deborah, I. Elizabeth Kumar, Aaron Horowitz, and Andrew D. Selbst. 2022. <span>“The <span>Fallacy</span> of <span>AI</span> <span>Functionality</span>.”</span> In <em>2022 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 959–72. <a href="https://doi.org/10.1145/3531146.3533158">https://doi.org/10.1145/3531146.3533158</a>.
</div>
<div id="ref-rao_assessing_2023" class="csl-entry" role="listitem">
Rao, Arya, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, Adam Landman, Keith Dreyer, and Marc D Succi. 2023. <span>“Assessing the <span>Utility</span> of <span>ChatGPT</span> <span>Throughout</span> the <span>Entire</span> <span>Clinical</span> <span>Workflow</span>: <span>Development</span> and <span>Usability</span> <span>Study</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (August): e48659. <a href="https://doi.org/10.2196/48659">https://doi.org/10.2196/48659</a>.
</div>
<div id="ref-romera-paredes_mathematical_2024" class="csl-entry" role="listitem">
Romera-Paredes, Bernardino, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, et al. 2024. <span>“Mathematical Discoveries from Program Search with Large Language Models.”</span> <em>Nature</em> 625 (7995): 468–75. <a href="https://doi.org/10.1038/s41586-023-06924-6">https://doi.org/10.1038/s41586-023-06924-6</a>.
</div>
<div id="ref-rottger_political_2024" class="csl-entry" role="listitem">
Röttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Schütze, and Dirk Hovy. 2024. <span>“Political <span>Compass</span> or <span>Spinning</span> <span>Arrow</span>? <span>Towards</span> <span>More</span> <span>Meaningful</span> <span>Evaluations</span> for <span>Values</span> and <span>Opinions</span> in <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.16786">http://arxiv.org/abs/2402.16786</a>.
</div>
<div id="ref-rozado_political_2023" class="csl-entry" role="listitem">
Rozado, David. 2023. <span>“The <span>Political</span> <span>Biases</span> of <span>ChatGPT</span>.”</span> <em>Social Sciences</em> 12 (3): 148. <a href="https://doi.org/10.3390/socsci12030148">https://doi.org/10.3390/socsci12030148</a>.
</div>
<div id="ref-rozado_political_2024" class="csl-entry" role="listitem">
———. 2024. <span>“The <span>Political</span> <span>Preferences</span> of <span>LLMs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.01789">http://arxiv.org/abs/2402.01789</a>.
</div>
<div id="ref-saab_capabilities_2024" class="csl-entry" role="listitem">
Saab, Khaled, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, et al. 2024. <span>“Capabilities of <span>Gemini</span> <span>Models</span> in <span>Medicine</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.18416">http://arxiv.org/abs/2404.18416</a>.
</div>
<div id="ref-sastry_computing_2024" class="csl-entry" role="listitem">
Sastry, Girish, Lennart Heim, Haydn Belfield, Markus Anderljung, Miles Brundage, Julian Hazell, Cullen O’Keefe, et al. 2024. <span>“Computing <span>Power</span> and the <span>Governance</span> of <span>Artificial</span> <span>Intelligence</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.08797">http://arxiv.org/abs/2402.08797</a>.
</div>
<div id="ref-shumailov_curse_2023" class="csl-entry" role="listitem">
Shumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023. <span>“The <span>Curse</span> of <span>Recursion</span>: <span>Training</span> on <span>Generated</span> <span>Data</span> <span>Makes</span> <span>Models</span> <span>Forget</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2305.17493">http://arxiv.org/abs/2305.17493</a>.
</div>
<div id="ref-singhal_large_2023" class="csl-entry" role="listitem">
Singhal, Karan, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, et al. 2023. <span>“Large Language Models Encode Clinical Knowledge.”</span> <em>Nature</em> 620 (7972): 172–80. <a href="https://doi.org/10.1038/s41586-023-06291-2">https://doi.org/10.1038/s41586-023-06291-2</a>.
</div>
<div id="ref-sun_artificial_2023" class="csl-entry" role="listitem">
Sun, Jie, Qun-Xi Dong, San-Wang Wang, Yong-Bo Zheng, Xiao-Xing Liu, Tang-Sheng Lu, Kai Yuan, et al. 2023. <span>“Artificial Intelligence in Psychiatry Research, Diagnosis, and Therapy.”</span> <em>Asian Journal of Psychiatry</em> 87 (September): 103705. <a href="https://doi.org/10.1016/j.ajp.2023.103705">https://doi.org/10.1016/j.ajp.2023.103705</a>.
</div>
<div id="ref-tian_spreadsheetllm_2024" class="csl-entry" role="listitem">
Tian, Yuzhang, Jianbo Zhao, Haoyu Dong, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, et al. 2024. <span>“<span>SpreadsheetLLM</span>: <span>Encoding</span> <span>Spreadsheets</span> for <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2407.09025">http://arxiv.org/abs/2407.09025</a>.
</div>
<div id="ref-tu_towards_2024" class="csl-entry" role="listitem">
Tu, Tao, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, et al. 2024. <span>“Towards <span>Conversational</span> <span>Diagnostic</span> <span>AI</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2401.05654">https://doi.org/10.48550/ARXIV.2401.05654</a>.
</div>
<div id="ref-udandarao_no_2024" class="csl-entry" role="listitem">
Udandarao, Vishaal, Ameya Prabhu, Adhiraj Ghosh, Yash Sharma, Philip H. S. Torr, Adel Bibi, Samuel Albanie, and Matthias Bethge. 2024. <span>“No "<span>Zero</span>-<span>Shot</span>" <span>Without</span> <span>Exponential</span> <span>Data</span>: <span>Pretraining</span> <span>Concept</span> <span>Frequency</span> <span>Determines</span> <span>Multimodal</span> <span>Model</span> <span>Performance</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.04125">http://arxiv.org/abs/2404.04125</a>.
</div>
<div id="ref-villalobos_will_2022" class="csl-entry" role="listitem">
Villalobos, Pablo, Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius Hobbhahn, and Anson Ho. 2022. <span>“Will We Run Out of Data? <span>An</span> Analysis of the Limits of Scaling Datasets in <span>Machine</span> <span>Learning</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2211.04325">http://arxiv.org/abs/2211.04325</a>.
</div>
<div id="ref-wang_sam-octa_2023" class="csl-entry" role="listitem">
Wang, Chengliang, Xinrun Chen, Haojian Ning, and Shiying Li. 2023. <span>“<span>SAM</span>-<span>OCTA</span>: <span>A</span> <span>Fine</span>-<span>Tuning</span> <span>Strategy</span> for <span>Applying</span> <span>Foundation</span> <span>Model</span> to <span>OCTA</span> <span>Image</span> <span>Segmentation</span> <span>Tasks</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.11758">http://arxiv.org/abs/2309.11758</a>.
</div>
<div id="ref-wei_chain--thought_2023" class="csl-entry" role="listitem">
Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. <span>“Chain-of-<span>Thought</span> <span>Prompting</span> <span>Elicits</span> <span>Reasoning</span> in <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2201.11903">http://arxiv.org/abs/2201.11903</a>.
</div>
<div id="ref-wei_long-form_2024" class="csl-entry" role="listitem">
Wei, Jerry, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, et al. 2024. <span>“Long-Form Factuality in Large Language Models.”</span> arXiv. <a href="http://arxiv.org/abs/2403.18802">http://arxiv.org/abs/2403.18802</a>.
</div>
<div id="ref-weiss_what_2024" class="csl-entry" role="listitem">
Weiss, Roy, Daniel Ayzenshteyn, Guy Amit, and Yisroel Mirsky. 2024. <span>“What <span>Was</span> <span>Your</span> <span>Prompt</span>? <span>A</span> <span>Remote</span> <span>Keylogging</span> <span>Attack</span> on <span>AI</span> <span>Assistants</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.09751">http://arxiv.org/abs/2403.09751</a>.
</div>
<div id="ref-wendler_llamas_2024" class="csl-entry" role="listitem">
Wendler, Chris, Veniamin Veselovsky, Giovanni Monea, and Robert West. 2024. <span>“Do <span>Llamas</span> <span>Work</span> in <span>English</span>? <span>On</span> the <span>Latent</span> <span>Language</span> of <span>Multilingual</span> <span>Transformers</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.10588">http://arxiv.org/abs/2402.10588</a>.
</div>
<div id="ref-wornow_shaky_2023" class="csl-entry" role="listitem">
Wornow, Michael, Yizhe Xu, Rahul Thapa, Birju Patel, Ethan Steinberg, Scott Fleming, Michael A. Pfeffer, Jason Fries, and Nigam H. Shah. 2023. <span>“The Shaky Foundations of Large Language Models and Foundation Models for Electronic Health Records.”</span> <em>Npj Digital Medicine</em> 6 (1): 135. <a href="https://doi.org/10.1038/s41746-023-00879-8">https://doi.org/10.1038/s41746-023-00879-8</a>.
</div>
<div id="ref-yiu_transmission_2023" class="csl-entry" role="listitem">
Yiu, Eunice, Eliza Kosoy, and Alison Gopnik. 2023. <span>“Transmission <span>Versus</span> <span>Truth</span>, <span>Imitation</span> <span>Versus</span> <span>Innovation</span>: <span>What</span> <span>Children</span> <span>Can</span> <span>Do</span> <span>That</span> <span>Large</span> <span>Language</span> and <span>Language</span>-and-<span>Vision</span> <span>Models</span> <span>Cannot</span> (<span>Yet</span>).”</span> <em>Perspectives on Psychological Science</em>, October, 17456916231201401. <a href="https://doi.org/10.1177/17456916231201401">https://doi.org/10.1177/17456916231201401</a>.
</div>
<div id="ref-yu_evaluating_2023" class="csl-entry" role="listitem">
Yu, Feiyang, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, Eduardo Kaiser Ururahy Nunes Fonseca, et al. 2023. <span>“Evaluating Progress in Automatic Chest <span>X</span>-Ray Radiology Report Generation.”</span> <em>Patterns</em> 4 (9): 100802. <a href="https://doi.org/10.1016/j.patter.2023.100802">https://doi.org/10.1016/j.patter.2023.100802</a>.
</div>
<div id="ref-zaleski_comprehensiveness_2024" class="csl-entry" role="listitem">
Zaleski, Amanda L, Rachel Berkowsky, Kelly Jean Thomas Craig, and Linda S Pescatello. 2024. <span>“Comprehensiveness, <span>Accuracy</span>, and <span>Readability</span> of <span>Exercise</span> <span>Recommendations</span> <span>Provided</span> by an <span>AI</span>-<span>Based</span> <span>Chatbot</span>: <span>Mixed</span> <span>Methods</span> <span>Study</span>.”</span> <em>JMIR Medical Education</em> 10 (January): e51308. <a href="https://doi.org/10.2196/51308">https://doi.org/10.2196/51308</a>.
</div>
<div id="ref-zhao_foundation_2024" class="csl-entry" role="listitem">
Zhao, Theodore, Yu Gu, Jianwei Yang, Naoto Usuyama, Ho Hin Lee, Sid Kiblawi, Tristan Naumann, et al. 2024. <span>“A Foundation Model for Joint Segmentation, Detection and Recognition of Biomedical Objects Across Nine Modalities.”</span> <em>Nature Methods</em>, November. <a href="https://doi.org/10.1038/s41592-024-02499-w">https://doi.org/10.1038/s41592-024-02499-w</a>.
</div>
<div id="ref-zhao_clip_2023" class="csl-entry" role="listitem">
Zhao, Zihao, Yuxiao Liu, Han Wu, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu, et al. 2023. <span>“<span>CLIP</span> in <span>Medical</span> <span>Imaging</span>: <span>A</span> <span>Comprehensive</span> <span>Survey</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2312.07353">http://arxiv.org/abs/2312.07353</a>.
</div>
<div id="ref-zheng_natural_2024" class="csl-entry" role="listitem">
Zheng, Huaixiu Steven, Swaroop Mishra, Hugh Zhang, Xinyun Chen, Minmin Chen, Azade Nova, Le Hou, et al. 2024. <span>“<span>NATURAL</span> <span>PLAN</span>: <span>Benchmarking</span> <span>LLMs</span> on <span>Natural</span> <span>Language</span> <span>Planning</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2406.04520">http://arxiv.org/abs/2406.04520</a>.
</div>
<div id="ref-zhou_webarena_2023" class="csl-entry" role="listitem">
Zhou, Shuyan, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, et al. 2023. <span>“<span>WebArena</span>: <span>A</span> <span>Realistic</span> <span>Web</span> <span>Environment</span> for <span>Building</span> <span>Autonomous</span> <span>Agents</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2307.13854">http://arxiv.org/abs/2307.13854</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/opticareai\.github\.io\/eyes-on-health\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch02.html" class="pagination-link" aria-label="Inside the Black Box: Understanding What AI Actually Does">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch04.html" class="pagination-link" aria-label="Beyond Computation: The Philosophy of Human Intelligence">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beyond Computation: The Philosophy of Human Intelligence</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025 People+Capital, LLC</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>