<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Inside the Black Box: Understanding What AI Actually Does – The Human Element</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch03.html" rel="next">
<link href="./Ch01.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-626149efe8f5d16e1d391ba177679bf0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="_resources/css/normalize.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch02.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">The Human Element</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.docx">
              <i class="bi bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The False Binary: Why AI Won’t Replace Human Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch02.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beyond Computation: The Philosophy of Human Intelligence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Human Edge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Finding the Sweet Spot</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Implementation Challenge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Human Element in Creative Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Following the Money</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Building the Future: A Human-Centric Vision for AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">About the Authors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-emperors-new-statistics" id="toc-the-emperors-new-statistics" class="nav-link active" data-scroll-target="#the-emperors-new-statistics"><span class="header-section-number">2.1</span> The Emperor’s New Statistics</a></li>
  <li><a href="#one-way-streets-the-critical-limitation-of-llms" id="toc-one-way-streets-the-critical-limitation-of-llms" class="nav-link" data-scroll-target="#one-way-streets-the-critical-limitation-of-llms"><span class="header-section-number">2.2</span> One-Way Streets: The Critical Limitation of LLMs</a></li>
  <li><a href="#inside-the-training-process" id="toc-inside-the-training-process" class="nav-link" data-scroll-target="#inside-the-training-process"><span class="header-section-number">2.3</span> Inside the Training Process</a></li>
  <li><a href="#what-does-the-training-data-include" id="toc-what-does-the-training-data-include" class="nav-link" data-scroll-target="#what-does-the-training-data-include"><span class="header-section-number">2.4</span> What Does the Training Data Include?</a></li>
  <li><a href="#models-learning-from-models-the-recursive-training-problem" id="toc-models-learning-from-models-the-recursive-training-problem" class="nav-link" data-scroll-target="#models-learning-from-models-the-recursive-training-problem"><span class="header-section-number">2.5</span> Models Learning from Models: The Recursive Training Problem</a></li>
  <li><a href="#beyond-text-completion-fine-tuning-for-specific-tasks" id="toc-beyond-text-completion-fine-tuning-for-specific-tasks" class="nav-link" data-scroll-target="#beyond-text-completion-fine-tuning-for-specific-tasks"><span class="header-section-number">2.6</span> Beyond Text Completion: Fine-Tuning for Specific Tasks</a></li>
  <li><a href="#what-ai-cant-do-the-limitations-that-matter" id="toc-what-ai-cant-do-the-limitations-that-matter" class="nav-link" data-scroll-target="#what-ai-cant-do-the-limitations-that-matter"><span class="header-section-number">2.7</span> What AI Can’t Do: The Limitations That Matter</a></li>
  <li><a href="#the-human-element-what-we-bring-that-ai-cant-replace" id="toc-the-human-element-what-we-bring-that-ai-cant-replace" class="nav-link" data-scroll-target="#the-human-element-what-we-bring-that-ai-cant-replace"><span class="header-section-number">2.8</span> The Human Element: What We Bring That AI Can’t Replace</a></li>
  <li><a href="#the-balance-where-humans-and-ai-excel" id="toc-the-balance-where-humans-and-ai-excel" class="nav-link" data-scroll-target="#the-balance-where-humans-and-ai-excel"><span class="header-section-number">2.9</span> The Balance: Where Humans and AI Excel</a></li>
  <li><a href="#the-implications-why-this-matters" id="toc-the-implications-why-this-matters" class="nav-link" data-scroll-target="#the-implications-why-this-matters"><span class="header-section-number">2.10</span> The Implications: Why This Matters</a></li>
  <li><a href="#where-we-go-from-here" id="toc-where-we-go-from-here" class="nav-link" data-scroll-target="#where-we-go-from-here"><span class="header-section-number">2.11</span> Where We Go From Here</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></h1>
<p class="subtitle lead">Demystifying AI’s capabilities and limitations from an implementer’s perspective</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="the-emperors-new-statistics" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-emperors-new-statistics"><span class="header-section-number">2.1</span> The Emperor’s New Statistics</h2>
<p>Artificial intelligence is a broad field which long-time researchers often jokingly define as “anything computers can’t do yet.” From early grammar checkers to chess to facial recognition, many features that are now routine were once considered AI. No doubt the same will eventually be said of the new generation of large language models (LLMs), the more precise term to describe the impressive new tools that include ChatGPT, Claude, and Gemini.</p>
<p>Under the hood, these systems are less magical than they first appear. Today’s LLMs are based on a straightforward application of an optimization algorithm called Generative Pre-trained Transformer (GPT) invented by Google researchers in 2017. While the implementation details involve complex mathematics, the core concept is surprisingly simple: predict what words are most likely to come next in a sequence based on patterns observed in vast amounts of text.</p>
<p>You can think of LLMs as massively optimized and expanded versions of the auto-complete feature your smartphone has offered for years. Instead of proposing the next word or two, these models can generate full sentences, paragraphs, books, and on and on without limit. Their power comes from the GPT optimization that lets them take advantage of the massively-parallel architecture of graphic processing units (GPUs). Just as a graphical image can be broken into smaller pixels, each manipulated in parallel, LLMs break text documents into characters (or “tokens”) that are processed simultaneously within the GPU.</p>
<p>The result is an impressive pattern-matching system that can mimic human-written text with remarkable fidelity—but without the understanding that underlies human communication. When ChatGPT writes a paragraph that sounds like Ernest Hemingway, it’s not channeling Hemingway’s artistic vision or life experiences. It’s generating text based on statistical patterns it observed in Hemingway’s writing and similar texts. The model has no concept of fishing, bullfighting, war, or any other experiences that shaped Hemingway’s distinctive voice. It’s merely producing words that, statistically speaking, are likely to follow one another in a Hemingway-like manner.</p>
</section>
<section id="one-way-streets-the-critical-limitation-of-llms" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="one-way-streets-the-critical-limitation-of-llms"><span class="header-section-number">2.2</span> One-Way Streets: The Critical Limitation of LLMs</h2>
<p>The GPT algorithm has one critical limitation that explains many of its failures: once set in motion, it cannot backtrack. Humans plan ahead, weigh different scenarios, and can change their minds based on foreseen alternatives. GPTs can only fake this planning ability through their access to mountains of data where such alternatives have already been explored.</p>
<p>Consider how you would solve a Sudoku puzzle. You might place a number in a cell, then work through several more cells before realizing your initial choice led to a contradiction. No problem—you backtrack, erase the number, and try a different approach. This recursive thinking process is fundamental to human problem-solving. But LLMs cannot do this. They generate text one token at a time, with no ability to revise earlier decisions based on later realizations.</p>
<p>This limitation explains why LLMs struggle with tasks that humans find relatively straightforward. They cannot do Sudoku, or handle chess positions not covered in their training data. Similarly, although they may appear to evaluate potential investment scenarios, they are merely generating plausible-sounding text based on patterns they’ve observed in financial discussions. They cannot truly consider alternative futures or change their analysis midstream.</p>
<p>This lack of genuine reasoning capability is why it would be wise to take AI predictions with considerable caution. Because they have no concept of imagining how a future situation might change current plans, they cannot truly engage in the kind of counterfactual thinking that underpins human judgment.</p>
</section>
<section id="inside-the-training-process" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="inside-the-training-process"><span class="header-section-number">2.3</span> Inside the Training Process</h2>
<p>LLMs are models that compress vast amounts of human knowledge—written, spoken, images, video—into a format that can generate similar-seeming content when given a starting prompt. Although the final models themselves are small enough to fit on a laptop or smartphone, they are created through a training process that consumes massive amounts of data—virtually everything on the public internet, plus collections of text from millions of books, magazines, academic journals, patent filings, and anything else their creators can find.</p>
<p>Thanks to the clever, time-saving shortcut discovered in the 2017 GPT algorithm, key parts of the training happen in parallel, limited only by the number of GPUs available. It is this optimization that explains the mad rush to buy GPUs, the chief beneficiary of which is Nvidia, thanks to its decades-long leadership in these fast processors. Although Nvidia chips were originally designed for fast graphics, their wide adoption means that many engineers are well-acquainted with CUDA (Compute Unified Device Architecture), the low-level graphics programming software that powers Nvidia devices. When designing the various implementations of GPT, it was natural for developers to optimize for CUDA, further cementing Nvidia’s lead.</p>
<p>Once trained, the LLM is a statistical prediction engine that knows the most likely word, phrase, or paragraphs that follow any given input. It knows, for example, that the phrase “Mary had a little” is highly likely to be followed by “lamb” or even the entire phrase “Its fleece was white as snow.” It will apply the same statistical completion algorithm to any snippet of text, including those that look like questions, where the most likely “completion” is the answer to the question. The statistically most likely way to complete the phrase “what is 1 + 1?” is “2.”</p>
<p>The final LLM consists of billions of “parameters,” finely-tuned statistical values created during the training process. But generating the response to your input requires similar levels of prodigious machine power. In fact, every character you type into the ChatGPT input box, as well as every character it types back, goes through many billions of computations. That slight delay you see as each character comes back at your terminal is not a clever UX (user experience) effect intended to appear like a human is typing the answer. In fact, the characters come out slowly because of the untold levels of computing power required to generate each one of them. Multiply this by the many millions of simultaneous ChatGPT users and you can understand why state-of-the-art LLMs are phenomenally expensive to operate.</p>
</section>
<section id="what-does-the-training-data-include" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="what-does-the-training-data-include"><span class="header-section-number">2.4</span> What Does the Training Data Include?</h2>
<p>The datasets used to train LLMs are enormous and diverse. OpenAI’s GPT-4, for example, was trained on hundreds of billions of words, including:</p>
<ul>
<li>The vast majority of the public internet, including websites, forums, and social media</li>
<li>Millions of books, from classic literature to modern non-fiction</li>
<li>Scientific papers and academic journals</li>
<li>Code repositories and technical documentation</li>
<li>News articles and government documents</li>
</ul>
<p>This massive corpus allows the model to encounter language used in countless contexts, enabling it to generate text that mimics a wide range of styles and domains. However, this approach also has significant limitations. The training data inevitably contains biases, inaccuracies, and outdated information that get encoded into the model’s parameters. And because the model has no understanding of the content—only statistical patterns—it cannot distinguish between reliable sources and misinformation.</p>
<p>Furthermore, while the model’s training data is vast, it’s still finite and frozen at a specific point in time. This creates what’s called a “knowledge cutoff”—a date beyond which the model has no information. Any developments, events, or publications after this date are completely unknown to the model unless specifically provided in the conversation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_resources/images/Ch02-images/OpenAITrainingDataNYTimesChart.png" class="img-fluid figure-img"></p>
<figcaption>ChatGPT is trained on vast text sources, a distillation of most human knowledge.</figcaption>
</figure>
</div>
</section>
<section id="models-learning-from-models-the-recursive-training-problem" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="models-learning-from-models-the-recursive-training-problem"><span class="header-section-number">2.5</span> Models Learning from Models: The Recursive Training Problem</h2>
<p>An increasingly troubling issue is the growing proportion of AI-generated content on the internet. As LLMs produce more and more text that gets published online, newer models are increasingly training on outputs from older models rather than authentic human expression. This creates a recursive problem—models learning from models learning from models—potentially amplifying biases and errors with each generation.</p>
<p>Researcher Ilia Shumailov at the University of Cambridge calls this phenomenon “the curse of recursion,” and it presents a fundamental challenge to the current approach of training AI on internet data. As AI-generated content proliferates, distinguishing authentic human expression from synthetic text becomes increasingly difficult. This recursion problem potentially undermines the very foundation of LLM training by gradually diluting the human element in the training data.</p>
</section>
<section id="beyond-text-completion-fine-tuning-for-specific-tasks" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="beyond-text-completion-fine-tuning-for-specific-tasks"><span class="header-section-number">2.6</span> Beyond Text Completion: Fine-Tuning for Specific Tasks</h2>
<p>While base LLMs are essentially sophisticated text prediction engines, they can be adapted for specific purposes through a process called fine-tuning. This involves additional training on specialized datasets with human feedback to optimize the model for particular tasks or to align its outputs with human values.</p>
<p>For example, the base GPT model might generate toxic or harmful content if that’s what the statistical patterns in its training data suggest. To address this, OpenAI and other companies employ techniques like RLHF (Reinforcement Learning from Human Feedback), where human evaluators rate different model outputs, and these ratings are used to further train the model to produce more helpful, harmless, and honest responses.</p>
<p>This fine-tuning process represents a crucial point of human intervention in the AI pipeline. The values and judgments of the human evaluators directly shape what kinds of responses the model will prioritize. However, this process also introduces new challenges, including the potential for evaluator biases to become magnified in the model’s behavior and the difficulty of clearly defining concepts like “helpful” or “harmful” across diverse cultural contexts.</p>
</section>
<section id="what-ai-cant-do-the-limitations-that-matter" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="what-ai-cant-do-the-limitations-that-matter"><span class="header-section-number">2.7</span> What AI Can’t Do: The Limitations That Matter</h2>
<p>Understanding what LLMs cannot do is as important as appreciating what they can do. Despite their impressive capabilities, today’s AI systems have several fundamental limitations:</p>
<ol type="1">
<li><p><strong>No Understanding or Consciousness</strong>: LLMs process patterns without understanding meaning. They have no consciousness, beliefs, desires, or intentions. They cannot truly understand concepts like justice, beauty, or truth—they can only mimic how humans talk about these concepts.</p></li>
<li><p><strong>No Backtracking or Planning</strong>: As mentioned earlier, LLMs cannot revise earlier parts of their generation based on later realizations. They cannot truly plan ahead or engage in the kind of recursive thinking that humans employ naturally.</p></li>
<li><p><strong>No Reality Grounding</strong>: LLMs have no direct access to physical reality. Their knowledge comes entirely from text and images in their training data, not from embodied experience in the world. They cannot verify facts against reality, only against patterns in their training data.</p></li>
<li><p><strong>No Self-Improvement</strong>: While LLMs can be updated by their creators, they cannot improve themselves through experience. Each interaction is essentially fresh—the model doesn’t learn from its mistakes or successes across conversations.</p></li>
<li><p><strong>No Originality</strong>: LLMs can combine and recombine elements from their training data in new ways, but they cannot create truly original concepts. They are fundamentally derivative, limited by what they’ve seen before.</p></li>
</ol>
<p>These limitations explain why LLMs, despite their impressive text generation capabilities, fail at tasks requiring genuine understanding, counterfactual reasoning, or creative leaps beyond their training data.</p>
</section>
<section id="the-human-element-what-we-bring-that-ai-cant-replace" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="the-human-element-what-we-bring-that-ai-cant-replace"><span class="header-section-number">2.8</span> The Human Element: What We Bring That AI Can’t Replace</h2>
<p>The limitations of LLMs highlight precisely what makes human intelligence distinctive and valuable. When we generate language, solve problems, or make decisions, we do far more than pattern matching. We understand the world through embodied experience, can plan recursively, and can imagine counterfactual scenarios. We can backtrack, revise our thinking, and make creative leaps beyond what we’ve previously encountered.</p>
<p>Consider how a skilled financial analyst evaluates an investment opportunity. They don’t simply pattern-match against previous investments; they consider unique aspects of the current situation, imagine various future scenarios, and continuously revise their analysis as new information emerges. They bring judgment based on embodied experience in the world—something no LLM can replicate.</p>
<p>This is why the most effective applications of AI don’t attempt to replace human judgment but rather to enhance it. When AI handles the pattern-matching tasks it excels at, humans are freed to focus on the aspects of work that require judgment, creativity, and understanding.</p>
</section>
<section id="the-balance-where-humans-and-ai-excel" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="the-balance-where-humans-and-ai-excel"><span class="header-section-number">2.9</span> The Balance: Where Humans and AI Excel</h2>
<p>The most successful implementations of AI technology recognize the complementary strengths of humans and machines. AI demonstrates remarkable capability in processing vast amounts of data quickly and identifying patterns across large datasets that would overwhelm human attention. It excels in generating content based on statistical regularities, performing repetitive tasks with unwavering consistency, and operating continuously without the fatigue that limits human performance.</p>
<p>Humans, meanwhile, bring fundamentally different strengths to the table. We understand context and meaning in ways that transcend statistical correlation. We make ethical judgments that require balancing competing values and considering impacts that may not be quantifiable. Our ability to think recursively and counterfactually—to imagine “what if” scenarios and revise our thinking—allows us to navigate novel situations with a flexibility that AI cannot match. Perhaps most importantly, humans can create truly novel concepts and approaches, and adapt to unprecedented situations by drawing on embodied experience and cross-domain knowledge.</p>
<p>By designing systems that leverage these complementary capabilities, organizations can achieve outcomes superior to what either humans or AI could accomplish alone. A human financial analyst with AI assistance, for instance, can process market data at unprecedented scale while maintaining the judgment needed to contextualize that data within broader economic and political realities. This synergy of human and artificial intelligence is the essence of the enhancement thesis we explore throughout this book.</p>
</section>
<section id="the-implications-why-this-matters" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="the-implications-why-this-matters"><span class="header-section-number">2.10</span> The Implications: Why This Matters</h2>
<p>Understanding what AI actually does—and what it doesn’t do—has profound implications for how we implement these technologies in business and society. When we recognize that LLMs are essentially sophisticated pattern-matching systems rather than genuinely intelligent entities, we can make more informed decisions about where and how to apply them.</p>
<p>This understanding helps explain why purely automated approaches often disappoint, while enhancement approaches succeed. Automated systems that attempt to replace human judgment entirely run up against the fundamental limitations of pattern matching. Enhancement approaches that combine AI’s computational power with human judgment and creativity can deliver superior results.</p>
<p>For investors, this insight suggests focusing on companies that understand the complementary nature of human and artificial intelligence rather than those promising full automation. For business leaders, it means designing implementation strategies that augment rather than replace human capabilities. And for workers, it means developing the distinctively human skills that AI cannot replicate.</p>
</section>
<section id="where-we-go-from-here" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="where-we-go-from-here"><span class="header-section-number">2.11</span> Where We Go From Here</h2>
<p>As AI technologies continue to advance, the boundary between what they can and cannot do will shift. Future systems will likely overcome some of the limitations we’ve discussed, potentially enabling more sophisticated reasoning and planning. However, the fundamental distinction between statistical pattern matching and genuine understanding remains, and with it, the continued importance of human judgment.</p>
<p>In the chapters ahead, we’ll explore how this understanding of AI’s capabilities and limitations translates into practical implementation strategies across industries. We’ll examine the “what versus how” distinction that guides effective human-AI collaboration, the philosophical dimensions of human judgment, and the investment implications of the enhancement thesis.</p>
<p>By grounding our approach in a clear-eyed understanding of what AI actually does, we can move beyond both the hype and the fear to develop strategies that truly enhance human capabilities rather than attempting to replace them.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abdin_phi-3_2024" class="csl-entry" role="listitem">
Abdin, Marah, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, et al. 2024. <span>“Phi-3 <span>Technical</span> <span>Report</span>: <span>A</span> <span>Highly</span> <span>Capable</span> <span>Language</span> <span>Model</span> <span>Locally</span> on <span>Your</span> <span>Phone</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.14219">http://arxiv.org/abs/2404.14219</a>.
</div>
<div id="ref-ai_yi_2024" class="csl-entry" role="listitem">
AI, 01, Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, et al. 2024. <span>“Yi: <span>Open</span> <span>Foundation</span> <span>Models</span> by 01.<span>AI</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.04652">http://arxiv.org/abs/2403.04652</a>.
</div>
<div id="ref-alamdari_protein_2023" class="csl-entry" role="listitem">
Alamdari, Sarah, Nitya Thakkar, Rianne Van Den Berg, Alex Xijie Lu, Nicolo Fusi, Ava Pardis Amini, and Kevin K Yang. 2023. <span>“Protein Generation with Evolutionary Diffusion: Sequence Is All You Need.”</span> Preprint. Bioengineering. <a href="https://doi.org/10.1101/2023.09.11.556673">https://doi.org/10.1101/2023.09.11.556673</a>.
</div>
<div id="ref-bender_dangers_2021" class="csl-entry" role="listitem">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>“On the <span>Dangers</span> of <span>Stochastic</span> <span>Parrots</span>: <span>Can</span> <span>Language</span> <span>Models</span> <span>Be</span> <span>Too</span> <span>Big</span>? 🦜.”</span> In <em>Proceedings of the 2021 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 610–23. Virtual Event Canada: ACM. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-berglund_reversal_2023" class="csl-entry" role="listitem">
Berglund, Lukas, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023. <span>“The <span>Reversal</span> <span>Curse</span>: <span>LLMs</span> Trained on "<span>A</span> Is <span>B</span>" Fail to Learn "<span>B</span> Is <span>A</span>".”</span> arXiv. <a href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a>.
</div>
<div id="ref-bsharat_principled_2023" class="csl-entry" role="listitem">
Bsharat, Sondos Mahmoud, Aidar Myrzakhan, and Zhiqiang Shen. 2023. <span>“Principled <span>Instructions</span> <span>Are</span> <span>All</span> <span>You</span> <span>Need</span> for <span>Questioning</span> <span>LLaMA</span>-1/2, <span>GPT</span>-3.5/4.”</span> arXiv. <a href="http://arxiv.org/abs/2312.16171">http://arxiv.org/abs/2312.16171</a>.
</div>
<div id="ref-burtch_consequences_2024" class="csl-entry" role="listitem">
Burtch, Gordon, Dokyun Lee, and Zhichen Chen. 2024. <span>“The Consequences of Generative <span>AI</span> for Online Knowledge Communities.”</span> <em>Scientific Reports</em> 14 (1): 10413. <a href="https://doi.org/10.1038/s41598-024-61221-0">https://doi.org/10.1038/s41598-024-61221-0</a>.
</div>
<div id="ref-butlin_consciousness_2023" class="csl-entry" role="listitem">
Butlin, Patrick, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, et al. 2023. <span>“Consciousness in <span>Artificial</span> <span>Intelligence</span>: <span>Insights</span> from the <span>Science</span> of <span>Consciousness</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2308.08708">https://doi.org/10.48550/ARXIV.2308.08708</a>.
</div>
<div id="ref-carlini_stealing_2024" class="csl-entry" role="listitem">
Carlini, Nicholas, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, et al. 2024. <span>“Stealing <span>Part</span> of a <span>Production</span> <span>Language</span> <span>Model</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.06634">http://arxiv.org/abs/2403.06634</a>.
</div>
<div id="ref-chang_speak_2023" class="csl-entry" role="listitem">
Chang, Kent K., Mackenzie Cramer, Sandeep Soni, and David Bamman. 2023a. <span>“Speak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.00118">https://doi.org/10.48550/ARXIV.2305.00118</a>.
</div>
<div id="ref-chang_speak_2023-1" class="csl-entry" role="listitem">
———. 2023b. <span>“Speak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.”</span> arXiv. <a href="http://arxiv.org/abs/2305.00118">http://arxiv.org/abs/2305.00118</a>.
</div>
<div id="ref-de__fauw_clinically_2018" class="csl-entry" role="listitem">
De Fauw, Jeffrey, Joseph R. Ledsam, Bernardino Romera-Paredes, Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham, et al. 2018. <span>“Clinically Applicable Deep Learning for Diagnosis and Referral in Retinal Disease.”</span> <em>Nature Medicine</em> 24 (9): 1342–50. <a href="https://doi.org/10.1038/s41591-018-0107-6">https://doi.org/10.1038/s41591-018-0107-6</a>.
</div>
<div id="ref-di_palma_evaluating_2023" class="csl-entry" role="listitem">
Di Palma, Dario, Giovanni Maria Biancofiore, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia, and Eugenio Di Sciascio. 2023. <span>“Evaluating <span>ChatGPT</span> as a <span>Recommender</span> <span>System</span>: <span>A</span> <span>Rigorous</span> <span>Approach</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.03613">http://arxiv.org/abs/2309.03613</a>.
</div>
<div id="ref-dodge_documenting_2021" class="csl-entry" role="listitem">
Dodge, Jesse, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. <span>“Documenting <span>Large</span> <span>Webtext</span> <span>Corpora</span>: <span>A</span> <span>Case</span> <span>Study</span> on the <span>Colossal</span> <span>Clean</span> <span>Crawled</span> <span>Corpus</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2104.08758">https://doi.org/10.48550/ARXIV.2104.08758</a>.
</div>
<div id="ref-dreyfus_why_2007" class="csl-entry" role="listitem">
Dreyfus, Hubert L. 2007. <span>“Why <span>Heideggerian</span> <span>AI</span> <span>Failed</span> and <span>How</span> <span>Fixing</span> It <span>Would</span> <span>Require</span> <span>Making</span> It <span>More</span> <span>Heideggerian</span>.”</span> <em>Philosophical Psychology</em> 20 (2): 247–68. <a href="https://doi.org/10.1080/09515080701239510">https://doi.org/10.1080/09515080701239510</a>.
</div>
<div id="ref-epoch_ai_data_2024" class="csl-entry" role="listitem">
Epoch AI. 2024. <span>“Data on <span>Large</span> <span>Language</span> <span>AI</span> <span>Models</span>.”</span> <a href="https://epochai.org/data/large-scale-ai-models">https://epochai.org/data/large-scale-ai-models</a>.
</div>
<div id="ref-erdil_explosive_2024" class="csl-entry" role="listitem">
Erdil, Ege, and Tamay Besiroglu. 2024. <span>“Explosive Growth from <span>AI</span> Automation: <span>A</span> Review of the Arguments.”</span> arXiv. <a href="http://arxiv.org/abs/2309.11690">http://arxiv.org/abs/2309.11690</a>.
</div>
<div id="ref-esteva_guide_2019" class="csl-entry" role="listitem">
Esteva, Andre, Alexandre Robicquet, Bharath Ramsundar, Volodymyr Kuleshov, Mark DePristo, Katherine Chou, Claire Cui, Greg Corrado, Sebastian Thrun, and Jeff Dean. 2019. <span>“A Guide to Deep Learning in Healthcare.”</span> <em>Nature Medicine</em> 25 (1): 24–29. <a href="https://doi.org/10.1038/s41591-018-0316-z">https://doi.org/10.1038/s41591-018-0316-z</a>.
</div>
<div id="ref-feng_pretraining_2023" class="csl-entry" role="listitem">
Feng, Shangbin, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov. 2023. <span>“From <span>Pretraining</span> <span>Data</span> to <span>Language</span> <span>Models</span> to <span>Downstream</span> <span>Tasks</span>: <span>Tracking</span> the <span>Trails</span> of <span>Political</span> <span>Biases</span> <span>Leading</span> to <span>Unfair</span> <span>NLP</span> <span>Models</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.08283">https://doi.org/10.48550/ARXIV.2305.08283</a>.
</div>
<div id="ref-goh_large_2024" class="csl-entry" role="listitem">
Goh, Ethan, Robert Gallo, Jason Hom, Eric Strong, Yingjie Weng, Hannah Kerman, Joséphine A. Cool, et al. 2024. <span>“Large <span>Language</span> <span>Model</span> <span>Influence</span> on <span>Diagnostic</span> <span>Reasoning</span>: <span>A</span> <span>Randomized</span> <span>Clinical</span> <span>Trial</span>.”</span> <em>JAMA Network Open</em> 7 (10): e2440969. <a href="https://doi.org/10.1001/jamanetworkopen.2024.40969">https://doi.org/10.1001/jamanetworkopen.2024.40969</a>.
</div>
<div id="ref-grossmann_ai_2023" class="csl-entry" role="listitem">
Grossmann, Igor, Matthew Feinberg, Dawn C. Parker, Nicholas A. Christakis, Philip E. Tetlock, and William A. Cunningham. 2023. <span>“<span>AI</span> and the Transformation of Social Science Research.”</span> <em>Science</em> 380 (6650): 1108–9. <a href="https://doi.org/10.1126/science.adi1778">https://doi.org/10.1126/science.adi1778</a>.
</div>
<div id="ref-gupta_calm_2023" class="csl-entry" role="listitem">
Gupta, Vipul, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, and Rebecca J. Passonneau. 2023. <span>“<span>CALM</span> : <span>A</span> <span>Multi</span>-Task <span>Benchmark</span> for <span>Comprehensive</span> <span>Assessment</span> of <span>Language</span> <span>Model</span> <span>Bias</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a>.
</div>
<div id="ref-he_foundation_2024" class="csl-entry" role="listitem">
He, Yuting, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, and Hao Chen. 2024. <span>“Foundation <span>Model</span> for <span>Advancing</span> <span>Healthcare</span>: <span>Challenges</span>, <span>Opportunities</span>, and <span>Future</span> <span>Directions</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.03264">http://arxiv.org/abs/2404.03264</a>.
</div>
<div id="ref-hendy_how_2023" class="csl-entry" role="listitem">
Hendy, Amr, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. <span>“How <span>Good</span> <span>Are</span> <span>GPT</span> <span>Models</span> at <span>Machine</span> <span>Translation</span>? <span>A</span> <span>Comprehensive</span> <span>Evaluation</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2302.09210">http://arxiv.org/abs/2302.09210</a>.
</div>
<div id="ref-hicks_chatgpt_2024" class="csl-entry" role="listitem">
Hicks, Michael Townsen, James Humphries, and Joe Slater. 2024. <span>“<span>ChatGPT</span> Is Bullshit.”</span> <em>Ethics and Information Technology</em> 26 (2): 38. <a href="https://doi.org/10.1007/s10676-024-09775-5">https://doi.org/10.1007/s10676-024-09775-5</a>.
</div>
<div id="ref-hoffmann_training_2022" class="csl-entry" role="listitem">
Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <span>“Training <span>Compute</span>-<span>Optimal</span> <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2203.15556">http://arxiv.org/abs/2203.15556</a>.
</div>
<div id="ref-hopkins_artificial_2023" class="csl-entry" role="listitem">
Hopkins, Ashley M, Jessica M Logan, Ganessan Kichenadasse, and Michael J Sorich. 2023. <span>“Artificial Intelligence Chatbots Will Revolutionize How Cancer Patients Access Information: <span>ChatGPT</span> Represents a Paradigm-Shift.”</span> <em>JNCI Cancer Spectrum</em> 7 (2): pkad010. <a href="https://doi.org/10.1093/jncics/pkad010">https://doi.org/10.1093/jncics/pkad010</a>.
</div>
<div id="ref-hristidis_chatgpt_2023" class="csl-entry" role="listitem">
Hristidis, Vagelis, Nicole Ruggiano, Ellen L Brown, Sai Rithesh Reddy Ganta, and Selena Stewart. 2023. <span>“<span>ChatGPT</span> Vs <span>Google</span> for <span>Queries</span> <span>Related</span> to <span>Dementia</span> and <span>Other</span> <span>Cognitive</span> <span>Decline</span>: <span>Comparison</span> of <span>Results</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (July): e48966. <a href="https://doi.org/10.2196/48966">https://doi.org/10.2196/48966</a>.
</div>
<div id="ref-huang_propaganda_2013" class="csl-entry" role="listitem">
Huang, Haifeng, and Zhi Li. 2013. <span>“Propaganda and <span>Signaling</span>.”</span> <em>SSRN Electronic Journal</em>. <a href="https://doi.org/10.2139/ssrn.2325101">https://doi.org/10.2139/ssrn.2325101</a>.
</div>
<div id="ref-huang_crispr-gpt_2024" class="csl-entry" role="listitem">
Huang, Kaixuan, Yuanhao Qu, Henry Cousins, William A. Johnson, Di Yin, Mihir Shah, Denny Zhou, Russ Altman, Mengdi Wang, and Le Cong. 2024. <span>“<span>CRISPR</span>-<span>GPT</span>: <span>An</span> <span>LLM</span> <span>Agent</span> for <span>Automated</span> <span>Design</span> of <span>Gene</span>-<span>Editing</span> <span>Experiments</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.18021">http://arxiv.org/abs/2404.18021</a>.
</div>
<div id="ref-jackson_exposure_2023" class="csl-entry" role="listitem">
Jackson, Joshua Conrad, Kai Chi Yam, Pok Man Tang, Chris G. Sibley, and Adam Waytz. 2023. <span>“Exposure to Automation Explains Religious Declines.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (34): e2304748120. <a href="https://doi.org/10.1073/pnas.2304748120">https://doi.org/10.1073/pnas.2304748120</a>.
</div>
<div id="ref-jin_darkbert_2023" class="csl-entry" role="listitem">
Jin, Youngjin, Eugene Jang, Jian Cui, Jin-Woo Chung, Yongjae Lee, and Seungwon Shin. 2023. <span>“<span>DarkBERT</span>: <span>A</span> <span>Language</span> <span>Model</span> for the <span>Dark</span> <span>Side</span> of the <span>Internet</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2305.08596">https://doi.org/10.48550/ARXIV.2305.08596</a>.
</div>
<div id="ref-jing_alphafold_2024" class="csl-entry" role="listitem">
Jing, Bowen, Bonnie Berger, and Tommi Jaakkola. 2024. <span>“<span>AlphaFold</span> <span>Meets</span> <span>Flow</span> <span>Matching</span> for <span>Generating</span> <span>Protein</span> <span>Ensembles</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.04845">http://arxiv.org/abs/2402.04845</a>.
</div>
<div id="ref-kaddour_challenges_2023" class="csl-entry" role="listitem">
Kaddour, Jean, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023. <span>“Challenges and <span>Applications</span> of <span>Large</span> <span>Language</span> <span>Models</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2307.10169">https://doi.org/10.48550/ARXIV.2307.10169</a>.
</div>
<div id="ref-kallini_mission_2024" class="csl-entry" role="listitem">
Kallini, Julie, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, and Christopher Potts. 2024. <span>“Mission: <span>Impossible</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.06416">http://arxiv.org/abs/2401.06416</a>.
</div>
<div id="ref-kanjee_accuracy_2023" class="csl-entry" role="listitem">
Kanjee, Zahir, Byron Crowe, and Adam Rodman. 2023. <span>“Accuracy of a <span>Generative</span> <span>Artificial</span> <span>Intelligence</span> <span>Model</span> in a <span>Complex</span> <span>Diagnostic</span> <span>Challenge</span>.”</span> <em>JAMA</em> 330 (1): 78. <a href="https://doi.org/10.1001/jama.2023.8288">https://doi.org/10.1001/jama.2023.8288</a>.
</div>
<div id="ref-kaufman_acoustic_2023" class="csl-entry" role="listitem">
Kaufman, Jaycee M., Anirudh Thommandram, and Yan Fossat. 2023. <span>“Acoustic <span>Analysis</span> and <span>Prediction</span> of <span>Type</span> 2 <span>Diabetes</span> <span>Mellitus</span> <span>Using</span> <span>Smartphone</span>-<span>Recorded</span> <span>Voice</span> <span>Segments</span>.”</span> <em>Mayo Clinic Proceedings: Digital Health</em> 1 (4): 534–44. <a href="https://doi.org/10.1016/j.mcpdig.2023.08.005">https://doi.org/10.1016/j.mcpdig.2023.08.005</a>.
</div>
<div id="ref-killock_ai_2020" class="csl-entry" role="listitem">
Killock, David. 2020. <span>“<span>AI</span> Outperforms Radiologists in Mammographic Screening.”</span> <em>Nature Reviews Clinical Oncology</em> 17 (3): 134–34. <a href="https://doi.org/10.1038/s41571-020-0329-7">https://doi.org/10.1038/s41571-020-0329-7</a>.
</div>
<div id="ref-kim_health-llm_2024" class="csl-entry" role="listitem">
Kim, Yubin, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park. 2024. <span>“Health-<span>LLM</span>: <span>Large</span> <span>Language</span> <span>Models</span> for <span>Health</span> <span>Prediction</span> via <span>Wearable</span> <span>Sensor</span> <span>Data</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.06866">http://arxiv.org/abs/2401.06866</a>.
</div>
<div id="ref-kung_performance_2022" class="csl-entry" role="listitem">
Kung, Tiffany H., Morgan Cheatham, ChatGPT, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, et al. 2022. <span>“Performance of <span>ChatGPT</span> on <span>USMLE</span>: <span>Potential</span> for <span>AI</span>-<span>Assisted</span> <span>Medical</span> <span>Education</span> <span>Using</span> <span>Large</span> <span>Language</span> <span>Models</span>.”</span> Preprint. Medical Education. <a href="https://doi.org/10.1101/2022.12.19.22283643">https://doi.org/10.1101/2022.12.19.22283643</a>.
</div>
<div id="ref-larson_myth_2021" class="csl-entry" role="listitem">
Larson, Erik J. 2021a. <em>The Myth of Artificial Intelligence: Why Computers Can’t Think the Way We Do</em>. Cambridge, Massachusetts London, England: The Belknap Press of Harvard University Press.
</div>
<div id="ref-larson_myth_2021-1" class="csl-entry" role="listitem">
———. 2021b. <em>The Myth of Artificial Intelligence: Why Computers Can’t Think the Way We Do</em>. Cambridge, Massachusetts: The Belknap Press of Harvard University Press.
</div>
<div id="ref-lee_deep_2017" class="csl-entry" role="listitem">
Lee, Cecilia S., Doug M. Baughman, and Aaron Y. Lee. 2017. <span>“Deep <span>Learning</span> <span>Is</span> <span>Effective</span> for <span>Classifying</span> <span>Normal</span> Versus <span>Age</span>-<span>Related</span> <span>Macular</span> <span>Degeneration</span> <span>OCT</span> <span>Images</span>.”</span> <em>Ophthalmology Retina</em> 1 (4): 322–27. <a href="https://doi.org/10.1016/j.oret.2016.12.009">https://doi.org/10.1016/j.oret.2016.12.009</a>.
</div>
<div id="ref-drazen_benefits_2023" class="csl-entry" role="listitem">
Lee, Peter, Sebastien Bubeck, and Joseph Petro. 2023. <span>“Benefits, <span>Limits</span>, and <span>Risks</span> of <span>GPT</span>-4 as an <span>AI</span> <span>Chatbot</span> for <span>Medicine</span>.”</span> Edited by Jeffrey M. Drazen, Isaac S. Kohane, and Tze-Yun Leong. <em>New England Journal of Medicine</em> 388 (13): 1233–39. <a href="https://doi.org/10.1056/NEJMsr2214184">https://doi.org/10.1056/NEJMsr2214184</a>.
</div>
<div id="ref-lee_ai_2023" class="csl-entry" role="listitem">
Lee, Peter, Carey Goldberg, and Isaac Kohane. 2023. <em>The <span>AI</span> Revolution in Medicine: <span>GPT</span>-4 and Beyond</em>. 1st ed. Hoboken: Pearson.
</div>
<div id="ref-leivada_dall-e_2022" class="csl-entry" role="listitem">
Leivada, Evelina, Elliot Murphy, and Gary Marcus. 2022. <span>“<span>DALL</span>-<span>E</span> 2 <span>Fails</span> to <span>Reliably</span> <span>Capture</span> <span>Common</span> <span>Syntactic</span> <span>Processes</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2210.12889">http://arxiv.org/abs/2210.12889</a>.
</div>
<div id="ref-lenat_getting_2023" class="csl-entry" role="listitem">
Lenat, Doug, and Gary Marcus. 2023. <span>“Getting from <span>Generative</span> <span>AI</span> to <span>Trustworthy</span> <span>AI</span>: <span>What</span> <span>LLMs</span> Might Learn from <span>Cyc</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2308.04445">http://arxiv.org/abs/2308.04445</a>.
</div>
<div id="ref-li_transformer-lite_2024" class="csl-entry" role="listitem">
Li, Luchang, Sheng Qian, Jie Lu, Lunxi Yuan, Rui Wang, and Qin Xie. 2024. <span>“Transformer-<span>Lite</span>: <span>High</span>-Efficiency <span>Deployment</span> of <span>Large</span> <span>Language</span> <span>Models</span> on <span>Mobile</span> <span>Phone</span> <span>GPUs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.20041">http://arxiv.org/abs/2403.20041</a>.
</div>
<div id="ref-liu_evaluating_2023" class="csl-entry" role="listitem">
Liu, Nelson F., Tianyi Zhang, and Percy Liang. 2023. <span>“Evaluating <span>Verifiability</span> in <span>Generative</span> <span>Search</span> <span>Engines</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2304.09848">http://arxiv.org/abs/2304.09848</a>.
</div>
<div id="ref-liu_agentbench_2023" class="csl-entry" role="listitem">
Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023. <span>“<span>AgentBench</span>: <span>Evaluating</span> <span>LLMs</span> as <span>Agents</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2308.03688">https://doi.org/10.48550/ARXIV.2308.03688</a>.
</div>
<div id="ref-liu_mobilellm_2024" class="csl-entry" role="listitem">
Liu, Zechun, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor Fedorov, Yunyang Xiong, et al. 2024. <span>“<span>MobileLLM</span>: <span>Optimizing</span> <span>Sub</span>-Billion <span>Parameter</span> <span>Language</span> <span>Models</span> for <span>On</span>-<span>Device</span> <span>Use</span> <span>Cases</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.14905">http://arxiv.org/abs/2402.14905</a>.
</div>
<div id="ref-liu_monolith_2022" class="csl-entry" role="listitem">
Liu, Zhuoran, Leqi Zou, Xuan Zou, Caihua Wang, Biao Zhang, Da Tang, Bolin Zhu, et al. 2022. <span>“Monolith: <span>Real</span> <span>Time</span> <span>Recommendation</span> <span>System</span> <span>With</span> <span>Collisionless</span> <span>Embedding</span> <span>Table</span>.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2209.07663">https://doi.org/10.48550/ARXIV.2209.07663</a>.
</div>
<div id="ref-lu_ai_2024" class="csl-entry" role="listitem">
Lu, Chris, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. 2024. <span>“The <span>AI</span> <span>Scientist</span>: <span>Towards</span> <span>Fully</span> <span>Automated</span> <span>Open</span>-<span>Ended</span> <span>Scientific</span> <span>Discovery</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2408.06292">http://arxiv.org/abs/2408.06292</a>.
</div>
<div id="ref-luo_biogpt_2022" class="csl-entry" role="listitem">
Luo, Renqian, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. <span>“<span>BioGPT</span>: Generative Pre-Trained Transformer for Biomedical Text Generation and Mining.”</span> <em>Briefings in Bioinformatics</em> 23 (6): bbac409. <a href="https://doi.org/10.1093/bib/bbac409">https://doi.org/10.1093/bib/bbac409</a>.
</div>
<div id="ref-lutsker_glucose_2024" class="csl-entry" role="listitem">
Lutsker, Guy, Gal Sapir, Anastasia Godneva, Smadar Shilo, Jerry R. Greenfield, Dorit Samocha-Bonet, Shie Mannor, et al. 2024. <span>“From <span>Glucose</span> <span>Patterns</span> to <span>Health</span> <span>Outcomes</span>: <span>A</span> <span>Generalizable</span> <span>Foundation</span> <span>Model</span> for <span>Continuous</span> <span>Glucose</span> <span>Monitor</span> <span>Data</span> <span>Analysis</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2408.11876">http://arxiv.org/abs/2408.11876</a>.
</div>
<div id="ref-ma_lets_2023" class="csl-entry" role="listitem">
Ma, Xiao, Swaroop Mishra, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023. <span>“Let’s <span>Do</span> a <span>Thought</span> <span>Experiment</span>: <span>Using</span> <span>Counterfactuals</span> to <span>Improve</span> <span>Moral</span> <span>Reasoning</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2306.14308">https://doi.org/10.48550/ARXIV.2306.14308</a>.
</div>
<div id="ref-mahowald_dissociating_2023" class="csl-entry" role="listitem">
Mahowald, Kyle, Anna A. Ivanova, Idan A. Blank, Nancy Kanwisher, Joshua B. Tenenbaum, and Evelina Fedorenko. 2023. <span>“Dissociating Language and Thought in Large Language Models: A Cognitive Perspective.”</span> arXiv. <a href="http://arxiv.org/abs/2301.06627">http://arxiv.org/abs/2301.06627</a>.
</div>
<div id="ref-manathunga_aligning_2023" class="csl-entry" role="listitem">
Manathunga, Supun, and Isuru Hettigoda. 2023. <span>“Aligning <span>Large</span> <span>Language</span> <span>Models</span> for <span>Clinical</span> <span>Tasks</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.02884">http://arxiv.org/abs/2309.02884</a>.
</div>
<div id="ref-mcduff_towards_2023" class="csl-entry" role="listitem">
McDuff, Daniel, Mike Schaekermann, Tao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan Singhal, et al. 2023. <span>“Towards <span>Accurate</span> <span>Differential</span> <span>Diagnosis</span> with <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2312.00164">http://arxiv.org/abs/2312.00164</a>.
</div>
<div id="ref-mesko_prompt_2023" class="csl-entry" role="listitem">
Meskó, Bertalan. 2023. <span>“Prompt <span>Engineering</span> as an <span>Important</span> <span>Emerging</span> <span>Skill</span> for <span>Medical</span> <span>Professionals</span>: <span>Tutorial</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (October): e50638. <a href="https://doi.org/10.2196/50638">https://doi.org/10.2196/50638</a>.
</div>
<div id="ref-mesko_imperative_2023" class="csl-entry" role="listitem">
Meskó, Bertalan, and Eric J. Topol. 2023. <span>“The Imperative for Regulatory Oversight of Large Language Models (or Generative <span>AI</span>) in Healthcare.”</span> <em>Npj Digital Medicine</em> 6 (1): 120. <a href="https://doi.org/10.1038/s41746-023-00873-0">https://doi.org/10.1038/s41746-023-00873-0</a>.
</div>
<div id="ref-milliere_philosophical_2024" class="csl-entry" role="listitem">
Millière, Raphaël, and Cameron Buckner. 2024. <span>“A <span>Philosophical</span> <span>Introduction</span> to <span>Language</span> <span>Models</span> – <span>Part</span> <span>I</span>: <span>Continuity</span> <span>With</span> <span>Classic</span> <span>Debates</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2401.03910">http://arxiv.org/abs/2401.03910</a>.
</div>
<div id="ref-narayanan_ai_2024" class="csl-entry" role="listitem">
Narayanan, Arvind, and Sayash Kapoor. 2024. <em><span>AI</span> Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference</em>. Princeton Oxford: Princeton University Press.
</div>
<div id="ref-nori_capabilities_2023" class="csl-entry" role="listitem">
Nori, Harsha, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. 2023. <span>“Capabilities of <span>GPT</span>-4 on <span>Medical</span> <span>Challenge</span> <span>Problems</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2303.13375">https://doi.org/10.48550/ARXIV.2303.13375</a>.
</div>
<div id="ref-oh_organ_2023" class="csl-entry" role="listitem">
Oh, Hamilton Se-Hwee, Jarod Rutledge, Daniel Nachun, Róbert Pálovics, Olamide Abiose, Patricia Moran-Losada, Divya Channappa, et al. 2023. <span>“Organ Aging Signatures in the Plasma Proteome Track Health and Disease.”</span> <em>Nature</em> 624 (7990): 164–72. <a href="https://doi.org/10.1038/s41586-023-06802-1">https://doi.org/10.1038/s41586-023-06802-1</a>.
</div>
<div id="ref-oren_proving_2023" class="csl-entry" role="listitem">
Oren, Yonatan, Nicole Meister, Niladri Chatterji, Faisal Ladhak, and Tatsunori B. Hashimoto. 2023. <span>“Proving <span>Test</span> <span>Set</span> <span>Contamination</span> in <span>Black</span> <span>Box</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2310.17623">http://arxiv.org/abs/2310.17623</a>.
</div>
<div id="ref-pei_deepfake_2024" class="csl-entry" role="listitem">
Pei, Gan, Jiangning Zhang, Menghan Hu, Guangtao Zhai, Chengjie Wang, Zhenyu Zhang, Jian Yang, Chunhua Shen, and Dacheng Tao. 2024. <span>“Deepfake <span>Generation</span> and <span>Detection</span>: <span>A</span> <span>Benchmark</span> and <span>Survey</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.17881">http://arxiv.org/abs/2403.17881</a>.
</div>
<div id="ref-qian_merge_2023" class="csl-entry" role="listitem">
Qian, Cheng, Xinran Zhao, and Sherry Tongshuang Wu. 2023. <span>“"<span>Merge</span> <span>Conflicts</span>!" <span>Exploring</span> the <span>Impacts</span> of <span>External</span> <span>Distractors</span> to <span>Parametric</span> <span>Knowledge</span> <span>Graphs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.08594">http://arxiv.org/abs/2309.08594</a>.
</div>
<div id="ref-qiu_towards_2024" class="csl-entry" role="listitem">
Qiu, Pengcheng, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, and Weidi Xie. 2024. <span>“Towards <span>Building</span> <span>Multilingual</span> <span>Language</span> <span>Model</span> for <span>Medicine</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.13963">http://arxiv.org/abs/2402.13963</a>.
</div>
<div id="ref-raji_fallacy_2022" class="csl-entry" role="listitem">
Raji, Inioluwa Deborah, I. Elizabeth Kumar, Aaron Horowitz, and Andrew D. Selbst. 2022. <span>“The <span>Fallacy</span> of <span>AI</span> <span>Functionality</span>.”</span> In <em>2022 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 959–72. <a href="https://doi.org/10.1145/3531146.3533158">https://doi.org/10.1145/3531146.3533158</a>.
</div>
<div id="ref-rao_assessing_2023" class="csl-entry" role="listitem">
Rao, Arya, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, Adam Landman, Keith Dreyer, and Marc D Succi. 2023. <span>“Assessing the <span>Utility</span> of <span>ChatGPT</span> <span>Throughout</span> the <span>Entire</span> <span>Clinical</span> <span>Workflow</span>: <span>Development</span> and <span>Usability</span> <span>Study</span>.”</span> <em>Journal of Medical Internet Research</em> 25 (August): e48659. <a href="https://doi.org/10.2196/48659">https://doi.org/10.2196/48659</a>.
</div>
<div id="ref-romera-paredes_mathematical_2024" class="csl-entry" role="listitem">
Romera-Paredes, Bernardino, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, et al. 2024. <span>“Mathematical Discoveries from Program Search with Large Language Models.”</span> <em>Nature</em> 625 (7995): 468–75. <a href="https://doi.org/10.1038/s41586-023-06924-6">https://doi.org/10.1038/s41586-023-06924-6</a>.
</div>
<div id="ref-rottger_political_2024" class="csl-entry" role="listitem">
Röttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Schütze, and Dirk Hovy. 2024. <span>“Political <span>Compass</span> or <span>Spinning</span> <span>Arrow</span>? <span>Towards</span> <span>More</span> <span>Meaningful</span> <span>Evaluations</span> for <span>Values</span> and <span>Opinions</span> in <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.16786">http://arxiv.org/abs/2402.16786</a>.
</div>
<div id="ref-rozado_political_2023" class="csl-entry" role="listitem">
Rozado, David. 2023. <span>“The <span>Political</span> <span>Biases</span> of <span>ChatGPT</span>.”</span> <em>Social Sciences</em> 12 (3): 148. <a href="https://doi.org/10.3390/socsci12030148">https://doi.org/10.3390/socsci12030148</a>.
</div>
<div id="ref-rozado_political_2024" class="csl-entry" role="listitem">
———. 2024. <span>“The <span>Political</span> <span>Preferences</span> of <span>LLMs</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.01789">http://arxiv.org/abs/2402.01789</a>.
</div>
<div id="ref-saab_capabilities_2024" class="csl-entry" role="listitem">
Saab, Khaled, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, et al. 2024. <span>“Capabilities of <span>Gemini</span> <span>Models</span> in <span>Medicine</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.18416">http://arxiv.org/abs/2404.18416</a>.
</div>
<div id="ref-sastry_computing_2024" class="csl-entry" role="listitem">
Sastry, Girish, Lennart Heim, Haydn Belfield, Markus Anderljung, Miles Brundage, Julian Hazell, Cullen O’Keefe, et al. 2024. <span>“Computing <span>Power</span> and the <span>Governance</span> of <span>Artificial</span> <span>Intelligence</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.08797">http://arxiv.org/abs/2402.08797</a>.
</div>
<div id="ref-shumailov_curse_2023" class="csl-entry" role="listitem">
Shumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023. <span>“The <span>Curse</span> of <span>Recursion</span>: <span>Training</span> on <span>Generated</span> <span>Data</span> <span>Makes</span> <span>Models</span> <span>Forget</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2305.17493">http://arxiv.org/abs/2305.17493</a>.
</div>
<div id="ref-singhal_large_2023" class="csl-entry" role="listitem">
Singhal, Karan, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, et al. 2023. <span>“Large Language Models Encode Clinical Knowledge.”</span> <em>Nature</em> 620 (7972): 172–80. <a href="https://doi.org/10.1038/s41586-023-06291-2">https://doi.org/10.1038/s41586-023-06291-2</a>.
</div>
<div id="ref-sun_artificial_2023" class="csl-entry" role="listitem">
Sun, Jie, Qun-Xi Dong, San-Wang Wang, Yong-Bo Zheng, Xiao-Xing Liu, Tang-Sheng Lu, Kai Yuan, et al. 2023. <span>“Artificial Intelligence in Psychiatry Research, Diagnosis, and Therapy.”</span> <em>Asian Journal of Psychiatry</em> 87 (September): 103705. <a href="https://doi.org/10.1016/j.ajp.2023.103705">https://doi.org/10.1016/j.ajp.2023.103705</a>.
</div>
<div id="ref-tian_spreadsheetllm_2024" class="csl-entry" role="listitem">
Tian, Yuzhang, Jianbo Zhao, Haoyu Dong, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, et al. 2024. <span>“<span>SpreadsheetLLM</span>: <span>Encoding</span> <span>Spreadsheets</span> for <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2407.09025">http://arxiv.org/abs/2407.09025</a>.
</div>
<div id="ref-tu_towards_2024" class="csl-entry" role="listitem">
Tu, Tao, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, et al. 2024. <span>“Towards <span>Conversational</span> <span>Diagnostic</span> <span>AI</span>.”</span> <a href="https://doi.org/10.48550/ARXIV.2401.05654">https://doi.org/10.48550/ARXIV.2401.05654</a>.
</div>
<div id="ref-udandarao_no_2024" class="csl-entry" role="listitem">
Udandarao, Vishaal, Ameya Prabhu, Adhiraj Ghosh, Yash Sharma, Philip H. S. Torr, Adel Bibi, Samuel Albanie, and Matthias Bethge. 2024. <span>“No "<span>Zero</span>-<span>Shot</span>" <span>Without</span> <span>Exponential</span> <span>Data</span>: <span>Pretraining</span> <span>Concept</span> <span>Frequency</span> <span>Determines</span> <span>Multimodal</span> <span>Model</span> <span>Performance</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2404.04125">http://arxiv.org/abs/2404.04125</a>.
</div>
<div id="ref-villalobos_will_2022" class="csl-entry" role="listitem">
Villalobos, Pablo, Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius Hobbhahn, and Anson Ho. 2022. <span>“Will We Run Out of Data? <span>An</span> Analysis of the Limits of Scaling Datasets in <span>Machine</span> <span>Learning</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2211.04325">http://arxiv.org/abs/2211.04325</a>.
</div>
<div id="ref-wang_sam-octa_2023" class="csl-entry" role="listitem">
Wang, Chengliang, Xinrun Chen, Haojian Ning, and Shiying Li. 2023. <span>“<span>SAM</span>-<span>OCTA</span>: <span>A</span> <span>Fine</span>-<span>Tuning</span> <span>Strategy</span> for <span>Applying</span> <span>Foundation</span> <span>Model</span> to <span>OCTA</span> <span>Image</span> <span>Segmentation</span> <span>Tasks</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2309.11758">http://arxiv.org/abs/2309.11758</a>.
</div>
<div id="ref-wei_chain--thought_2023" class="csl-entry" role="listitem">
Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. <span>“Chain-of-<span>Thought</span> <span>Prompting</span> <span>Elicits</span> <span>Reasoning</span> in <span>Large</span> <span>Language</span> <span>Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2201.11903">http://arxiv.org/abs/2201.11903</a>.
</div>
<div id="ref-wei_long-form_2024" class="csl-entry" role="listitem">
Wei, Jerry, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, et al. 2024. <span>“Long-Form Factuality in Large Language Models.”</span> arXiv. <a href="http://arxiv.org/abs/2403.18802">http://arxiv.org/abs/2403.18802</a>.
</div>
<div id="ref-weiss_what_2024" class="csl-entry" role="listitem">
Weiss, Roy, Daniel Ayzenshteyn, Guy Amit, and Yisroel Mirsky. 2024. <span>“What <span>Was</span> <span>Your</span> <span>Prompt</span>? <span>A</span> <span>Remote</span> <span>Keylogging</span> <span>Attack</span> on <span>AI</span> <span>Assistants</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.09751">http://arxiv.org/abs/2403.09751</a>.
</div>
<div id="ref-wendler_llamas_2024" class="csl-entry" role="listitem">
Wendler, Chris, Veniamin Veselovsky, Giovanni Monea, and Robert West. 2024. <span>“Do <span>Llamas</span> <span>Work</span> in <span>English</span>? <span>On</span> the <span>Latent</span> <span>Language</span> of <span>Multilingual</span> <span>Transformers</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2402.10588">http://arxiv.org/abs/2402.10588</a>.
</div>
<div id="ref-wornow_shaky_2023" class="csl-entry" role="listitem">
Wornow, Michael, Yizhe Xu, Rahul Thapa, Birju Patel, Ethan Steinberg, Scott Fleming, Michael A. Pfeffer, Jason Fries, and Nigam H. Shah. 2023. <span>“The Shaky Foundations of Large Language Models and Foundation Models for Electronic Health Records.”</span> <em>Npj Digital Medicine</em> 6 (1): 135. <a href="https://doi.org/10.1038/s41746-023-00879-8">https://doi.org/10.1038/s41746-023-00879-8</a>.
</div>
<div id="ref-yiu_transmission_2023" class="csl-entry" role="listitem">
Yiu, Eunice, Eliza Kosoy, and Alison Gopnik. 2023. <span>“Transmission <span>Versus</span> <span>Truth</span>, <span>Imitation</span> <span>Versus</span> <span>Innovation</span>: <span>What</span> <span>Children</span> <span>Can</span> <span>Do</span> <span>That</span> <span>Large</span> <span>Language</span> and <span>Language</span>-and-<span>Vision</span> <span>Models</span> <span>Cannot</span> (<span>Yet</span>).”</span> <em>Perspectives on Psychological Science</em>, October, 17456916231201401. <a href="https://doi.org/10.1177/17456916231201401">https://doi.org/10.1177/17456916231201401</a>.
</div>
<div id="ref-yu_evaluating_2023" class="csl-entry" role="listitem">
Yu, Feiyang, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, Eduardo Kaiser Ururahy Nunes Fonseca, et al. 2023. <span>“Evaluating Progress in Automatic Chest <span>X</span>-Ray Radiology Report Generation.”</span> <em>Patterns</em> 4 (9): 100802. <a href="https://doi.org/10.1016/j.patter.2023.100802">https://doi.org/10.1016/j.patter.2023.100802</a>.
</div>
<div id="ref-zaleski_comprehensiveness_2024" class="csl-entry" role="listitem">
Zaleski, Amanda L, Rachel Berkowsky, Kelly Jean Thomas Craig, and Linda S Pescatello. 2024. <span>“Comprehensiveness, <span>Accuracy</span>, and <span>Readability</span> of <span>Exercise</span> <span>Recommendations</span> <span>Provided</span> by an <span>AI</span>-<span>Based</span> <span>Chatbot</span>: <span>Mixed</span> <span>Methods</span> <span>Study</span>.”</span> <em>JMIR Medical Education</em> 10 (January): e51308. <a href="https://doi.org/10.2196/51308">https://doi.org/10.2196/51308</a>.
</div>
<div id="ref-zhao_foundation_2024" class="csl-entry" role="listitem">
Zhao, Theodore, Yu Gu, Jianwei Yang, Naoto Usuyama, Ho Hin Lee, Sid Kiblawi, Tristan Naumann, et al. 2024. <span>“A Foundation Model for Joint Segmentation, Detection and Recognition of Biomedical Objects Across Nine Modalities.”</span> <em>Nature Methods</em>, November. <a href="https://doi.org/10.1038/s41592-024-02499-w">https://doi.org/10.1038/s41592-024-02499-w</a>.
</div>
<div id="ref-zhao_clip_2023" class="csl-entry" role="listitem">
Zhao, Zihao, Yuxiao Liu, Han Wu, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu, et al. 2023. <span>“<span>CLIP</span> in <span>Medical</span> <span>Imaging</span>: <span>A</span> <span>Comprehensive</span> <span>Survey</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2312.07353">http://arxiv.org/abs/2312.07353</a>.
</div>
<div id="ref-zheng_natural_2024" class="csl-entry" role="listitem">
Zheng, Huaixiu Steven, Swaroop Mishra, Hugh Zhang, Xinyun Chen, Minmin Chen, Azade Nova, Le Hou, et al. 2024. <span>“<span>NATURAL</span> <span>PLAN</span>: <span>Benchmarking</span> <span>LLMs</span> on <span>Natural</span> <span>Language</span> <span>Planning</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2406.04520">http://arxiv.org/abs/2406.04520</a>.
</div>
<div id="ref-zhou_webarena_2023" class="csl-entry" role="listitem">
Zhou, Shuyan, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, et al. 2023. <span>“<span>WebArena</span>: <span>A</span> <span>Realistic</span> <span>Web</span> <span>Environment</span> for <span>Building</span> <span>Autonomous</span> <span>Agents</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2307.13854">http://arxiv.org/abs/2307.13854</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/richardsprague\.github\.io\/people-capital\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch01.html" class="pagination-link" aria-label="The False Binary: Why AI Won't Replace Human Work">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The False Binary: Why AI Won’t Replace Human Work</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch03.html" class="pagination-link" aria-label="The What-How Divide">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025 People+Capital, LLC</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>