<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; The Human Edge ‚Äì The Human Element</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch06.html" rel="next">
<link href="./Ch04.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-626149efe8f5d16e1d391ba177679bf0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="_resources/css/normalize.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch05.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Human Edge</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">The Human Element</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./The-Human-Element.docx">
              <i class="bi bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The False Binary: Why AI Won‚Äôt Replace Human Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inside the Black Box: Understanding What AI Actually Does</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The What-How Divide</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beyond Computation: The Philosophy of Human Intelligence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch05.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Human Edge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Finding the Sweet Spot</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Implementation Challenge</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Human Element in Creative Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Following the Money</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Building the Future: A Human-Centric Vision for AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">About the Authors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-uniqueness-of-human-judgment" id="toc-the-uniqueness-of-human-judgment" class="nav-link active" data-scroll-target="#the-uniqueness-of-human-judgment"><span class="header-section-number">5.1</span> The Uniqueness of Human Judgment</a></li>
  <li><a href="#the-architecture-of-judgment" id="toc-the-architecture-of-judgment" class="nav-link" data-scroll-target="#the-architecture-of-judgment"><span class="header-section-number">5.2</span> The Architecture of Judgment</a></li>
  <li><a href="#the-what-how-divide-in-professional-contexts" id="toc-the-what-how-divide-in-professional-contexts" class="nav-link" data-scroll-target="#the-what-how-divide-in-professional-contexts"><span class="header-section-number">5.3</span> The ‚ÄúWhat-How‚Äù Divide in Professional Contexts</a></li>
  <li><a href="#decision-making-under-uncertainty" id="toc-decision-making-under-uncertainty" class="nav-link" data-scroll-target="#decision-making-under-uncertainty"><span class="header-section-number">5.4</span> Decision-Making Under Uncertainty</a></li>
  <li><a href="#the-enhancement-framework-revisited" id="toc-the-enhancement-framework-revisited" class="nav-link" data-scroll-target="#the-enhancement-framework-revisited"><span class="header-section-number">5.5</span> The Enhancement Framework Revisited</a></li>
  <li><a href="#the-philosophical-stakes" id="toc-the-philosophical-stakes" class="nav-link" data-scroll-target="#the-philosophical-stakes"><span class="header-section-number">5.6</span> The Philosophical Stakes</a></li>
  <li><a href="#investment-implications" id="toc-investment-implications" class="nav-link" data-scroll-target="#investment-implications"><span class="header-section-number">5.7</span> Investment Implications</a></li>
  <li><a href="#judgment-as-competitive-advantage" id="toc-judgment-as-competitive-advantage" class="nav-link" data-scroll-target="#judgment-as-competitive-advantage"><span class="header-section-number">5.8</span> Judgment as Competitive Advantage</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Human Edge</span></h1>
<p class="subtitle lead">Judgment in an Age of Algorithms</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In an era increasingly defined by algorithmic processing, the question of human judgment‚Äôs unique value becomes not merely philosophical but practical. The rapid advancement of artificial intelligence has created a peculiar paradox: as machines become more capable of executing sophisticated tasks, the most distinctly human capacities become more valuable, not less. To understand this paradox requires careful examination of what constitutes judgment and why it remains stubbornly resistant to computational replication.</p>
<section id="the-uniqueness-of-human-judgment" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="the-uniqueness-of-human-judgment"><span class="header-section-number">5.1</span> The Uniqueness of Human Judgment</h2>
<p>Recall the ambitious attempt to create Beethoven‚Äôs unfinished tenth symphony using artificial intelligence. The project, undertaken by Playform AI, represented a perfect test case for understanding the boundaries between algorithmic production and human creation. The team trained sophisticated models on Beethoven‚Äôs complete works, incorporating fragments and sketches the composer had left for his tenth symphony. The result was technically proficient‚Äînotes arranged in patterns statistically consistent with Beethoven‚Äôs compositional style. Yet something essential was missing.</p>
<p>Music critic Jan Swafford‚Äôs assessment was unequivocal: ‚Äúaimless and uninspired.‚Äù What Swafford identified was not merely technical deficiency but the absence of struggle, refinement, and contextual understanding that characterized Beethoven‚Äôs actual creative process. The composer‚Äôs drafts were often mundane until transformed through iterative revision guided by judgment‚Äîa quality that emerges from being situated in a cultural, historical, and emotional context that no algorithm, however sophisticated, currently inhabits.</p>
<p>This observation extends beyond music. Across domains‚Äîfrom sports to business leadership, from medical diagnosis to strategic planning‚Äîwe find consistent evidence that human judgment operates differently from algorithmic processing. The difference lies not merely in computational capacity but in the nature of understanding itself.</p>
<p>As discussed in chapter four, Martin Heidegger‚Äôs philosophical framework provides valuable insight here. Heidegger challenged the Cartesian notion that human intelligence is primarily computational, arguing instead that our fundamental relationship with the world is one of ‚Äúbeing-in-the-world‚Äù (Dasein). From this perspective, understanding emerges not from abstract calculation but from practical engagement with a meaningful context. Humans do not process the world as detached observers calculating optimal responses; rather, we inhabit it as participants whose very perception is structured by practical concerns and possibilities.</p>
<p>When we navigate complex situations‚Äîwhether negotiating a business deal, diagnosing an unusual medical condition, or responding to unexpected market shifts‚Äîwe draw upon this embodied understanding. We recognize patterns not as statistical correlations but as meaningful constellations of relevance. This capacity for situated judgment represents what philosopher Hubert Dreyfus, interpreting Heidegger, called ‚Äúcomportment‚Äù‚Äîan orientation toward the world that precedes and enables explicit reasoning.</p>
<p>Artificial intelligence systems, while increasingly sophisticated in their pattern recognition capabilities, operate fundamentally differently. They recognize statistical regularities without inhabiting the human world of concerns and commitments. This distinction becomes apparent when examining the architecture of both human and algorithmic judgment.</p>
</section>
<section id="the-architecture-of-judgment" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-architecture-of-judgment"><span class="header-section-number">5.2</span> The Architecture of Judgment</h2>
<p>Human judgment integrates multiple dimensions of understanding that current AI systems struggle to replicate. Large language models (LLMs) represent state-of-the-art capabilities in natural language processing. These systems excel at pattern recognition and statistical inference but encounter fundamental limitations when faced with tasks requiring genuine understanding.</p>
<p>The inability of LLMs to ‚Äúbacktrack‚Äù‚Äîto revise fundamental assumptions mid-stream‚Äîrepresents more than a technical limitation. It reveals a structural difference between statistical pattern completion and genuine understanding. When humans engage in complex reasoning, we constantly revise our approach based on emerging information, testing alternative frames of reference and adjusting our conceptual foundations. This capacity for recursive self-correction reflects our temporality‚Äîour ability to hold past, present, and future in dynamic tension.</p>
<p>For example, when confronted with the task of writing ‚Äúa sentence that describes its own length in words,‚Äù LLMs consistently fail despite their impressive capabilities. The task requires not merely statistical inference but meta-cognitive awareness‚Äîthe ability to simultaneously generate content while monitoring and adjusting that content against an evolving standard. This capacity for self-reference and dynamic adjustment characterizes human judgment across domains.</p>
<p>Equally significant is what philosopher Michael Polanyi termed ‚Äútacit knowledge‚Äù‚Äîunderstanding that cannot be fully articulated in explicit terms. Expert clinicians recognize patterns of disease before they can articulate the specific indicators that triggered their concern. Experienced investors sense market shifts through subtle cues that precede formal indicators. This dimension of understanding emerges from embodied experience accumulated over years of immersion in particular contexts.</p>
<p>The distinction parallels what we might call the ‚Äúwhat-how‚Äù divide in contemporary knowledge work. Artificial intelligence excels at executing ‚Äúhow‚Äù tasks‚Äîimplementing specific procedures once objectives have been defined. The increasing capability of AI systems to execute these procedural tasks generates enormous efficiency gains across industries. Yet these gains simultaneously increase the premium on ‚Äúwhat‚Äù intelligence‚Äîthe capacity to determine meaningful objectives, frame problems effectively, and identify relevant contexts for analysis.</p>
</section>
<section id="the-what-how-divide-in-professional-contexts" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="the-what-how-divide-in-professional-contexts"><span class="header-section-number">5.3</span> The ‚ÄúWhat-How‚Äù Divide in Professional Contexts</h2>
<p>Financial markets provide a particularly instructive domain for examining this distinction. Quantitative models have transformed investment management, enabling sophisticated analysis of vast datasets and revealing patterns invisible to unaided human perception. Yet the most successful investment approaches typically integrate algorithmic analysis with human judgment rather than replacing the latter with the former.</p>
<p>This integration recognizes that market behavior reflects not merely mathematical relationships but complex human psychology, institutional dynamics, and contextual factors that resist complete formalization. Both the 1998 collapse of Long Term Capital and the 2008 financial crisis illustrated the dangers of excessive reliance on quantitative models that failed to account for human behavior under exceptional conditions. Similarly, the unprecedented monetary interventions following the COVID-19 pandemic created market conditions that defied historical patterns, requiring judgment to navigate effectively.</p>
<p>The most sophisticated hedge funds and investment firms have therefore developed what might be termed ‚Äújudgment architectures‚Äù‚Äîorganizational structures that integrate algorithmic processing with human expertise. These architectures recognize that algorithms excel at processing vast datasets and identifying statistical patterns, while human judgment excels at integrating these patterns with broader contextual understanding and adapting to novel situations. Investment firms that were successful navigating the 1998 and 2008 crises recognized that human intervention was indispensable to handle unique situations. Yet it is those situations that differentiate an outstanding investor from one who is merely competent.</p>
<p>Similar patterns emerge in technical implementation across industries.Think for example of the arduous development of fully autonomous vehicles, easily one of the most ambitious applications of artificial intelligence to real-world problems. Despite massive investments and impressive technical achievements, full autonomy remains elusive in complex, unpredictable environments. Today, autonomous vehicle can manage trips that are relatively easy and uneventful, say an orderly turn on a quiet road or an exit from a highway, but they still struggle and are accident-prone when an expected situation emerges, say if a pedestrian suddenly emerges in the car‚Äôs path.</p>
<p>The challenges facing autonomous vehicle systems reveal the limitations of purely algorithmic approaches to navigation and decision-making. While these systems excel at processing sensor data and executing well-defined maneuvers, they struggle with the contextual understanding that human drivers develop through embodied experience. A human driver intuitively recognizes that children playing near a street require extra caution, that an unusually positioned vehicle might indicate an unseen hazard, or that specific weather conditions might affect road surfaces in ways not immediately visible.</p>
<p>Rodney Brooks, robotics pioneer and former director of MIT‚Äôs Computer Science and Artificial Intelligence Laboratory, has consistently emphasized these limitations. His predictions regarding autonomous vehicle development have proven remarkably accurate, with full autonomy consistently arriving later than industry projections. Brooks understands that navigating physical environments requires not merely sophisticated sensors and algorithms but contextual understanding that emerges from being situated in a meaningful world.</p>
</section>
<section id="decision-making-under-uncertainty" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="decision-making-under-uncertainty"><span class="header-section-number">5.4</span> Decision-Making Under Uncertainty</h2>
<p>Perhaps the most significant advantage of human judgment becomes apparent under conditions of genuine uncertainty. Algorithmic approaches excel at optimizing decisions under risk‚Äîsituations where potential outcomes and their probabilities can be reasonably estimated. They struggle, however, with uncertainty‚Äîsituations involving unknown variables, emergent phenomena, and fundamental indeterminacy.</p>
<p>This distinction becomes particularly relevant in domains characterized by complexity, path dependency, and human interaction. In planning a pandemic response for example, initial frameworks must adapt to evolving viral behavior, social dynamics, and institutional constraints. The COVID-19 pandemic revealed both the value of algorithmic modeling and its limitations when confronting genuinely novel situations. The most effective responses integrated computational modeling with expert judgment that could adapt to emerging information and contextual factors.</p>
<p>The limitations of purely algorithmic approaches under uncertainty relate to what we might call the ‚Äúparadox of explicability.‚Äù Organizations increasingly demand explainable AI‚Äîsystems whose recommendations can be traced to transparent reasoning processes. Yet humans routinely trust human experts whose intuitive judgments cannot be fully articulated and that may appear opaque to a layperson. We accept that an experienced physician‚Äôs concern might precede explicit justification or that a seasoned investor‚Äôs caution might reflect pattern recognition too subtle for immediate expression.</p>
<p>This asymmetric standard constitutes the ultimate ‚Äúhuman edge‚Äù and it reflects an implicit understanding that human judgment operates differently from algorithmic processing. We recognize that human experts integrate explicit knowledge with tacit understanding developed through situated experience. This integration enables what philosopher Charles Sanders Peirce termed ‚Äúabduction‚Äù‚Äîthe generation of novel hypotheses that cannot be derived through purely deductive or inductive reasoning.</p>
<p>The capacity for abductive reasoning becomes particularly valuable when confronting black swan events‚Äîhigh-impact developments that lie outside normal expectations and resist prediction through historical analysis. The financial market disruptions following the 2001 terrorist attacks, the 2008 financial crisis, and the COVID-19 pandemic each required judgment that could transcend historical patterns and recognize emergent possibilities.</p>
</section>
<section id="the-enhancement-framework-revisited" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="the-enhancement-framework-revisited"><span class="header-section-number">5.5</span> The Enhancement Framework Revisited</h2>
<p>Understanding these distinctive capacities allows us to develop more effective approaches to human-AI collaboration. Rather than conceptualizing artificial intelligence as a replacement for human judgment, we can design systems that enhance human capabilities by performing complementary functions. This enhancement framework acknowledges the distinctive strengths of both human judgment and algorithmic processing. Simply put, AI can enhance, accelerate and facilitate a lot of work, but it cannot perform at the same standard of excellence of top human experts.</p>
<p>Effective enhancement requires careful attention to interface design, workflow integration, and organizational architecture. Systems that increase cognitive load or interrupt natural decision processes can impair rather than enhance judgment. Conversely, well-designed systems can augment human capabilities by performing computational tasks that would otherwise consume attention, presenting relevant information at appropriate moments, and identifying patterns that might escape notice.</p>
<p>Palantir Technologies offers an instructive example of this approach. The company‚Äôs data integration platforms serve intelligence agencies, financial institutions, and healthcare organizations by augmenting rather than replacing analyst judgment. These systems enable human analysts to navigate vast datasets efficiently, identify relevant patterns, and develop insights that inform strategic decisions. The resulting ‚Äúintelligence augmentation‚Äù preserves human judgment while enhancing the informational context within which that judgment operates.</p>
<p>Similar principles apply across domains. In healthcare, diagnostic support systems have proven most effective when designed to augment rather than replace physician judgment. These systems can identify potential conditions based on symptom patterns, suggest relevant tests, and provide reference information while preserving the physician‚Äôs capacity to integrate these inputs with clinical observation and patient context.</p>
<p>Maintaining this balance requires organizational cultures and training protocols that preserve ‚Äújudgment muscles‚Äù rather than allowing atrophy through excessive automation. Just as physical skills deteriorate without practice, judgment capacities require regular exercise to maintain effectiveness. Organizations that excessively automate routine decisions may inadvertently undermine the expertise development that enables effective judgment in non-routine situations.</p>
</section>
<section id="the-philosophical-stakes" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="the-philosophical-stakes"><span class="header-section-number">5.6</span> The Philosophical Stakes</h2>
<p>The distinction between enhancement and replacement frameworks reflects deeper philosophical questions about authenticity and agency in an algorithmic age. As artificial intelligence systems generate increasingly sophisticated outputs‚Äîfrom business analyses to creative content‚Äîwe confront questions about the value of human contribution and the nature of meaningful work.</p>
<p>Consider the emerging phenomenon of AI-generated content that appears ‚Äútoo perfect‚Äù in its technical execution while lacking the distinctive voice that characterizes human expression. This perfection paradoxically signals inauthenticity‚Äîan absence of the individual perspective and situated understanding that give human communication its distinctive character. We value human content not despite but partially because of its imperfections, which signal authentic engagement with the messiness of lived experience. In some fields, we could say that the human is great because he/she is imperfect, and not robotic.</p>
<p>This observation connects to Heidegger‚Äôs critique of technology as potentially obscuring authentic human engagement with the world. The danger lies not in technological advancement itself but in frameworks that position technology as a replacement for rather than an enhancement of distinctively human capacities. When we conceptualize artificial intelligence primarily as a substitute for human judgment, we risk undermining the very qualities that give work meaning and enable effective navigation of complex environments.</p>
<p>Contemporary philosophical approaches, including extended cognition and enactivist theories of mind, offer valuable resources for reconciling technological enhancement with authentic human agency. These frameworks recognize that human cognition has always been extended through tools‚Äîfrom writing implements to computational devices‚Äîwithout thereby becoming less authentically human. The question becomes not whether to integrate algorithmic processing into human work but how to do so in ways that preserve and enhance rather than diminish human judgment.</p>
</section>
<section id="investment-implications" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="investment-implications"><span class="header-section-number">5.7</span> Investment Implications</h2>
<p>These philosophical considerations have practical implications for investment strategy in an age of advancing artificial intelligence. Companies developing AI applications fall broadly into two categories: those pursuing replacement frameworks that aim to automate human judgment, and those pursuing enhancement frameworks that aim to augment human capabilities. The latter category may offer more sustainable competitive advantages and resilient business models.</p>
<p>Several factors favor enhancement-focused approaches:</p>
<ol type="1">
<li><p>Regulatory frameworks increasingly demand human oversight for high-stakes decisions, creating persistent demand for human-in-the-loop systems in healthcare, financial services, and other regulated industries.</p></li>
<li><p>Enhancement approaches align with organizational preferences for incremental transformation rather than disruptive replacement, facilitating adoption and integration.</p></li>
<li><p>Enhancement frameworks leverage existing human expertise while improving efficiency, creating immediate value rather than requiring complete transformation of workflows.</p></li>
<li><p>The limitations of purely algorithmic approaches to complex, uncertain environments create persistent demand for human judgment in strategic roles.</p></li>
</ol>
<p>These factors suggest that the most durable competitive advantages may emerge from technologies that enhance rather than replace human judgment, and from the addition of human inputs to these technologies in ways that yield greater results. Vector databases represent one such technology, enabling more effective knowledge management by organizing information according to conceptual relevance rather than merely textual similarity. These systems enhance human capabilities by making relevant information more accessible without attempting to replace the judgment that determines how that information should be applied.</p>
<p>Similar opportunities exist across sectors. Healthcare technologies that enhance physician capabilities while preserving clinical judgment may prove more sustainable than those pursuing full automation of diagnostic processes. Financial technologies that augment analyst capabilities while preserving strategic judgment may outperform those attempting to replace human decision-making entirely. Educational technologies that enhance teacher effectiveness while preserving pedagogical judgment may demonstrate greater durability than those positioning technology as a replacement for human instruction.</p>
</section>
<section id="judgment-as-competitive-advantage" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="judgment-as-competitive-advantage"><span class="header-section-number">5.8</span> Judgment as Competitive Advantage</h2>
<p>The paradox of advancing artificial intelligence is that it simultaneously commoditizes certain skills while increasing the premium on distinctively human judgment. As procedural tasks become increasingly automated, the capacity to frame problems effectively, identify relevant contexts, and navigate uncertainty becomes more valuable, not less. This pattern suggests that developing judgment capacity‚Äîboth individual and organizational‚Äîrepresents a sustainable competitive advantage in an algorithmic age.</p>
<p>The enhancement framework provides a guide for navigating this transformation effectively. By conceptualizing artificial intelligence as augmenting rather than replacing human judgment, organizations can leverage technological capabilities while preserving the distinctive capacities that enable effective navigation of complex, uncertain environments. This approach recognizes that the most valuable form of intelligence emerges not from either human or algorithmic processing in isolation but from their thoughtful integration.</p>
<p>The future belongs not to those who seek to replicate human judgment but to those who enhance it‚Äîpreserving the human element in an increasingly algorithmic world. This is in fact the human advantage that cannot be replicated by AI, the ultimate human edge.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abdin_phi-3_2024" class="csl-entry" role="listitem">
Abdin, Marah, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, et al. 2024. <span>‚ÄúPhi-3 <span>Technical</span> <span>Report</span>: <span>A</span> <span>Highly</span> <span>Capable</span> <span>Language</span> <span>Model</span> <span>Locally</span> on <span>Your</span> <span>Phone</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2404.14219">http://arxiv.org/abs/2404.14219</a>.
</div>
<div id="ref-ai_yi_2024" class="csl-entry" role="listitem">
AI, 01, Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, et al. 2024. <span>‚ÄúYi: <span>Open</span> <span>Foundation</span> <span>Models</span> by 01.<span>AI</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.04652">http://arxiv.org/abs/2403.04652</a>.
</div>
<div id="ref-alamdari_protein_2023" class="csl-entry" role="listitem">
Alamdari, Sarah, Nitya Thakkar, Rianne Van Den Berg, Alex Xijie Lu, Nicolo Fusi, Ava Pardis Amini, and Kevin K Yang. 2023. <span>‚ÄúProtein Generation with Evolutionary Diffusion: Sequence Is All You Need.‚Äù</span> Preprint. Bioengineering. <a href="https://doi.org/10.1101/2023.09.11.556673">https://doi.org/10.1101/2023.09.11.556673</a>.
</div>
<div id="ref-bender_dangers_2021" class="csl-entry" role="listitem">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>‚ÄúOn the <span>Dangers</span> of <span>Stochastic</span> <span>Parrots</span>: <span>Can</span> <span>Language</span> <span>Models</span> <span>Be</span> <span>Too</span> <span>Big</span>? ü¶ú.‚Äù</span> In <em>Proceedings of the 2021 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 610‚Äì23. Virtual Event Canada: ACM. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-berglund_reversal_2023" class="csl-entry" role="listitem">
Berglund, Lukas, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023. <span>‚ÄúThe <span>Reversal</span> <span>Curse</span>: <span>LLMs</span> Trained on "<span>A</span> Is <span>B</span>" Fail to Learn "<span>B</span> Is <span>A</span>".‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a>.
</div>
<div id="ref-bsharat_principled_2023" class="csl-entry" role="listitem">
Bsharat, Sondos Mahmoud, Aidar Myrzakhan, and Zhiqiang Shen. 2023. <span>‚ÄúPrincipled <span>Instructions</span> <span>Are</span> <span>All</span> <span>You</span> <span>Need</span> for <span>Questioning</span> <span>LLaMA</span>-1/2, <span>GPT</span>-3.5/4.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2312.16171">http://arxiv.org/abs/2312.16171</a>.
</div>
<div id="ref-burtch_consequences_2024" class="csl-entry" role="listitem">
Burtch, Gordon, Dokyun Lee, and Zhichen Chen. 2024. <span>‚ÄúThe Consequences of Generative <span>AI</span> for Online Knowledge Communities.‚Äù</span> <em>Scientific Reports</em> 14 (1): 10413. <a href="https://doi.org/10.1038/s41598-024-61221-0">https://doi.org/10.1038/s41598-024-61221-0</a>.
</div>
<div id="ref-butlin_consciousness_2023" class="csl-entry" role="listitem">
Butlin, Patrick, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, et al. 2023. <span>‚ÄúConsciousness in <span>Artificial</span> <span>Intelligence</span>: <span>Insights</span> from the <span>Science</span> of <span>Consciousness</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2308.08708">https://doi.org/10.48550/ARXIV.2308.08708</a>.
</div>
<div id="ref-carlini_stealing_2024" class="csl-entry" role="listitem">
Carlini, Nicholas, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, et al. 2024. <span>‚ÄúStealing <span>Part</span> of a <span>Production</span> <span>Language</span> <span>Model</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.06634">http://arxiv.org/abs/2403.06634</a>.
</div>
<div id="ref-chang_speak_2023" class="csl-entry" role="listitem">
Chang, Kent K., Mackenzie Cramer, Sandeep Soni, and David Bamman. 2023a. <span>‚ÄúSpeak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2305.00118">https://doi.org/10.48550/ARXIV.2305.00118</a>.
</div>
<div id="ref-chang_speak_2023-1" class="csl-entry" role="listitem">
‚Äî‚Äî‚Äî. 2023b. <span>‚ÄúSpeak, <span>Memory</span>: <span>An</span> <span>Archaeology</span> of <span>Books</span> <span>Known</span> to <span>ChatGPT</span>/<span>GPT</span>-4.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2305.00118">http://arxiv.org/abs/2305.00118</a>.
</div>
<div id="ref-de__fauw_clinically_2018" class="csl-entry" role="listitem">
De Fauw, Jeffrey, Joseph R. Ledsam, Bernardino Romera-Paredes, Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham, et al. 2018. <span>‚ÄúClinically Applicable Deep Learning for Diagnosis and Referral in Retinal Disease.‚Äù</span> <em>Nature Medicine</em> 24 (9): 1342‚Äì50. <a href="https://doi.org/10.1038/s41591-018-0107-6">https://doi.org/10.1038/s41591-018-0107-6</a>.
</div>
<div id="ref-di_palma_evaluating_2023" class="csl-entry" role="listitem">
Di Palma, Dario, Giovanni Maria Biancofiore, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia, and Eugenio Di Sciascio. 2023. <span>‚ÄúEvaluating <span>ChatGPT</span> as a <span>Recommender</span> <span>System</span>: <span>A</span> <span>Rigorous</span> <span>Approach</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.03613">http://arxiv.org/abs/2309.03613</a>.
</div>
<div id="ref-dodge_documenting_2021" class="csl-entry" role="listitem">
Dodge, Jesse, Maarten Sap, Ana Marasoviƒá, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. <span>‚ÄúDocumenting <span>Large</span> <span>Webtext</span> <span>Corpora</span>: <span>A</span> <span>Case</span> <span>Study</span> on the <span>Colossal</span> <span>Clean</span> <span>Crawled</span> <span>Corpus</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2104.08758">https://doi.org/10.48550/ARXIV.2104.08758</a>.
</div>
<div id="ref-dreyfus_why_2007" class="csl-entry" role="listitem">
Dreyfus, Hubert L. 2007. <span>‚ÄúWhy <span>Heideggerian</span> <span>AI</span> <span>Failed</span> and <span>How</span> <span>Fixing</span> It <span>Would</span> <span>Require</span> <span>Making</span> It <span>More</span> <span>Heideggerian</span>.‚Äù</span> <em>Philosophical Psychology</em> 20 (2): 247‚Äì68. <a href="https://doi.org/10.1080/09515080701239510">https://doi.org/10.1080/09515080701239510</a>.
</div>
<div id="ref-epoch_ai_data_2024" class="csl-entry" role="listitem">
Epoch AI. 2024. <span>‚ÄúData on <span>Large</span> <span>Language</span> <span>AI</span> <span>Models</span>.‚Äù</span> <a href="https://epochai.org/data/large-scale-ai-models">https://epochai.org/data/large-scale-ai-models</a>.
</div>
<div id="ref-erdil_explosive_2024" class="csl-entry" role="listitem">
Erdil, Ege, and Tamay Besiroglu. 2024. <span>‚ÄúExplosive Growth from <span>AI</span> Automation: <span>A</span> Review of the Arguments.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.11690">http://arxiv.org/abs/2309.11690</a>.
</div>
<div id="ref-esteva_guide_2019" class="csl-entry" role="listitem">
Esteva, Andre, Alexandre Robicquet, Bharath Ramsundar, Volodymyr Kuleshov, Mark DePristo, Katherine Chou, Claire Cui, Greg Corrado, Sebastian Thrun, and Jeff Dean. 2019. <span>‚ÄúA Guide to Deep Learning in Healthcare.‚Äù</span> <em>Nature Medicine</em> 25 (1): 24‚Äì29. <a href="https://doi.org/10.1038/s41591-018-0316-z">https://doi.org/10.1038/s41591-018-0316-z</a>.
</div>
<div id="ref-feng_pretraining_2023" class="csl-entry" role="listitem">
Feng, Shangbin, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov. 2023. <span>‚ÄúFrom <span>Pretraining</span> <span>Data</span> to <span>Language</span> <span>Models</span> to <span>Downstream</span> <span>Tasks</span>: <span>Tracking</span> the <span>Trails</span> of <span>Political</span> <span>Biases</span> <span>Leading</span> to <span>Unfair</span> <span>NLP</span> <span>Models</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2305.08283">https://doi.org/10.48550/ARXIV.2305.08283</a>.
</div>
<div id="ref-goh_large_2024" class="csl-entry" role="listitem">
Goh, Ethan, Robert Gallo, Jason Hom, Eric Strong, Yingjie Weng, Hannah Kerman, Jos√©phine A. Cool, et al. 2024. <span>‚ÄúLarge <span>Language</span> <span>Model</span> <span>Influence</span> on <span>Diagnostic</span> <span>Reasoning</span>: <span>A</span> <span>Randomized</span> <span>Clinical</span> <span>Trial</span>.‚Äù</span> <em>JAMA Network Open</em> 7 (10): e2440969. <a href="https://doi.org/10.1001/jamanetworkopen.2024.40969">https://doi.org/10.1001/jamanetworkopen.2024.40969</a>.
</div>
<div id="ref-grossmann_ai_2023" class="csl-entry" role="listitem">
Grossmann, Igor, Matthew Feinberg, Dawn C. Parker, Nicholas A. Christakis, Philip E. Tetlock, and William A. Cunningham. 2023. <span>‚Äú<span>AI</span> and the Transformation of Social Science Research.‚Äù</span> <em>Science</em> 380 (6650): 1108‚Äì9. <a href="https://doi.org/10.1126/science.adi1778">https://doi.org/10.1126/science.adi1778</a>.
</div>
<div id="ref-gupta_calm_2023" class="csl-entry" role="listitem">
Gupta, Vipul, Pranav Narayanan Venkit, Hugo Lauren√ßon, Shomir Wilson, and Rebecca J. Passonneau. 2023. <span>‚Äú<span>CALM</span> : <span>A</span> <span>Multi</span>-Task <span>Benchmark</span> for <span>Comprehensive</span> <span>Assessment</span> of <span>Language</span> <span>Model</span> <span>Bias</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a>.
</div>
<div id="ref-he_foundation_2024" class="csl-entry" role="listitem">
He, Yuting, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, and Hao Chen. 2024. <span>‚ÄúFoundation <span>Model</span> for <span>Advancing</span> <span>Healthcare</span>: <span>Challenges</span>, <span>Opportunities</span>, and <span>Future</span> <span>Directions</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2404.03264">http://arxiv.org/abs/2404.03264</a>.
</div>
<div id="ref-hendy_how_2023" class="csl-entry" role="listitem">
Hendy, Amr, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. <span>‚ÄúHow <span>Good</span> <span>Are</span> <span>GPT</span> <span>Models</span> at <span>Machine</span> <span>Translation</span>? <span>A</span> <span>Comprehensive</span> <span>Evaluation</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2302.09210">http://arxiv.org/abs/2302.09210</a>.
</div>
<div id="ref-hicks_chatgpt_2024" class="csl-entry" role="listitem">
Hicks, Michael Townsen, James Humphries, and Joe Slater. 2024. <span>‚Äú<span>ChatGPT</span> Is Bullshit.‚Äù</span> <em>Ethics and Information Technology</em> 26 (2): 38. <a href="https://doi.org/10.1007/s10676-024-09775-5">https://doi.org/10.1007/s10676-024-09775-5</a>.
</div>
<div id="ref-hoffmann_training_2022" class="csl-entry" role="listitem">
Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <span>‚ÄúTraining <span>Compute</span>-<span>Optimal</span> <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2203.15556">http://arxiv.org/abs/2203.15556</a>.
</div>
<div id="ref-hopkins_artificial_2023" class="csl-entry" role="listitem">
Hopkins, Ashley M, Jessica M Logan, Ganessan Kichenadasse, and Michael J Sorich. 2023. <span>‚ÄúArtificial Intelligence Chatbots Will Revolutionize How Cancer Patients Access Information: <span>ChatGPT</span> Represents a Paradigm-Shift.‚Äù</span> <em>JNCI Cancer Spectrum</em> 7 (2): pkad010. <a href="https://doi.org/10.1093/jncics/pkad010">https://doi.org/10.1093/jncics/pkad010</a>.
</div>
<div id="ref-hristidis_chatgpt_2023" class="csl-entry" role="listitem">
Hristidis, Vagelis, Nicole Ruggiano, Ellen L Brown, Sai Rithesh Reddy Ganta, and Selena Stewart. 2023. <span>‚Äú<span>ChatGPT</span> Vs <span>Google</span> for <span>Queries</span> <span>Related</span> to <span>Dementia</span> and <span>Other</span> <span>Cognitive</span> <span>Decline</span>: <span>Comparison</span> of <span>Results</span>.‚Äù</span> <em>Journal of Medical Internet Research</em> 25 (July): e48966. <a href="https://doi.org/10.2196/48966">https://doi.org/10.2196/48966</a>.
</div>
<div id="ref-huang_propaganda_2013" class="csl-entry" role="listitem">
Huang, Haifeng, and Zhi Li. 2013. <span>‚ÄúPropaganda and <span>Signaling</span>.‚Äù</span> <em>SSRN Electronic Journal</em>. <a href="https://doi.org/10.2139/ssrn.2325101">https://doi.org/10.2139/ssrn.2325101</a>.
</div>
<div id="ref-huang_crispr-gpt_2024" class="csl-entry" role="listitem">
Huang, Kaixuan, Yuanhao Qu, Henry Cousins, William A. Johnson, Di Yin, Mihir Shah, Denny Zhou, Russ Altman, Mengdi Wang, and Le Cong. 2024. <span>‚Äú<span>CRISPR</span>-<span>GPT</span>: <span>An</span> <span>LLM</span> <span>Agent</span> for <span>Automated</span> <span>Design</span> of <span>Gene</span>-<span>Editing</span> <span>Experiments</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2404.18021">http://arxiv.org/abs/2404.18021</a>.
</div>
<div id="ref-jackson_exposure_2023" class="csl-entry" role="listitem">
Jackson, Joshua Conrad, Kai Chi Yam, Pok Man Tang, Chris G. Sibley, and Adam Waytz. 2023. <span>‚ÄúExposure to Automation Explains Religious Declines.‚Äù</span> <em>Proceedings of the National Academy of Sciences</em> 120 (34): e2304748120. <a href="https://doi.org/10.1073/pnas.2304748120">https://doi.org/10.1073/pnas.2304748120</a>.
</div>
<div id="ref-jin_darkbert_2023" class="csl-entry" role="listitem">
Jin, Youngjin, Eugene Jang, Jian Cui, Jin-Woo Chung, Yongjae Lee, and Seungwon Shin. 2023. <span>‚Äú<span>DarkBERT</span>: <span>A</span> <span>Language</span> <span>Model</span> for the <span>Dark</span> <span>Side</span> of the <span>Internet</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2305.08596">https://doi.org/10.48550/ARXIV.2305.08596</a>.
</div>
<div id="ref-jing_alphafold_2024" class="csl-entry" role="listitem">
Jing, Bowen, Bonnie Berger, and Tommi Jaakkola. 2024. <span>‚Äú<span>AlphaFold</span> <span>Meets</span> <span>Flow</span> <span>Matching</span> for <span>Generating</span> <span>Protein</span> <span>Ensembles</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.04845">http://arxiv.org/abs/2402.04845</a>.
</div>
<div id="ref-kaddour_challenges_2023" class="csl-entry" role="listitem">
Kaddour, Jean, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023. <span>‚ÄúChallenges and <span>Applications</span> of <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2307.10169">https://doi.org/10.48550/ARXIV.2307.10169</a>.
</div>
<div id="ref-kallini_mission_2024" class="csl-entry" role="listitem">
Kallini, Julie, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, and Christopher Potts. 2024. <span>‚ÄúMission: <span>Impossible</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2401.06416">http://arxiv.org/abs/2401.06416</a>.
</div>
<div id="ref-kanjee_accuracy_2023" class="csl-entry" role="listitem">
Kanjee, Zahir, Byron Crowe, and Adam Rodman. 2023. <span>‚ÄúAccuracy of a <span>Generative</span> <span>Artificial</span> <span>Intelligence</span> <span>Model</span> in a <span>Complex</span> <span>Diagnostic</span> <span>Challenge</span>.‚Äù</span> <em>JAMA</em> 330 (1): 78. <a href="https://doi.org/10.1001/jama.2023.8288">https://doi.org/10.1001/jama.2023.8288</a>.
</div>
<div id="ref-kaufman_acoustic_2023" class="csl-entry" role="listitem">
Kaufman, Jaycee M., Anirudh Thommandram, and Yan Fossat. 2023. <span>‚ÄúAcoustic <span>Analysis</span> and <span>Prediction</span> of <span>Type</span> 2 <span>Diabetes</span> <span>Mellitus</span> <span>Using</span> <span>Smartphone</span>-<span>Recorded</span> <span>Voice</span> <span>Segments</span>.‚Äù</span> <em>Mayo Clinic Proceedings: Digital Health</em> 1 (4): 534‚Äì44. <a href="https://doi.org/10.1016/j.mcpdig.2023.08.005">https://doi.org/10.1016/j.mcpdig.2023.08.005</a>.
</div>
<div id="ref-killock_ai_2020" class="csl-entry" role="listitem">
Killock, David. 2020. <span>‚Äú<span>AI</span> Outperforms Radiologists in Mammographic Screening.‚Äù</span> <em>Nature Reviews Clinical Oncology</em> 17 (3): 134‚Äì34. <a href="https://doi.org/10.1038/s41571-020-0329-7">https://doi.org/10.1038/s41571-020-0329-7</a>.
</div>
<div id="ref-kim_health-llm_2024" class="csl-entry" role="listitem">
Kim, Yubin, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park. 2024. <span>‚ÄúHealth-<span>LLM</span>: <span>Large</span> <span>Language</span> <span>Models</span> for <span>Health</span> <span>Prediction</span> via <span>Wearable</span> <span>Sensor</span> <span>Data</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2401.06866">http://arxiv.org/abs/2401.06866</a>.
</div>
<div id="ref-kung_performance_2022" class="csl-entry" role="listitem">
Kung, Tiffany H., Morgan Cheatham, ChatGPT, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepa√±o, et al. 2022. <span>‚ÄúPerformance of <span>ChatGPT</span> on <span>USMLE</span>: <span>Potential</span> for <span>AI</span>-<span>Assisted</span> <span>Medical</span> <span>Education</span> <span>Using</span> <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> Preprint. Medical Education. <a href="https://doi.org/10.1101/2022.12.19.22283643">https://doi.org/10.1101/2022.12.19.22283643</a>.
</div>
<div id="ref-larson_myth_2021" class="csl-entry" role="listitem">
Larson, Erik J. 2021a. <em>The Myth of Artificial Intelligence: Why Computers Can‚Äôt Think the Way We Do</em>. Cambridge, Massachusetts London, England: The Belknap Press of Harvard University Press.
</div>
<div id="ref-larson_myth_2021-1" class="csl-entry" role="listitem">
‚Äî‚Äî‚Äî. 2021b. <em>The Myth of Artificial Intelligence: Why Computers Can‚Äôt Think the Way We Do</em>. Cambridge, Massachusetts: The Belknap Press of Harvard University Press.
</div>
<div id="ref-lee_deep_2017" class="csl-entry" role="listitem">
Lee, Cecilia S., Doug M. Baughman, and Aaron Y. Lee. 2017. <span>‚ÄúDeep <span>Learning</span> <span>Is</span> <span>Effective</span> for <span>Classifying</span> <span>Normal</span> Versus <span>Age</span>-<span>Related</span> <span>Macular</span> <span>Degeneration</span> <span>OCT</span> <span>Images</span>.‚Äù</span> <em>Ophthalmology Retina</em> 1 (4): 322‚Äì27. <a href="https://doi.org/10.1016/j.oret.2016.12.009">https://doi.org/10.1016/j.oret.2016.12.009</a>.
</div>
<div id="ref-drazen_benefits_2023" class="csl-entry" role="listitem">
Lee, Peter, Sebastien Bubeck, and Joseph Petro. 2023. <span>‚ÄúBenefits, <span>Limits</span>, and <span>Risks</span> of <span>GPT</span>-4 as an <span>AI</span> <span>Chatbot</span> for <span>Medicine</span>.‚Äù</span> Edited by Jeffrey M. Drazen, Isaac S. Kohane, and Tze-Yun Leong. <em>New England Journal of Medicine</em> 388 (13): 1233‚Äì39. <a href="https://doi.org/10.1056/NEJMsr2214184">https://doi.org/10.1056/NEJMsr2214184</a>.
</div>
<div id="ref-lee_ai_2023" class="csl-entry" role="listitem">
Lee, Peter, Carey Goldberg, and Isaac Kohane. 2023. <em>The <span>AI</span> Revolution in Medicine: <span>GPT</span>-4 and Beyond</em>. 1st ed. Hoboken: Pearson.
</div>
<div id="ref-leivada_dall-e_2022" class="csl-entry" role="listitem">
Leivada, Evelina, Elliot Murphy, and Gary Marcus. 2022. <span>‚Äú<span>DALL</span>-<span>E</span> 2 <span>Fails</span> to <span>Reliably</span> <span>Capture</span> <span>Common</span> <span>Syntactic</span> <span>Processes</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2210.12889">http://arxiv.org/abs/2210.12889</a>.
</div>
<div id="ref-lenat_getting_2023" class="csl-entry" role="listitem">
Lenat, Doug, and Gary Marcus. 2023. <span>‚ÄúGetting from <span>Generative</span> <span>AI</span> to <span>Trustworthy</span> <span>AI</span>: <span>What</span> <span>LLMs</span> Might Learn from <span>Cyc</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2308.04445">http://arxiv.org/abs/2308.04445</a>.
</div>
<div id="ref-li_transformer-lite_2024" class="csl-entry" role="listitem">
Li, Luchang, Sheng Qian, Jie Lu, Lunxi Yuan, Rui Wang, and Qin Xie. 2024. <span>‚ÄúTransformer-<span>Lite</span>: <span>High</span>-Efficiency <span>Deployment</span> of <span>Large</span> <span>Language</span> <span>Models</span> on <span>Mobile</span> <span>Phone</span> <span>GPUs</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.20041">http://arxiv.org/abs/2403.20041</a>.
</div>
<div id="ref-liu_evaluating_2023" class="csl-entry" role="listitem">
Liu, Nelson F., Tianyi Zhang, and Percy Liang. 2023. <span>‚ÄúEvaluating <span>Verifiability</span> in <span>Generative</span> <span>Search</span> <span>Engines</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2304.09848">http://arxiv.org/abs/2304.09848</a>.
</div>
<div id="ref-liu_agentbench_2023" class="csl-entry" role="listitem">
Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023. <span>‚Äú<span>AgentBench</span>: <span>Evaluating</span> <span>LLMs</span> as <span>Agents</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2308.03688">https://doi.org/10.48550/ARXIV.2308.03688</a>.
</div>
<div id="ref-liu_mobilellm_2024" class="csl-entry" role="listitem">
Liu, Zechun, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor Fedorov, Yunyang Xiong, et al. 2024. <span>‚Äú<span>MobileLLM</span>: <span>Optimizing</span> <span>Sub</span>-Billion <span>Parameter</span> <span>Language</span> <span>Models</span> for <span>On</span>-<span>Device</span> <span>Use</span> <span>Cases</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.14905">http://arxiv.org/abs/2402.14905</a>.
</div>
<div id="ref-liu_monolith_2022" class="csl-entry" role="listitem">
Liu, Zhuoran, Leqi Zou, Xuan Zou, Caihua Wang, Biao Zhang, Da Tang, Bolin Zhu, et al. 2022. <span>‚ÄúMonolith: <span>Real</span> <span>Time</span> <span>Recommendation</span> <span>System</span> <span>With</span> <span>Collisionless</span> <span>Embedding</span> <span>Table</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2209.07663">https://doi.org/10.48550/ARXIV.2209.07663</a>.
</div>
<div id="ref-lu_ai_2024" class="csl-entry" role="listitem">
Lu, Chris, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. 2024. <span>‚ÄúThe <span>AI</span> <span>Scientist</span>: <span>Towards</span> <span>Fully</span> <span>Automated</span> <span>Open</span>-<span>Ended</span> <span>Scientific</span> <span>Discovery</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2408.06292">http://arxiv.org/abs/2408.06292</a>.
</div>
<div id="ref-luo_biogpt_2022" class="csl-entry" role="listitem">
Luo, Renqian, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. <span>‚Äú<span>BioGPT</span>: Generative Pre-Trained Transformer for Biomedical Text Generation and Mining.‚Äù</span> <em>Briefings in Bioinformatics</em> 23 (6): bbac409. <a href="https://doi.org/10.1093/bib/bbac409">https://doi.org/10.1093/bib/bbac409</a>.
</div>
<div id="ref-lutsker_glucose_2024" class="csl-entry" role="listitem">
Lutsker, Guy, Gal Sapir, Anastasia Godneva, Smadar Shilo, Jerry R. Greenfield, Dorit Samocha-Bonet, Shie Mannor, et al. 2024. <span>‚ÄúFrom <span>Glucose</span> <span>Patterns</span> to <span>Health</span> <span>Outcomes</span>: <span>A</span> <span>Generalizable</span> <span>Foundation</span> <span>Model</span> for <span>Continuous</span> <span>Glucose</span> <span>Monitor</span> <span>Data</span> <span>Analysis</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2408.11876">http://arxiv.org/abs/2408.11876</a>.
</div>
<div id="ref-ma_lets_2023" class="csl-entry" role="listitem">
Ma, Xiao, Swaroop Mishra, Ahmad Beirami, Alex Beutel, and Jilin Chen. 2023. <span>‚ÄúLet‚Äôs <span>Do</span> a <span>Thought</span> <span>Experiment</span>: <span>Using</span> <span>Counterfactuals</span> to <span>Improve</span> <span>Moral</span> <span>Reasoning</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2306.14308">https://doi.org/10.48550/ARXIV.2306.14308</a>.
</div>
<div id="ref-mahowald_dissociating_2023" class="csl-entry" role="listitem">
Mahowald, Kyle, Anna A. Ivanova, Idan A. Blank, Nancy Kanwisher, Joshua B. Tenenbaum, and Evelina Fedorenko. 2023. <span>‚ÄúDissociating Language and Thought in Large Language Models: A Cognitive Perspective.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2301.06627">http://arxiv.org/abs/2301.06627</a>.
</div>
<div id="ref-manathunga_aligning_2023" class="csl-entry" role="listitem">
Manathunga, Supun, and Isuru Hettigoda. 2023. <span>‚ÄúAligning <span>Large</span> <span>Language</span> <span>Models</span> for <span>Clinical</span> <span>Tasks</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.02884">http://arxiv.org/abs/2309.02884</a>.
</div>
<div id="ref-mcduff_towards_2023" class="csl-entry" role="listitem">
McDuff, Daniel, Mike Schaekermann, Tao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan Singhal, et al. 2023. <span>‚ÄúTowards <span>Accurate</span> <span>Differential</span> <span>Diagnosis</span> with <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2312.00164">http://arxiv.org/abs/2312.00164</a>.
</div>
<div id="ref-mesko_prompt_2023" class="csl-entry" role="listitem">
Mesk√≥, Bertalan. 2023. <span>‚ÄúPrompt <span>Engineering</span> as an <span>Important</span> <span>Emerging</span> <span>Skill</span> for <span>Medical</span> <span>Professionals</span>: <span>Tutorial</span>.‚Äù</span> <em>Journal of Medical Internet Research</em> 25 (October): e50638. <a href="https://doi.org/10.2196/50638">https://doi.org/10.2196/50638</a>.
</div>
<div id="ref-mesko_imperative_2023" class="csl-entry" role="listitem">
Mesk√≥, Bertalan, and Eric J. Topol. 2023. <span>‚ÄúThe Imperative for Regulatory Oversight of Large Language Models (or Generative <span>AI</span>) in Healthcare.‚Äù</span> <em>Npj Digital Medicine</em> 6 (1): 120. <a href="https://doi.org/10.1038/s41746-023-00873-0">https://doi.org/10.1038/s41746-023-00873-0</a>.
</div>
<div id="ref-milliere_philosophical_2024" class="csl-entry" role="listitem">
Milli√®re, Rapha√´l, and Cameron Buckner. 2024. <span>‚ÄúA <span>Philosophical</span> <span>Introduction</span> to <span>Language</span> <span>Models</span> ‚Äì <span>Part</span> <span>I</span>: <span>Continuity</span> <span>With</span> <span>Classic</span> <span>Debates</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2401.03910">http://arxiv.org/abs/2401.03910</a>.
</div>
<div id="ref-narayanan_ai_2024" class="csl-entry" role="listitem">
Narayanan, Arvind, and Sayash Kapoor. 2024. <em><span>AI</span> Snake Oil: What Artificial Intelligence Can Do, What It Can‚Äôt, and How to Tell the Difference</em>. Princeton Oxford: Princeton University Press.
</div>
<div id="ref-nori_capabilities_2023" class="csl-entry" role="listitem">
Nori, Harsha, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. 2023. <span>‚ÄúCapabilities of <span>GPT</span>-4 on <span>Medical</span> <span>Challenge</span> <span>Problems</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2303.13375">https://doi.org/10.48550/ARXIV.2303.13375</a>.
</div>
<div id="ref-oh_organ_2023" class="csl-entry" role="listitem">
Oh, Hamilton Se-Hwee, Jarod Rutledge, Daniel Nachun, R√≥bert P√°lovics, Olamide Abiose, Patricia Moran-Losada, Divya Channappa, et al. 2023. <span>‚ÄúOrgan Aging Signatures in the Plasma Proteome Track Health and Disease.‚Äù</span> <em>Nature</em> 624 (7990): 164‚Äì72. <a href="https://doi.org/10.1038/s41586-023-06802-1">https://doi.org/10.1038/s41586-023-06802-1</a>.
</div>
<div id="ref-oren_proving_2023" class="csl-entry" role="listitem">
Oren, Yonatan, Nicole Meister, Niladri Chatterji, Faisal Ladhak, and Tatsunori B. Hashimoto. 2023. <span>‚ÄúProving <span>Test</span> <span>Set</span> <span>Contamination</span> in <span>Black</span> <span>Box</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2310.17623">http://arxiv.org/abs/2310.17623</a>.
</div>
<div id="ref-pei_deepfake_2024" class="csl-entry" role="listitem">
Pei, Gan, Jiangning Zhang, Menghan Hu, Guangtao Zhai, Chengjie Wang, Zhenyu Zhang, Jian Yang, Chunhua Shen, and Dacheng Tao. 2024. <span>‚ÄúDeepfake <span>Generation</span> and <span>Detection</span>: <span>A</span> <span>Benchmark</span> and <span>Survey</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.17881">http://arxiv.org/abs/2403.17881</a>.
</div>
<div id="ref-qian_merge_2023" class="csl-entry" role="listitem">
Qian, Cheng, Xinran Zhao, and Sherry Tongshuang Wu. 2023. <span>‚Äú"<span>Merge</span> <span>Conflicts</span>!" <span>Exploring</span> the <span>Impacts</span> of <span>External</span> <span>Distractors</span> to <span>Parametric</span> <span>Knowledge</span> <span>Graphs</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.08594">http://arxiv.org/abs/2309.08594</a>.
</div>
<div id="ref-qiu_towards_2024" class="csl-entry" role="listitem">
Qiu, Pengcheng, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, and Weidi Xie. 2024. <span>‚ÄúTowards <span>Building</span> <span>Multilingual</span> <span>Language</span> <span>Model</span> for <span>Medicine</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.13963">http://arxiv.org/abs/2402.13963</a>.
</div>
<div id="ref-raji_fallacy_2022" class="csl-entry" role="listitem">
Raji, Inioluwa Deborah, I. Elizabeth Kumar, Aaron Horowitz, and Andrew D. Selbst. 2022. <span>‚ÄúThe <span>Fallacy</span> of <span>AI</span> <span>Functionality</span>.‚Äù</span> In <em>2022 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 959‚Äì72. <a href="https://doi.org/10.1145/3531146.3533158">https://doi.org/10.1145/3531146.3533158</a>.
</div>
<div id="ref-rao_assessing_2023" class="csl-entry" role="listitem">
Rao, Arya, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, Adam Landman, Keith Dreyer, and Marc D Succi. 2023. <span>‚ÄúAssessing the <span>Utility</span> of <span>ChatGPT</span> <span>Throughout</span> the <span>Entire</span> <span>Clinical</span> <span>Workflow</span>: <span>Development</span> and <span>Usability</span> <span>Study</span>.‚Äù</span> <em>Journal of Medical Internet Research</em> 25 (August): e48659. <a href="https://doi.org/10.2196/48659">https://doi.org/10.2196/48659</a>.
</div>
<div id="ref-romera-paredes_mathematical_2024" class="csl-entry" role="listitem">
Romera-Paredes, Bernardino, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, et al. 2024. <span>‚ÄúMathematical Discoveries from Program Search with Large Language Models.‚Äù</span> <em>Nature</em> 625 (7995): 468‚Äì75. <a href="https://doi.org/10.1038/s41586-023-06924-6">https://doi.org/10.1038/s41586-023-06924-6</a>.
</div>
<div id="ref-rottger_political_2024" class="csl-entry" role="listitem">
R√∂ttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Sch√ºtze, and Dirk Hovy. 2024. <span>‚ÄúPolitical <span>Compass</span> or <span>Spinning</span> <span>Arrow</span>? <span>Towards</span> <span>More</span> <span>Meaningful</span> <span>Evaluations</span> for <span>Values</span> and <span>Opinions</span> in <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.16786">http://arxiv.org/abs/2402.16786</a>.
</div>
<div id="ref-rozado_political_2023" class="csl-entry" role="listitem">
Rozado, David. 2023. <span>‚ÄúThe <span>Political</span> <span>Biases</span> of <span>ChatGPT</span>.‚Äù</span> <em>Social Sciences</em> 12 (3): 148. <a href="https://doi.org/10.3390/socsci12030148">https://doi.org/10.3390/socsci12030148</a>.
</div>
<div id="ref-rozado_political_2024" class="csl-entry" role="listitem">
‚Äî‚Äî‚Äî. 2024. <span>‚ÄúThe <span>Political</span> <span>Preferences</span> of <span>LLMs</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.01789">http://arxiv.org/abs/2402.01789</a>.
</div>
<div id="ref-saab_capabilities_2024" class="csl-entry" role="listitem">
Saab, Khaled, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, et al. 2024. <span>‚ÄúCapabilities of <span>Gemini</span> <span>Models</span> in <span>Medicine</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2404.18416">http://arxiv.org/abs/2404.18416</a>.
</div>
<div id="ref-sastry_computing_2024" class="csl-entry" role="listitem">
Sastry, Girish, Lennart Heim, Haydn Belfield, Markus Anderljung, Miles Brundage, Julian Hazell, Cullen O‚ÄôKeefe, et al. 2024. <span>‚ÄúComputing <span>Power</span> and the <span>Governance</span> of <span>Artificial</span> <span>Intelligence</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.08797">http://arxiv.org/abs/2402.08797</a>.
</div>
<div id="ref-shumailov_curse_2023" class="csl-entry" role="listitem">
Shumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023. <span>‚ÄúThe <span>Curse</span> of <span>Recursion</span>: <span>Training</span> on <span>Generated</span> <span>Data</span> <span>Makes</span> <span>Models</span> <span>Forget</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2305.17493">http://arxiv.org/abs/2305.17493</a>.
</div>
<div id="ref-singhal_large_2023" class="csl-entry" role="listitem">
Singhal, Karan, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, et al. 2023. <span>‚ÄúLarge Language Models Encode Clinical Knowledge.‚Äù</span> <em>Nature</em> 620 (7972): 172‚Äì80. <a href="https://doi.org/10.1038/s41586-023-06291-2">https://doi.org/10.1038/s41586-023-06291-2</a>.
</div>
<div id="ref-sun_artificial_2023" class="csl-entry" role="listitem">
Sun, Jie, Qun-Xi Dong, San-Wang Wang, Yong-Bo Zheng, Xiao-Xing Liu, Tang-Sheng Lu, Kai Yuan, et al. 2023. <span>‚ÄúArtificial Intelligence in Psychiatry Research, Diagnosis, and Therapy.‚Äù</span> <em>Asian Journal of Psychiatry</em> 87 (September): 103705. <a href="https://doi.org/10.1016/j.ajp.2023.103705">https://doi.org/10.1016/j.ajp.2023.103705</a>.
</div>
<div id="ref-tian_spreadsheetllm_2024" class="csl-entry" role="listitem">
Tian, Yuzhang, Jianbo Zhao, Haoyu Dong, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, et al. 2024. <span>‚Äú<span>SpreadsheetLLM</span>: <span>Encoding</span> <span>Spreadsheets</span> for <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2407.09025">http://arxiv.org/abs/2407.09025</a>.
</div>
<div id="ref-tu_towards_2024" class="csl-entry" role="listitem">
Tu, Tao, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, et al. 2024. <span>‚ÄúTowards <span>Conversational</span> <span>Diagnostic</span> <span>AI</span>.‚Äù</span> <a href="https://doi.org/10.48550/ARXIV.2401.05654">https://doi.org/10.48550/ARXIV.2401.05654</a>.
</div>
<div id="ref-udandarao_no_2024" class="csl-entry" role="listitem">
Udandarao, Vishaal, Ameya Prabhu, Adhiraj Ghosh, Yash Sharma, Philip H. S. Torr, Adel Bibi, Samuel Albanie, and Matthias Bethge. 2024. <span>‚ÄúNo "<span>Zero</span>-<span>Shot</span>" <span>Without</span> <span>Exponential</span> <span>Data</span>: <span>Pretraining</span> <span>Concept</span> <span>Frequency</span> <span>Determines</span> <span>Multimodal</span> <span>Model</span> <span>Performance</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2404.04125">http://arxiv.org/abs/2404.04125</a>.
</div>
<div id="ref-villalobos_will_2022" class="csl-entry" role="listitem">
Villalobos, Pablo, Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius Hobbhahn, and Anson Ho. 2022. <span>‚ÄúWill We Run Out of Data? <span>An</span> Analysis of the Limits of Scaling Datasets in <span>Machine</span> <span>Learning</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2211.04325">http://arxiv.org/abs/2211.04325</a>.
</div>
<div id="ref-wang_sam-octa_2023" class="csl-entry" role="listitem">
Wang, Chengliang, Xinrun Chen, Haojian Ning, and Shiying Li. 2023. <span>‚Äú<span>SAM</span>-<span>OCTA</span>: <span>A</span> <span>Fine</span>-<span>Tuning</span> <span>Strategy</span> for <span>Applying</span> <span>Foundation</span> <span>Model</span> to <span>OCTA</span> <span>Image</span> <span>Segmentation</span> <span>Tasks</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2309.11758">http://arxiv.org/abs/2309.11758</a>.
</div>
<div id="ref-wei_chain--thought_2023" class="csl-entry" role="listitem">
Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. <span>‚ÄúChain-of-<span>Thought</span> <span>Prompting</span> <span>Elicits</span> <span>Reasoning</span> in <span>Large</span> <span>Language</span> <span>Models</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2201.11903">http://arxiv.org/abs/2201.11903</a>.
</div>
<div id="ref-wei_long-form_2024" class="csl-entry" role="listitem">
Wei, Jerry, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, et al. 2024. <span>‚ÄúLong-Form Factuality in Large Language Models.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.18802">http://arxiv.org/abs/2403.18802</a>.
</div>
<div id="ref-weiss_what_2024" class="csl-entry" role="listitem">
Weiss, Roy, Daniel Ayzenshteyn, Guy Amit, and Yisroel Mirsky. 2024. <span>‚ÄúWhat <span>Was</span> <span>Your</span> <span>Prompt</span>? <span>A</span> <span>Remote</span> <span>Keylogging</span> <span>Attack</span> on <span>AI</span> <span>Assistants</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2403.09751">http://arxiv.org/abs/2403.09751</a>.
</div>
<div id="ref-wendler_llamas_2024" class="csl-entry" role="listitem">
Wendler, Chris, Veniamin Veselovsky, Giovanni Monea, and Robert West. 2024. <span>‚ÄúDo <span>Llamas</span> <span>Work</span> in <span>English</span>? <span>On</span> the <span>Latent</span> <span>Language</span> of <span>Multilingual</span> <span>Transformers</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2402.10588">http://arxiv.org/abs/2402.10588</a>.
</div>
<div id="ref-wornow_shaky_2023" class="csl-entry" role="listitem">
Wornow, Michael, Yizhe Xu, Rahul Thapa, Birju Patel, Ethan Steinberg, Scott Fleming, Michael A. Pfeffer, Jason Fries, and Nigam H. Shah. 2023. <span>‚ÄúThe Shaky Foundations of Large Language Models and Foundation Models for Electronic Health Records.‚Äù</span> <em>Npj Digital Medicine</em> 6 (1): 135. <a href="https://doi.org/10.1038/s41746-023-00879-8">https://doi.org/10.1038/s41746-023-00879-8</a>.
</div>
<div id="ref-yiu_transmission_2023" class="csl-entry" role="listitem">
Yiu, Eunice, Eliza Kosoy, and Alison Gopnik. 2023. <span>‚ÄúTransmission <span>Versus</span> <span>Truth</span>, <span>Imitation</span> <span>Versus</span> <span>Innovation</span>: <span>What</span> <span>Children</span> <span>Can</span> <span>Do</span> <span>That</span> <span>Large</span> <span>Language</span> and <span>Language</span>-and-<span>Vision</span> <span>Models</span> <span>Cannot</span> (<span>Yet</span>).‚Äù</span> <em>Perspectives on Psychological Science</em>, October, 17456916231201401. <a href="https://doi.org/10.1177/17456916231201401">https://doi.org/10.1177/17456916231201401</a>.
</div>
<div id="ref-yu_evaluating_2023" class="csl-entry" role="listitem">
Yu, Feiyang, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, Eduardo Kaiser Ururahy Nunes Fonseca, et al. 2023. <span>‚ÄúEvaluating Progress in Automatic Chest <span>X</span>-Ray Radiology Report Generation.‚Äù</span> <em>Patterns</em> 4 (9): 100802. <a href="https://doi.org/10.1016/j.patter.2023.100802">https://doi.org/10.1016/j.patter.2023.100802</a>.
</div>
<div id="ref-zaleski_comprehensiveness_2024" class="csl-entry" role="listitem">
Zaleski, Amanda L, Rachel Berkowsky, Kelly Jean Thomas Craig, and Linda S Pescatello. 2024. <span>‚ÄúComprehensiveness, <span>Accuracy</span>, and <span>Readability</span> of <span>Exercise</span> <span>Recommendations</span> <span>Provided</span> by an <span>AI</span>-<span>Based</span> <span>Chatbot</span>: <span>Mixed</span> <span>Methods</span> <span>Study</span>.‚Äù</span> <em>JMIR Medical Education</em> 10 (January): e51308. <a href="https://doi.org/10.2196/51308">https://doi.org/10.2196/51308</a>.
</div>
<div id="ref-zhao_foundation_2024" class="csl-entry" role="listitem">
Zhao, Theodore, Yu Gu, Jianwei Yang, Naoto Usuyama, Ho Hin Lee, Sid Kiblawi, Tristan Naumann, et al. 2024. <span>‚ÄúA Foundation Model for Joint Segmentation, Detection and Recognition of Biomedical Objects Across Nine Modalities.‚Äù</span> <em>Nature Methods</em>, November. <a href="https://doi.org/10.1038/s41592-024-02499-w">https://doi.org/10.1038/s41592-024-02499-w</a>.
</div>
<div id="ref-zhao_clip_2023" class="csl-entry" role="listitem">
Zhao, Zihao, Yuxiao Liu, Han Wu, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu, et al. 2023. <span>‚Äú<span>CLIP</span> in <span>Medical</span> <span>Imaging</span>: <span>A</span> <span>Comprehensive</span> <span>Survey</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2312.07353">http://arxiv.org/abs/2312.07353</a>.
</div>
<div id="ref-zheng_natural_2024" class="csl-entry" role="listitem">
Zheng, Huaixiu Steven, Swaroop Mishra, Hugh Zhang, Xinyun Chen, Minmin Chen, Azade Nova, Le Hou, et al. 2024. <span>‚Äú<span>NATURAL</span> <span>PLAN</span>: <span>Benchmarking</span> <span>LLMs</span> on <span>Natural</span> <span>Language</span> <span>Planning</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2406.04520">http://arxiv.org/abs/2406.04520</a>.
</div>
<div id="ref-zhou_webarena_2023" class="csl-entry" role="listitem">
Zhou, Shuyan, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, et al. 2023. <span>‚Äú<span>WebArena</span>: <span>A</span> <span>Realistic</span> <span>Web</span> <span>Environment</span> for <span>Building</span> <span>Autonomous</span> <span>Agents</span>.‚Äù</span> arXiv. <a href="http://arxiv.org/abs/2307.13854">http://arxiv.org/abs/2307.13854</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/richardsprague\.github\.io\/people-capital\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch04.html" class="pagination-link" aria-label="Beyond Computation: The Philosophy of Human Intelligence">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beyond Computation: The Philosophy of Human Intelligence</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch06.html" class="pagination-link" aria-label="Finding the Sweet Spot">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Finding the Sweet Spot</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025 People+Capital, LLC</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>