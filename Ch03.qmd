---
title: "The What-How Divide"
subtitle: "AI's Real Impact on Knowledge Work"
---


Until recently, career success in knowledge work depended heavily on mastering "how" skills - knowing how to build a compelling PowerPoint, how to structure a financial model, or how to write efficient code. But as AI systems become more capable at these technical tasks, the competitive advantage is shifting dramatically toward people who know "what" needs to be done - those who can identify the right problems to solve and strategies to pursue.

This fundamental shift from "how" to "what" has profound implications for businesses, careers, and investment opportunities. Let's explore why this transformation is happening and what it means for different stakeholders.

## The Traditional "How" Advantage


Traditionally, organizations needed large teams of specialists who knew "how" to perform various technical tasks: 

- Financial analysts who knew how to build complex Excel models
- Software engineers who knew how to write code in specific languages
- Designers who knew how to use tools like Photoshop
- Writers who knew how to craft clear technical documentation
- Translators who knew how to convert text between languages

These specialists developed their skills through years of practice and training. Their expertise created both job security and earning power - companies were willing to pay premium salaries for people who could execute complex technical tasks effectively.

## AI's Disruption of "How"


Large language models and other AI tools are rapidly getting better at many of these "how" tasks:

- ChatGPT can write basic code in multiple languages
- Midjourney can generate sophisticated images
- Translation tools are approaching human-level quality
- AI assistants can create presentations and documentation

This capability is expanding quickly. Tasks that seemed immune to automation just a few years ago are now being handled competently by AI systems. And unlike human specialists who may take years to master new skills, AI systems can be rapidly retrained or fine-tuned for new capabilities.

## The Rise of "What" Skills

As AI handles more of the “how,” competitive advantage shifts to people who excel at determining “what” needs to be done:

- What problems are worth solving?
- What features should a product include?
- What markets should a company enter?
- What strategies will create sustainable advantages?
- What metrics matter most for success?

These “what” decisions require capabilities that current AI systems fundamentally lack:


**Pattern Recognition Across Domains** Humans can notice subtle patterns and draw insights across seemingly unrelated fields. A business leader might see parallels between consumer behavior in fashion and trends in enterprise software, leading to novel strategic insights. Current AI
systems, despite their broad training, struggle to make these creative connections in meaningful ways.

**Judgment Under Uncertainty** Many crucial business decisions involve incomplete information and conflicting priorities. Experienced leaders develop judgment about which risks are worth taking and which tradeoffs make sense. This type of judgment emerges from years of seeing both successes and failures firsthand - something AI systems cannot truly replicate.

**Understanding Human Context** Success in business ultimately depends on understanding human needs, motivations, and behaviors. While AI can process vast amounts of data about human behavior, it lacks the innate understanding that comes from being human and experiencing the full range of human emotions and social dynamics.

## Real-World Examples

Let's look at some specific examples of how this "what vs. how" divide plays out:



### ChatGPT and Chess: The What vs. How Divide


ChatGPT excels at the "how" aspects of chess. It can explain rules with precise clarity, describe tactical motifs like forks and pins, recommend standard opening principles, and even execute move sequences when prompted. This "how" capability stems from its training on countless chess books, articles, and game annotations, allowing it to mimic the instructional patterns of chess literature.

Where ChatGPT fundamentally falls short is in the "what" domain of chess. It cannot determine what strategic approach makes sense in a complex position, what long-term plan to pursue, or what the most critical elements of a position are. Even more fundamentally, ChatGPT cannot decide what it means to "play chess well" in the first place.

Consider a simple example: in a given position, should a player sacrifice material for an attack? This decision requires weighing potential attacking chances against concrete defensive resources - a judgment that integrates evaluation of multiple possible futures. ChatGPT can explain how sacrifices work in general, but cannot reliably determine what sacrifice (if any) is appropriate in a specific complex position.

Even more telling is ChatGPT's inability to set appropriate chess goals. A human must instruct the AI to "find checkmate in two moves" or "evaluate this position" or "recommend an opening for a beginner." The AI cannot independently determine what chess problems are worth solving or what chess knowledge would benefit a particular player. It lacks the purposeful orientation that human players naturally bring to the game.

This mirrors the broader pattern we've observed across domains. AI systems like ChatGPT handle the mechanics - the "how" - with impressive competence. But they remain tools awaiting human direction regarding "what" goals to pursue, "what" problems need solving, and "what" considerations matter most in any given context.

For chess learners, this creates an interesting dynamic. ChatGPT can serve as an always-available resource for understanding "how" chess pieces move, "how" to execute basic tactics, and "how" traditional openings proceed. But determining "what" to study, "what" skills to prioritize, and "what" strategic approaches align with one's strengths - these remain distinctly human judgments that no current AI can meaningfully address.

The limitations become even more apparent in competitive contexts. Strong human players know that chess is not merely about following rules and recognizing patterns - it's about making judgments under uncertainty, having a coherent vision of how the game should develop, and understanding which factors deserve attention in ambiguous positions. These "what" decisions remain beyond ChatGPT's capabilities, even as it continues to improve at describing "how" chess concepts work in isolation.

As AI capabilities advance, this fundamental divide persists. The most valuable human contribution isn't executing the mechanical aspects of chess, but rather making the judgment calls about what matters, what deserves attention, and what goals are worth pursuing in the first place.


### Book-Writing: When Bulldozers Move Words

  What's the value of traditional books when ChatGPT can generate coherent answers to any question?

A good analogy is with construction projects. Like bulldozers that efficiently move earth, AI can rapidly generate vast quantities of coherent text. But just as construction requires both heavy machinery and skilled artisans, meaningful books need both AI's raw productive power and human refinement.

However, a well-crafted book offers something different: a carefully structured approach that helps readers decide their level of engagement. The finite, constrained nature of a book provides focus that chatbots, with their endless potential for digression, cannot easily match.

The key to understanding AI's role in authorship lies in recognizing the distinct phases of book creation.

1.  The initial phase - deciding subject matter and scope, aka the     "what" phase --- remains fundamentally human. While AI can help     brainstorm ideas or identify underexplored topics, the essential     creative spark and purpose must come from human intention. This     reflects a broader truth about AI: it excels at processing existing     patterns but struggles to generate truly novel directions.

2.  The next phase --- outlining the subject into smaller, related     topics that make a coherent whole --- demonstrates the potential for     human-AI collaboration. AI can quickly generate comprehensive topic     structures, but human expertise is crucial for identifying gaps,     inconsistencies, or areas requiring special emphasis. This interplay     between AI's broad pattern recognition and human domain knowledge     creates stronger frameworks than either could achieve alone.

3.  The writing phase is where AI's "bulldozer" capabilities shine.     Instead of laboriously crafting individual sentences, authors can     use AI to generate substantial blocks of coherent text. This     dramatically accelerates the initial draft process. However, like     rough-graded earth, this AI-generated text requires careful     refinement to achieve its final form.

4.  The refinement phase is where human judgment becomes paramount.     Authors must shape the AI-generated content to maintain consistent     voice, ensure logical flow, and preserve the book's core purpose.     This requires understanding nuances of audience expectations and     subject matter that current AI systems cannot fully grasp.

This iterative process of generation and refinement continues until the project achieves its goals - another judgment that requires human evaluation. The result is neither purely AI-generated nor traditionally human-authored, but rather a new form of hybrid creativity that leverages the strengths of both.

The role of books may evolve, but their fundamental purpose - to present structured, focused exploration of subjects - will always be valuable. The challenge for authors is not to compete with AI's raw generative capabilities, but to use them effectively while maintaining the human elements that give books their lasting value.

This suggests a future where successful authors are those who master the art of AI collaboration rather than resist it. Just as modern architects must understand both traditional design principles and computer-aided tools, tomorrow's authors will need to balance classic writing skills with AI capabilities.

The key question is no longer whether AI will replace human authors, but how it will transform the authorship process. The answer lies in recognizing that while AI can move mountains of words, humans must still decide which mountains to move and how to shape the resulting landscape.

This transformation parallels broader changes in knowledge work. As AI handles more routine cognitive tasks, human value increasingly derives from higher-order skills like judgment, creativity, and strategic thinking. The greatest rewards of authorship, as in many professional fields, will accrue to those who can effectively combine human insight with AI capabilities.

The rise of AI authors doesn't diminish the value of books but rather changes how they're created. The essential human elements - purpose, judgment, refinement - remain crucial, even as AI dramatically expands our capability to generate and process information. The result may be not just better books, but new forms of knowledge sharing that we're only beginning to imagine.


## More examples

### Software Development: Beyond Code Generation


The construction industry provides useful analogies for understanding AI's impact on software development. Just as modern construction sites use both automated machinery and skilled human workers, software development is evolving into a hybrid process where AI handles routine coding tasks while humans focus on architecture and design decisions.

Consider a typical software project. Traditional development required writing every line of code manually, like building a house brick by brick. Now, AI coding assistants like GitHub Copilot or Amazon CodeWhisperer can generate entire functions or modules automatically, similar to how prefabricated components accelerated construction. These AI tools excel at producing standard elements - authentication systems, database queries, API endpoints - just as manufacturing automation excels at producing standardized building materials.

However, like construction projects, software development involves more than assembling standard components. A successful project requires understanding user needs, designing intuitive interfaces, ensuring security, and maintaining long-term reliability. These higher-level decisions remain firmly in human territory.

The architectural parallel is particularly apt. Just as architects must consider aesthetics, functionality, and structural integrity, software architects must balance user experience, system performance, and code maintainability. AI can suggest implementation details, but it cannot determine whether a feature aligns with business goals or how it might affect user behavior.

Technical debt offers another illuminating comparison. In construction, taking shortcuts (like using lower-grade materials) can speed completion but creates future maintenance problems. Similarly, in software development, quick fixes and temporary solutions accumulate as technical debt. While AI can identify potential debt and suggest refactoring strategies, humans must weigh the business tradeoffs of addressing it now versus later.

Integration challenges further highlight AI's limitations. Modern software systems are complex ecosystems of interacting components, like cities with interconnected infrastructure systems. AI excels at optimizing individual components but struggles to understand system-wide implications. Humans must orchestrate these interactions, ensuring different parts work together coherently while maintaining system reliability and performance.

Security considerations demonstrate another crucial human role. Like building security systems, software security requires anticipating potential threats and implementing appropriate protections. AI can identify common vulnerabilities and suggest fixes, but it cannot understand the broader security context or evaluate risk tradeoffs. These decisions require human judgment informed by business context and threat assessment.

The testing and quality assurance phase reveals both AI's strengths and limitations. AI tools can automatically generate test cases and identify potential bugs, similar to automated building inspections. However, human testers are still essential for evaluating user experience, identifying edge cases, and ensuring the software meets business requirements. AI can verify that code works as written, but humans must verify it works as intended.

Looking ahead, successful software development will likely become increasingly collaborative between humans and AI. Development teams will need to master new workflows that leverage AI's capabilities while maintaining human oversight of critical decisions. This might involve using AI for initial code generation and routine maintenance while focusing human effort on architecture, security, and user experience.

This evolution parallels broader trends in professional work. Just as power tools didn't eliminate the need for skilled carpenters but changed how they work, AI won't eliminate software developers but will transform their role. The most valuable developers will be those who can effectively direct AI tools while maintaining high-level system understanding.

The implications for software education and training are significant. Future developers will need less emphasis on memorizing syntax and more focus on system design, architecture, and AI collaboration skills. This mirrors how modern architectural education focuses less on manual drafting and more on design principles and computer-aided tools.

However, the fundamental role of human creativity and judgment remains unchanged. Just as beautiful buildings require human vision despite advanced construction technology, great software requires human insight despite sophisticated AI tools. The key is understanding AI as an enabler of human creativity rather than its replacement. AI working alone can be competent at creating an adequate building that meets the programmatic requirements laid out by its developers, but a truly great building will still require human input and humans' ability to push the frontier of creativity.

This suggests that software development is entering a new phase where success depends on effectively combining AI capabilities with human insight. Here again, the best outcomes will result from humans' ability to leverage AI. The winners will be those who can best envision how technology can serve human needs while using AI to implement that vision efficiently and reliably.

In this new paradigm, the measure of a developer shifts from lines of code written to the effectiveness of their human-AI collaboration in creating valuable software solutions. The construction industry's evolution from manual labor to machine-assisted craftsmanship provides a roadmap for this transformation.

### Investment Analysis: Beyond the Numbers

Just as modern factories use automation for routine manufacturing while relying on human expertise for product design and quality control, investment analysis is evolving into a hybrid process where AI handles data processing while humans focus on strategic insights and judgment calls.

Consider a typical investment analysis project. Traditionally, analysts spent countless hours gathering financial data, creating comparison spreadsheets, and writing preliminary reports. Now, AI can instantly process quarterly reports, generate peer comparisons, and draft initial analyses. This is similar to how automated assembly lines handle routine manufacturing tasks, freeing human workers to focus on complex problems requiring judgment and creativity.

However, like manufacturing, successful investing involves more than processing standard inputs. While AI excels at identifying patterns in financial statements and market data, it struggles with crucial qualitative factors. Can management be trusted? Is the company's competitive advantage sustainable? Will current market opportunities persist? These questions require human judgment informed by experience and industry knowledge.

The manufacturing quality control parallel is particularly relevant. Just as experienced inspectors can spot subtle defects that automated systems miss, seasoned investors can identify red flags in management behavior or market dynamics that AI might overlook. A CEO's body language during earnings calls, the timing of insider stock sales, or subtle shifts in competitive dynamics - these nuanced signals often prove more valuable than quantitative metrics.

Competitive analysis offers another illuminating comparison. In manufacturing, understanding market dynamics requires more than analyzing production statistics - it requires insight into changing consumer preferences, emerging technologies, and competitor strategies. Similarly, while AI can process vast amounts of market data, humans must evaluate whether a company's competitive position is truly defensible and whether management's strategy aligns with market realities.

The role of trust highlights another crucial human element. Just as manufacturing partnerships require trust built through personal relationships and demonstrated reliability, investment success often depends on accurately assessing management credibility. AI can flag inconsistencies in financial statements or unusual transaction patterns, but it cannot evaluate character or judge whether explanations for apparent irregularities are credible.

Market opportunity assessment demonstrates similar limitations. Like evaluating new manufacturing technologies, assessing market opportunities requires understanding both technical capabilities and human behavior. AI can analyze historical market data and identify trends, but it cannot predict how human customers, competitors, and regulators will react to new situations. These predictions require human insight into psychology and social dynamics.

Risk assessment reveals both AI's strengths and limitations. AI systems can quickly identify common risk factors and calculate standard metrics, similar to automated safety systems in manufacturing. However, the most significant risks often come from unexpected directions that don't appear in historical data. Human judgment remains essential for identifying and evaluating these non-obvious risks.

Looking ahead, successful investment analysis will likely become increasingly collaborative between humans and AI. Analysis teams will need to master new workflows that leverage AI's data processing capabilities while maintaining human oversight of critical judgments. This might involve using AI for initial screening and routine monitoring while focusing human effort on qualitative assessment and strategic thinking.

This evolution parallels broader trends in professional work. Automation did not eliminate the need for skilled manufacturing workers but changed their role, and AI will not eliminate investment analysts but will transform how they work. The most valuable analysts will be those who can effectively direct AI tools while maintaining deep industry understanding and judgment capabilities.

The implications for investment education and training are significant. Future analysts will need less emphasis on spreadsheet skills and more focus on business judgment and AI collaboration capabilities. This mirrors how modern manufacturing education focuses less on manual skills and more on process management and technology integration.

However, the fundamental role of human judgment remains unchanged. Just as quality manufacturing requires human oversight despite advanced automation, successful investing requires human insight despite sophisticated AI tools. The key is understanding AI as an enhancer of human judgment rather than its replacement.

This suggests that investment analysis is entering a new phase where success depends on effectively combining AI capabilities with human insight. Analysts who can best understand business fundamentals while using AI will perform better than those who can merely process data faster.

In this new paradigm, the measure of an analyst shifts from computational speed to the effectiveness of their human-AI collaboration in identifying truly attractive investments. The manufacturing industry's evolution from manual production to technology-enhanced craftsmanship provides a roadmap for this transformation.


### AI and Healthcare: Beyond Pattern Recognition

The evolution of AI in healthcare parallels modern manufacturing quality control, where automated systems handle routine inspections while skilled technicians focus on complex problems requiring human judgment. Similarly, healthcare is becoming a hybrid system where AI processes medical data while human doctors focus on patient relationships and complex medical decisions.

Consider a typical diagnostic process. Traditionally, doctors spent considerable time reviewing test results, consulting medical literature, and documenting findings. Now, AI can instantly analyze lab results, medical images, and patient histories to suggest potential diagnoses. This is similar to how automated inspection systems quickly identify defects in manufactured products, allowing human inspectors to focus on more complex quality issues.

However, like quality control, successful healthcare involves more than pattern recognition. While AI excels at identifying anomalies in test results and suggesting standard treatments, it struggles with crucial contextual factors. How will a patient's living situation affect treatment adherence? Which side effects are acceptable given a patient's lifestyle? What treatment modifications are needed given other health conditions? These questions require human judgment informed by direct patient interaction and medical experience.

The empathy factor is particularly relevant. Effective quality control requires understanding how products will be used in real-world conditions, and effective healthcare requires understanding patients' lives and concerns. AI can process medical histories and suggest treatment protocols, but it cannot truly empathize with patient fears or understand how cultural and personal factors might affect treatment success.

Treatment customization offers another illuminating comparison. In manufacturing, standard quality metrics must often be adjusted for specific use cases. Similarly, while AI can recommend standard treatments based on medical literature, doctors must adapt these recommendations to individual patient circumstances. A treatment protocol that looks optimal on paper might be impractical or inappropriate given a patient's specific situation.

The trust relationship highlights another crucial human element. In the same way that manufacturing quality depends on trust between suppliers and customers, healthcare outcomes often depend on patient trust in their medical providers. AI can provide accurate medical information, but it cannot build the personal trust that encourages treatment compliance and honest symptom reporting.

Emergency response demonstrates both AI's strengths and limitations. AI systems can quickly process vital signs and suggest immediate interventions, similar to automated safety systems in manufacturing. However, emergency medicine often requires split-second decisions based on incomplete information and complex tradeoffs. Human judgment remains essential for these high-stakes decisions where standard protocols may not apply.

Looking ahead, successful healthcare will likely become increasingly collaborative between humans and AI. Medical teams will need to master new workflows that leverage AI's analytical capabilities while maintaining human oversight of critical decisions. This might involve using AI for initial screening and routine monitoring while focusing human effort on patient interaction and complex case management.

This evolution parallels broader trends in professional work. Automation did not eliminate the need for skilled quality control technicians but changed their role, and AI will not eliminate doctors but will transform how they work. The most valuable healthcare providers will be those who can effectively direct AI tools while maintaining strong patient relationships and clinical judgment.

The implications for medical education and training are significant. Future doctors will need less emphasis on memorizing medical facts and more focus on patient communication and AI collaboration skills. This mirrors how modern quality control training focuses less on inspection procedures and more on system management and problem-solving.

However, the fundamental role of human judgment remains unchanged. Quality control requires human oversight despite advanced inspection technology, and healthcare requires human insight despite sophisticated AI tools. The key is understanding AI as an enhancer of medical judgment rather than its replacement.

This suggests that healthcare is entering a new phase where success depends on effectively combining AI capabilities with human insight. Those who can understand patient needs while using AI to enhance this understanding will reap more rewards than those who can merely recall the most medical facts and procedures.

In this new paradigm, the measure of a healthcare provider shifts from diagnostic speed to the effectiveness of their human-AI collaboration in achieving optimal patient outcomes. The quality control industry's evolution from manual inspection to technology-enhanced oversight provides a roadmap for this transformation.

The challenge ahead is not whether to adopt AI in healthcare, but how to integrate it while preserving the human elements that make medicine effective. Success will require understanding both AI's capabilities and its limitations, while never losing sight of healthcare's fundamental mission: helping human patients achieve better health outcomes through personalized, compassionate care.

## Investment Implications

This shift has important implications for investors:

**Winners**:

- Companies that help humans make better "what" decisions
- Tools that augment human judgment rather than replace it
- Platforms that combine AI capabilities with human insight
- Businesses with strong human judgment at their core

**Losers**: 

- Pure automation plays that don't preserve human judgment
- Companies selling commoditized "how" skills
- Businesses that can't articulate their human advantage

## The Future of Work

This transition suggests several changes in how organizations will operate:

**New Organizational Structures**

- Flatter hierarchies as AI handles routine coordination
- Smaller, more senior teams focused on "what" decisions
- Greater emphasis on judgment and strategic thinking

**Changed Skill Requirements**

- Less focus on technical tool proficiency
- More emphasis on strategic thinking and judgment
- Greater value placed on cross-domain knowledge

**Modified Training Approaches**

- Reduced time spent teaching technical "how" skills
- Increased focus on judgment development
- More emphasis on understanding human factors

## Preparing for the Transition

For individuals and organizations looking to succeed in this new environment, several approaches make sense:

**For Individuals**:

- Focus on developing judgment through varied experiences
- Build broad knowledge across multiple domains
- Practice making and learning from strategic decisions
- Get comfortable with ambiguity and uncertainty

**For Organizations**:

- Invest in tools that augment human judgment
- Develop processes that capture and share strategic insights - Create cultures that value and develop good judgment
- Build teams with diverse perspectives and experiences

### The Human Element Remains Central

It's crucial to remember that this shift doesn't diminish the importance of human contribution - it actually elevates it. As AI handles more routine tasks, human judgment, creativity, and wisdom become more valuable, not less.

Consider the example of chess: Despite AI systems being able to beat any human player, human chess hasn't disappeared. Instead, it's evolved. The most interesting matches now involve human-AI collaboration, where success depends on humans knowing what positions to play for and when to trust or override AI suggestions.

This pattern will likely repeat across many fields - the key to success will be understanding what humans do best and creating systems that augment these capabilities rather than try to replace them.

## Looking Ahead

The transition from "how" to "what" won't happen overnight, but it's already underway. Organizations and individuals that recognize and adapt to this shift will have significant advantages. Those that continue to focus primarily on "how" skills risk finding their capabilities increasingly commoditized by AI.

This shift also suggests we need to rethink education and training. Rather than focusing primarily on teaching technical skills that AI might soon handle, we should emphasize developing judgment, creativity, and strategic thinking - the fundamentally human capabilities that will become increasingly valuable.

The future belongs not to those who can execute tasks most efficiently, but to those who can best decide what tasks are worth doing in the first place.

In the early days of the personal computer revolution, spreadsheet software transformed financial analysis. Critics warned that tools like VisiCalc and Lotus 1-2-3 would eliminate financial analysts by automating their calculations. Instead, these tools dramatically increased productivity while shifting analysts' focus from mathematical computation to business insight. Today's artificial intelligence is driving a similar transformation, but at a far greater scale and across virtually every knowledge-based profession.


![What-How Matrix](_resources/images/Ch03-images/what-how-matrix.svg){#fig-what-how-matrix width=80%}

## Beyond the False Binary

The current discourse on AI's impact falls into a tiresome and inaccurate binary: either AI will replace human workers entirely, or its effects will be marginal. Both narratives miss the fundamental transformation underway. What we're witnessing is not wholesale replacement but a profound shift in the nature of human contribution—a redistribution of value across the knowledge work spectrum that redefines which human capabilities command a premium.

This transformation becomes apparent when we distinguish between two fundamental aspects of any intellectual task: determining *what* needs to be done versus executing *how* to do it. This distinction, while seemingly straightforward, carries profound implications for the future of work, business strategy, and investment that extend far beyond the simplistic replacement narrative dominating public discourse.

The what-how framework offers remarkable clarity amid the confusing narratives surrounding AI. It helps explain why certain cognitive tasks are rapidly becoming commoditized while others remain stubbornly resistant to automation. More importantly, it provides a roadmap for individuals, organizations, and policymakers navigating a landscape where artificial intelligence increasingly pervades knowledge work.

Until the arrival of generative AI, individuals gained professional advantages through superior "how" skills---they excelled at crafting compelling presentations, building complex spreadsheets, writing efficient code, or translating between languages. These implementation abilities represented valuable skills that could be developed and applied on behalf of those who determined *what* needed to be done.

In traditional organizational hierarchies, executives and managers typically decide *what* initiatives to pursue, while specialized knowledge workers determine *how* to execute them. This division has historically functioned efficiently because *how* expertise---whether in financial modeling, software development, or content creation---required significant investment in learning specialized tools and methodologies.

The emergence of sophisticated AI systems fundamentally alters this equation. Large language models demonstrate remarkable proficiency in implementation tasks, often exceeding human capabilities in narrow domains. They can generate code, compose business communications, create visual assets, and perform complex analyses with minimal human guidance. These systems excel precisely in the domain of *how*---the execution of well-defined tasks within established parameters.

What these systems cannot do---and what remains uniquely human---is determine *what* is worth doing in the first place. They cannot independently identify which problems merit attention, which strategies align with organizational values, or which approaches will resonate with stakeholders. They lack the contextual understanding, ethical framework, and strategic vision required to make these determinations.

As noted already, the financial analyst traditionally created value from technical modeling skills. As AI systems increasingly automate complex financial calculations, the analyst's competitive advantage shifts toward identifying which factors merit analysis, which comparisons yield strategic insights, and how findings translate into investment decisions. The technical implementation---the *how*---becomes commoditized, while judgment about *what* to analyze becomes the primary value driver.

This pattern repeats across knowledge work domains. In marketing, AI can generate endless variations of campaign materials, but cannot determine which messaging will align with brand values and audience expectations. In software development, AI can produce functional code based on specifications but cannot identify which features will deliver genuine user value. In healthcare, AI can analyze diagnostic images with remarkable accuracy but cannot integrate these findings with the full context of patient well-being.

## Philosophical Dimensions of the Divide

The what-how divide resonates with deeper philosophical questions about the nature of intelligence and agency. Martin Heidegger, whose work we explore more fully in Chapter 4, offers particularly relevant insights through his concept of "comportments"—the way humans face and engage with the world around them.

When we are deeply engaged in an activity—skillfully driving a car, playing an instrument, or writing code—we are not consciously thinking about the mechanics of these actions. Our focus extends beyond the immediate task to its purpose and meaning within our broader existence. The ultimate comportment, Heidegger suggests, is our orientation toward being itself, which encompasses our understanding of past, present, and future.

Artificial intelligence systems, even sophisticated ones like GPT-4 or Claude, lack these comportments. They process information without any inherent purpose or temporal orientation. They can mimic human-like outputs but have no concept of why these outputs matter or how they fit into broader human concerns. This philosophical distinction manifests practically in AI's inability to determine *what* is worth doing independent of human direction.

The what-how divide thus represents more than a practical delineation of tasks; it reflects a fundamental distinction between human and artificial intelligence. While AI excels at executing well-defined processes—the *how*—it cannot engage with the existential questions of purpose and meaning that inform human decisions about *what* deserves attention.

This philosophical perspective helps explain why LLMs struggle with certain seemingly simple tasks, as we demonstrated in prior chapters. Tasks that require constant re-evaluation and adjustment based on evolving goals—like writing a sentence that accurately describes its own length or completing a Sudoku puzzle—reveal the fundamental limitations of systems that cannot backtrack or reconsider their approach once they've begun generating outputs.

## Case Studies: The Divide in Practice

To illustrate the what-how divide, let's examine several domains where this transformation is particularly evident:

### Software Development

Traditional programming expertise focused heavily on implementation details—mastering specific languages, frameworks, and architectural patterns. While these technical skills remain valuable, AI code generation tools increasingly automate routine implementation tasks. The premium shifts toward determining which features will deliver value, how systems should interact with users, and what architectural decisions will support long-term business objectives.

Senior developers report that junior programmers who once spent years mastering syntax and debugging techniques now leverage AI assistants to handle these aspects, allowing them to focus earlier in their careers on higher-level system design and user experience considerations—traditionally the domain of more experienced developers.

This shift alters the career progression trajectory for software engineers. Technical implementation skills remain necessary but insufficient; they must be paired with strategic judgment about what deserves implementation in the first place. Engineers who maintain purely technical focus without developing this broader perspective may find their competitive position eroding as AI systems increasingly automate routine coding tasks.

### Content Creation

In media and marketing, AI systems now generate remarkably coherent and stylistically appropriate content at scale. The limiting factor is no longer production capacity but strategic direction—determining which messages will resonate with target audiences, which topics deserve attention, and how content aligns with broader brand narratives.

Marketing executives evaluating AI writing assistants frequently report that while these tools can "automatically compose email replies," users typically spend as much time editing these drafts as they would creating responses from scratch. The real value emerges when humans with deep customer knowledge direct these tools toward specific strategic objectives.

This transformation extends beyond business communication to creative fields. As we explored with the AI-generated completion of Beethoven's unfinished tenth symphony, technical proficiency alone cannot replicate the ineffable quality that distinguishes truly meaningful creative work. As music critic Jan Swafford observed, "We humans need to see the human doing it." The value derives not just from the output itself but from knowing it represents authentic human struggle, insight, and purpose.

### Healthcare

Medical diagnostic systems increasingly match or exceed human performance in analyzing medical images, identifying patterns in patient data, and suggesting potential diagnoses. Yet these systems cannot determine which factors are most relevant for a particular patient, how to weigh complex trade-offs between treatment options, or how to communicate findings in ways that respect patient values and preferences.

A physician whose only skill is knowing *how* to diagnose a patient's condition is becoming less necessary. The crucial human contribution shifts toward determining *what* aspects of patient wellbeing deserve priority, which treatment approaches align with patient values, and how to integrate medical insights with broader quality-of-life considerations.

This shift carries significant implications for medical education and practice. Technical diagnostic skills remain essential but must increasingly be paired with heightened capabilities for integrative judgment, ethical reasoning, and communication. The most effective healthcare practitioners of the future will leverage AI for routine analytical tasks while focusing their human expertise on the complex judgments that machines cannot make.

## The Competitive Dynamics of the Divide

The what-how framework carries significant implications for competitive strategy across industries. As implementation capabilities become increasingly commoditized through AI, sustainable competitive advantage shifts toward superior judgment about what deserves implementation in the first place.

This dynamic particularly challenges organizations that have traditionally derived their advantage primarily from superior execution. When AI systems can implement strategies with comparable efficiency across competitors, the primary differentiator becomes the quality of strategic judgment guiding that implementation. Organizations must evolve their capabilities accordingly, developing institutional capacity for the complex judgments that remain resistant to automation.

We see this pattern emerging in investment management, where quantitative analysis tools have become increasingly sophisticated and widely available. The differentiator for successful investment firms shifts toward superior judgment about which factors merit analysis, which market signals deserve attention, and how various considerations should be weighted in decision-making.

Similarly, in management consulting, the technical aspects of data analysis and presentation—traditionally key components of the service offering—are increasingly automated. The value proposition shifts toward helping clients determine which problems deserve attention, which approaches align with organizational values, and how various factors should be prioritized.

For technology companies specifically, the what-how framework offers valuable guidance for product development. The most successful AI implementations enhance rather than replace human judgment, allowing people to focus on the high-value *what* decisions where they maintain a durable advantage. Products that merely automate implementation without facilitating better strategic decisions will struggle to deliver sustainable value.

## Organizational Implications

This fundamental shift carries significant implications for how organizations approach talent development, operational structure, and competitive strategy. Companies that recognize and adapt to the what-how divide will establish sustainable advantages in an AI-enhanced economy.

First, talent development programs must evolve beyond technical training focused on implementation skills. While baseline technical literacy remains essential, organizations should invest more heavily in developing employees' abilities to frame problems effectively, synthesize insights across domains, and make nuanced judgments that integrate technical, business, and ethical considerations.

The most valuable professional development initiatives will foster precisely those capabilities that remain distinctly human—contextual understanding, strategic synthesis, and ethical judgment. This represents a significant departure from traditional approaches that emphasize mastery of specific tools and methodologies.

Second, workflow design should consciously separate strategic decisions from implementation details, creating clear interfaces between human judgment and AI execution. This approach maintains appropriate human oversight while leveraging AI's capabilities for rapid, consistent implementation.

Effective workflow design requires careful consideration of where human judgment adds the most value. Rather than automating entire processes end-to-end, organizations should identify the critical decision points where human judgment remains essential and design workflows that explicitly incorporate this judgment while automating surrounding implementation steps.

Third, organizational structures should evolve to emphasize roles that combine domain expertise with AI literacy. The traditional separation between business strategists and technical implementers becomes less valuable as AI systems increasingly bridge this gap. New hybrid roles will emerge that focus on translating business objectives into effective AI implementation approaches.

This structural evolution may require reconsidering traditional career paths and reporting relationships. Organizations that maintain rigid distinctions between technical and strategic roles may struggle to develop the integrated capabilities needed for effective human-AI collaboration.

## Investment Implications

For investors, the what-how framework offers valuable guidance for evaluating AI-related opportunities. Companies positioned to win in this environment include those that:

1. Develop tools that enhance human strategic thinking rather than merely automating implementation tasks 2. Create platforms that facilitate seamless collaboration between human judgment and AI execution 3. Build solutions that maintain appropriate human oversight while leveraging AI capabilities 4. Design business models that recognize and reward uniquely human contributions

By contrast, companies that focus exclusively on automation without considering the continued importance of human judgment will likely struggle to deliver sustainable value. The most successful AI implementations will be those that augment rather than replace human capabilities, allowing people to focus on the high-value *what* decisions where they maintain a durable advantage.

This perspective offers a useful corrective to the common investor tendency to overvalue pure automation plays. The history of technology adoption suggests that approaches that enhance rather than replace human capabilities typically deliver more sustainable value over time.

## The Evolution of Knowledge Work

As AI capabilities continue to evolve, we can anticipate further shifts in the relative value of different forms of human contribution. Implementation skills—the *how*—will continue to be commoditized, while strategic judgment—the *what*—will command an increasing premium. This doesn't mean implementation expertise becomes irrelevant, but rather that it must be paired with higher-level strategic capabilities to remain valuable.

For individual knowledge workers, this suggests a clear direction for professional development. Rather than focusing exclusively on technical mastery within narrow domains, sustainable career advancement will require developing broader strategic capabilities: understanding stakeholder needs, synthesizing insights across disciplines, and making nuanced judgments that integrate technical, business, and ethical considerations.

For educational institutions, the what-how divide suggests the need for fundamental curriculum redesign. Traditional education systems heavily emphasize *how* skills—teaching specific methodologies, tools, and techniques. Future-oriented education should place greater emphasis on developing students' abilities to frame problems effectively, think across disciplinary boundaries, and make contextual judgments that cannot be easily automated.

For policymakers, this framework offers a more nuanced understanding of AI's impact on employment and economic opportunity. Rather than focusing exclusively on potential job displacement, policy approaches should consider how to facilitate the transition toward work that emphasizes uniquely human strategic capabilities while ensuring that the benefits of AI-driven productivity gains are broadly shared.

## Integration with Enhancement Thesis

The what-how framework aligns perfectly with our core thesis that AI will enhance rather than replace human capabilities across industries. By automating routine implementation tasks, AI frees human cognitive capacity for higher-level strategic thinking—the domain where human judgment maintains a durable advantage. This represents not replacement but enhancement of human potential.

This perspective also explains why purely automated approaches often disappoint. When AI systems operate without appropriate human direction and oversight, they may execute flawlessly within their parameters while completely missing the broader context that gives their outputs meaning and value. The most successful implementations maintain humans "in the loop" precisely because human judgment about *what* matters cannot be delegated to automated systems.

Consider full self-driving technology, which we'll explore more fully in later chapters. Companies like Tesla have collected unprecedented amounts of driving data and developed increasingly sophisticated systems for navigating complex environments. Yet as robotics pioneer Rodney Brooks has observed, these systems still struggle with the contextual judgment that experienced human drivers exercise effortlessly.

A human driver approaching a neighborhood with cars parked tightly on both sides naturally slows down, recognizing the increased risk of children darting into the street. This judgment doesn't derive from explicit rules but from a holistic understanding of context that integrates multiple factors—some explicit, others tacit. Autonomous systems may eventually replicate this behavior through sophisticated pattern recognition, but they cannot independently determine which factors deserve attention without human direction.

## Conclusion: Navigating the Transformation

The what-how divide provides a powerful framework for understanding AI's true impact on knowledge work and business strategy. Rather than wholesale replacement, we're witnessing a fundamental shift in the nature of human contribution—from executing well-defined tasks to making strategic judgments about what deserves attention and how different considerations should be weighed.

This transformation presents both challenges and opportunities. Organizations and individuals that continue to focus exclusively on implementation skills will find their competitive position eroding as AI systems increasingly automate these functions. Those who develop the strategic judgment to determine *what* is worth doing—and the ability to direct AI systems effectively toward these ends—will thrive in an AI-enhanced economy.

The what-how framework aligns with our broader thesis that successful AI implementation requires keeping humans "in the loop." Not because of temporary technical limitations that will eventually be overcome, but because of fundamental differences between human and artificial intelligence. The most valuable human contributions have always involved more than technical execution—they reflect purpose, meaning, and judgment that remain uniquely human even as AI capabilities advance.

In the next chapter, we'll explore these philosophical dimensions more deeply, examining why understanding the nature of human intelligence is crucial for designing effective human-AI collaborations. By recognizing both the capabilities and limitations of artificial intelligence, we can develop approaches that truly enhance human potential rather than attempting to replace it.